{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate evoked LFP response by optogenetic stimulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load LFP and packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from IPython.display import display\n",
    "from ipyfilechooser import FileChooser\n",
    "from scipy.stats import zscore\n",
    "import json\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Channels = '//10.69.168.1/crnldata/forgetting/Aurelie/allLFPChannels_perMice.xlsx'\n",
    "allchannels = pd.read_excel(Channels, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose OpenEphys folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # tries to retrieve dpath either from a previous run or from a previous notebook\n",
    "    %store -r dpath\n",
    "    #dpath=Path(dpath).parent\n",
    "except:\n",
    "    print(\"the path was not defined in store\")\n",
    "    #dpath = \"/Users/mb/Documents/Syntuitio/AudreyHay/PlanB/ExampleRedLines/2022_08_06/13_30_01/My_V4_Miniscope/\"\n",
    "    dpath = \"//10.69.168.1/crnldata/forgetting/Aurelie/\"\n",
    "\n",
    "\n",
    "fc1 = FileChooser(dpath,select_default=True, show_only_dirs = True, title = \"<b>Go inside the folder containing the LFP raw file</b>\")\n",
    "display(fc1)\n",
    "\n",
    "# Sample callback function\n",
    "def update_my_folder(chooser):\n",
    "    global dpath\n",
    "    dpath = chooser.selected\n",
    "    %store dpath\n",
    "    return \n",
    "\n",
    "# Register callback function\n",
    "fc1.register_callback(update_my_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load LFPs data, TTL, timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_base = Path(dpath)\n",
    "\n",
    "LFPfile = Path(f'{folder_base}\\continuousDS.npy') #RawDataChannelExtractedDS.npy\n",
    "LFPfile2= Path(f'{folder_base}\\continuous.dat')\n",
    "\n",
    "# Load LFPs data \n",
    "if LFPfile.exists(): # prefer loading downsample file other original file\n",
    "    print('continuousDS.npy file')\n",
    "    All = np.load(LFPfile, mmap_mode= 'r')\n",
    "    samplerate=1000 \n",
    "    numchannel=All.shape[1]\n",
    "    # Load LFPs timestamps \n",
    "    for file_pathTS in folder_base.parent.parent.glob('**/continuous/*/timeStampsDS.npy'):\n",
    "        print('LFPs timestamps file = ', file_pathTS)\n",
    "        LFPtimestamps = np.load(file_pathTS)  \n",
    "elif LFPfile2.exists():\n",
    "    print('continuous.dat file')\n",
    "    LFPfile = LFPfile2\n",
    "    DataRec = np.fromfile(LFPfile, dtype=\"int16\")\n",
    "    filepath_metadata = Path(os.path.join(folder_base.parent.parent, f'structure.oebin'))\n",
    "    if filepath_metadata.exists():    \n",
    "        with open(filepath_metadata) as f:\n",
    "            metadata = json.load(f)\n",
    "        samplerate=metadata['continuous'][0]['sample_rate']  \n",
    "        numchannel=metadata['continuous'][0]['num_channels']  \n",
    "    else:\n",
    "        samplerate=1000 \n",
    "        numchannel=32\n",
    "    All = DataRec.reshape(-1,numchannel)\n",
    "    # Load LFPs timestamps \n",
    "    for file_pathTS in folder_base.parent.parent.glob('**/continuous/*/timeStamps.npy'):\n",
    "        print('LFPs timestamps file = ', file_pathTS)\n",
    "        LFPtimestamps = np.load(file_pathTS)  \n",
    "else: \n",
    "    print('no LFPs file found')\n",
    "\n",
    "print(numchannel, 'channels recorded')\n",
    "print('sample rate =', samplerate, 'Hz')\n",
    "print(round(All.shape[0]/samplerate/60), 'min of recording')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_decimal=3 # 4 = 0.1ms precision / 3 = 1ms precision\n",
    "\n",
    "# Load TTLs\n",
    "TTL_Opto_duration=[]\n",
    "for file_pathTTL in folder_base.parent.parent.glob('**/TTL/timeStamps.npy'):\n",
    "    print('TTL opto file = ', file_pathTTL)\n",
    "    TTL_Opto_o = np.load(file_pathTTL)\n",
    "    TTL_Opto_duration =[round(TTL_Opto_o[i+1] - TTL_Opto_o[i],nb_decimal) for i in range(len(TTL_Opto_o) - 1)[::2]]\n",
    "    TTL_Opto= TTL_Opto_o[::2] # remove the TTL for laser OFF, only keep TTL for laser ON. CAUTION /!/ works only if it started with a TTL for laser ON\n",
    "    print(TTL_Opto.shape[0], 'opto stimulations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsample LFP data to 1kHz if needed & save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if samplerate > 1000:\n",
    "    datalen = np.shape(All)[0]\n",
    "    new_sampling_rate = 1000 # Hz\n",
    "    Nmber_points = int(datalen * new_sampling_rate / samplerate)\n",
    "    AllDS=signal.resample(All, Nmber_points, axis = 0)\n",
    "    LFPtimestampsDS=LFPtimestamps[::10][:-1]\n",
    "    samplerate=new_sampling_rate\n",
    "    np.save(f'{LFPfile.parent}/continuousDS.npy', AllDS)\n",
    "    np.save(f'{file_pathTS.parent}/timeStampsDS.npy', LFPtimestampsDS)\n",
    "    All=AllDS\n",
    "    LFPtimestamps=LFPtimestampsDS\n",
    "# eventually delete original files to gain space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load LFPs channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse=[]\n",
    "for mouse_name in allchannels.index:\n",
    "    if mouse_name in LFPfile.__str__():\n",
    "        mouse.append(mouse_name)\n",
    "\n",
    "sCh=0 \n",
    "all_ch_selected=1\n",
    "if len(mouse)>1: # found multiple mouse name in the path\n",
    "    if numchannel==32 : #  Only one mouse recorded\n",
    "        ID = 0 # change the index if this is not the good mouse name\n",
    "        print(f\"/!\\ Mutliple mouse names in the path = {mouse}. The n°{ID+1} was choosen automatically = {mouse[ID]}.\")\n",
    "        mouse=mouse[ID] \n",
    "    elif numchannel % 32 == 0: # Multiple mice recorded at the same time\n",
    "        ID = 0 # choose 0 to see the first mouse recorded, 1 the second, 2 the third, 3 the fourth (only 4 mice can be recorded at the same time)\n",
    "        sCh= 32*ID \n",
    "        print(f\"/!\\ Mutliple mice recorded at the same time = {mouse}. The n°{ID+1} was choosen automatically = {mouse[ID]}.\")\n",
    "        mouse=mouse[ID] \n",
    "    else: # the number of channels recorded is not a multiple of 32 = you probably selected manually which channel to record \n",
    "        ID = 0 # choose 0 to see the first mouse recorded, 1 the second, 2 the third, 3 the fourth (only 4 mice can be recorded at the same time)\n",
    "        print(f\"/!\\ Mutliple mice recorded at the same time = {mouse}. The n°{ID+1} was choosen automatically = {mouse[ID]}.\\n/!\\ Channels were manually selected for the recording.\")\n",
    "        mouse=mouse[ID] \n",
    "        all_ch_selected=0 # not all channels were recorded\n",
    "elif len(mouse)==1: # found one mouse name in the path\n",
    "    mouse=mouse[0]\n",
    "\n",
    "if mouse:\n",
    "    RecordedArea=[]\n",
    "    ChoosenChannels=[]\n",
    "    combined=[]\n",
    "    num_ch=0\n",
    "    for idx, channels in enumerate(allchannels.loc[mouse]):\n",
    "        region=allchannels.loc[mouse].index[idx]\n",
    "        if region != 'EMG':\n",
    "            if isinstance(allchannels.loc[mouse].loc[region], str): # at least 2 channels\n",
    "                ch_list = channels.split('_')\n",
    "                for idx, ch in enumerate(ch_list): # only take the 2 first channels (change the order in the excel file if you want another pair)\n",
    "                    LFP=All[:,int(ch)+sCh] if all_ch_selected else All[:,num_ch]\n",
    "                    num_ch+=1\n",
    "                    locals()[f'{region}_{idx}']=LFP\n",
    "                    RecordedArea.append(f'{region}_{idx}')    \n",
    "                    combined=zscore(LFP[:,np.newaxis]) if len(combined)==0 else np.append(combined, zscore(LFP[:,np.newaxis]), axis=1)\n",
    "                    ChoosenChannels.append(ch)  if all_ch_selected else ChoosenChannels.append([num_ch])    \n",
    "            elif isinstance(allchannels.loc[mouse].loc[region], (np.int64, int)): # only one channel\n",
    "                ch=allchannels.loc[mouse].loc[region]  \n",
    "                idx=0\n",
    "                ChoosenChannels.append(str(ch)) if all_ch_selected else ChoosenChannels.append(num_ch)\n",
    "                LFP=All[:,ch+sCh] if all_ch_selected else All[:,num_ch]\n",
    "                num_ch+=1\n",
    "                locals()[f'{region}_{idx}']=LFP\n",
    "                RecordedArea.append(f'{region}_{idx}')    \n",
    "                combined=zscore(LFP[:,np.newaxis]) if len(combined)==0 else np.append(combined, zscore(LFP[:,np.newaxis]), axis=1)\n",
    "    print(mouse)\n",
    "    print(RecordedArea)\n",
    "    print(ChoosenChannels) \n",
    "else:\n",
    "    print(\"/!\\ No mouse name found in the path OR in the excel file 'allLFPChannels_perMice.xlsx'\")\n",
    "    mouse='' # fill mouse name\n",
    "    RecordedArea=['PFC_0','PFC_1'] # change \n",
    "    PFC_0=All[:,0] # change \n",
    "    PFC_1=All[:,0] # change \n",
    "    combined=np.stack([zscore(PFC_0), zscore(PFC_1)], axis=1) # change "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check TTL durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.stairs(np.array(TTL_Opto_duration)*1000)\n",
    "plt.xlabel('# Opto stimulations')\n",
    "plt.ylabel('Opto stimulation durations (ms)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get response of each brain region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllEPSPs=[]\n",
    "for ttl in TTL_Opto:   \n",
    "    idx = (np.abs(LFPtimestamps - ttl)).argmin() # find the closest LFP timestamps to the TTL\n",
    "    AllEPSPs.append(combined[idx-round(0.5*samplerate):idx+round(0.5*samplerate), :]) #500 ms before and after TTL\n",
    "\n",
    "plt.close()\n",
    "plt.figure(figsize=(6, 3))\n",
    "time_axis = np.linspace(-500, 500, np.shape(AllEPSPs)[1]) \n",
    "mEPSPs=np.mean(AllEPSPs, axis=0)\n",
    "colors = cm.rainbow(np.linspace(0, 1, np.shape(mEPSPs)[1]))\n",
    "for i in np.arange(0,np.shape(AllEPSPs)[2]):\n",
    "    plt.plot(time_axis, mEPSPs[:,i], label=f'{RecordedArea[i]}', color=colors[i])\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Averaged EPSPs\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncols=1)\n",
    "plt.subplots_adjust(right=.5)\n",
    "plt.xlim([-25, 50])\n",
    "plt.title(f'Mouse = {mouse}, Stim opto duration = {np.unique(TTL_Opto_duration)[0]*1000} - {np.round(np.unique(TTL_Opto_duration)[-1]*1000,2)} ms \\nfilename = {folder_base.parts[-6]}', fontsize=12) # Change to indicate where is located that LFP\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get response for one brain region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose brain region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_region='oPFC_0' # to change\n",
    "SelectedLFP=locals()[Selected_region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_differentStim=len(np.unique(TTL_Opto_duration)) # how many different opto stim are performed in the arduino protocol (here a loop of 19 stim with different durations)\n",
    "DurStim=np.unique(TTL_Opto_duration)*1000 # durations of each unique stim (from 1 ms to 20 ms with a step of 1)\n",
    "\n",
    "halfdurEPSP=0.1 #sec\n",
    "analyseWindow= 0.025 #sec post stim\n",
    "\n",
    "AllStim={}\n",
    "for i, ttl  in enumerate(TTL_Opto):\n",
    "    idx = (np.abs(LFPtimestamps - ttl)).argmin() # find the closest LFP timestamps to the TTL    \n",
    "    if str(TTL_Opto_duration[i]*1000) in AllStim:\n",
    "        AllStim[str(TTL_Opto_duration[i]*1000) ]=pd.concat([AllStim[str(TTL_Opto_duration[i]*1000) ],pd.DataFrame(SelectedLFP[idx-round(halfdurEPSP*samplerate):idx+round(halfdurEPSP*samplerate)])],axis=1)\n",
    "    else:\n",
    "        AllStim[str(TTL_Opto_duration[i]*1000) ]=pd.DataFrame(SelectedLFP[idx-round(halfdurEPSP*samplerate):idx+round(halfdurEPSP*samplerate)])\n",
    "   \n",
    "AllStim_sorted = dict(sorted(AllStim.items()))\n",
    "meanAllStim= pd.DataFrame([np.mean(AllStim_sorted[key], axis=1) for key in AllStim_sorted.keys()]).T\n",
    "meanAllStim= pd.DataFrame([meanAllStim[key]-np.mean(meanAllStim[key][int((halfdurEPSP*samplerate)-(halfdurEPSP*samplerate)):int(halfdurEPSP*samplerate)]) for key in meanAllStim.columns]).T\n",
    "meanAllStim.columns=DurStim #convert columns names in ms\n",
    "\n",
    "\"\"\"                         \n",
    "Amplitude=[]\n",
    "Max=[]\n",
    "HalfMaxWidth=[]\n",
    "for i in meanAllStim.columns:\n",
    "    y=meanAllStim[i][round(halfdurEPSP*samplerate):round((halfdurEPSP+analyseWindow)*samplerate)]\n",
    "    peaks, properties = signal.find_peaks(y, height=min(y), prominence=0)\n",
    "    if len(peaks) > 0:\n",
    "        widths, width_heights, left_ips, right_ips = signal.peak_widths(y, peaks, rel_height=0.5)\n",
    "        biggest_peak_idx = np.argmax(properties[\"peak_heights\"])\n",
    "        biggest_peak = peaks[biggest_peak_idx]\n",
    "        half_width = widths[biggest_peak_idx] / 2\n",
    "        Amplitude.append(properties[\"prominences\"][biggest_peak_idx])\n",
    "        Max.append(properties[\"peak_heights\"][biggest_peak_idx])\n",
    "        HalfMaxWidth.append(half_width)\n",
    "    else:\n",
    "        Amplitude.append(np.nan)\n",
    "        Max.append(np.nan)\n",
    "        HalfMaxWidth.append(np.nan)\n",
    "\"\"\"\n",
    "Amplitude=meanAllStim[round(halfdurEPSP*samplerate):round((halfdurEPSP+analyseWindow)*samplerate)].max()-meanAllStim[round(halfdurEPSP*samplerate):round((halfdurEPSP+analyseWindow)*samplerate)].min()\n",
    "Max=meanAllStim[round(halfdurEPSP*samplerate):round((halfdurEPSP+analyseWindow)*samplerate)].max()\n",
    "HalfMaxWidth = [((np.abs(meanAllStim[i][meanAllStim[i][meanAllStim[i]==Max[i]].index[0]:] - Max[i]/2)).argmin() -round(halfdurEPSP*samplerate) + meanAllStim[i][meanAllStim[i]==Max[i]].index[0])/samplerate*1000 for i in meanAllStim.columns]\n",
    "\n",
    "# Plot\n",
    "plt.close()\n",
    "fig, axs = plt.subplots(2,2, figsize=(12,6))\n",
    "fig.suptitle(f'Mouse = {mouse}, LFP = {Selected_region} \\nfilename = {folder_base.parts[-6]}', fontsize=12) # Change to indicate where is located that LFP\n",
    "\n",
    "time_axis = np.linspace(-halfdurEPSP*1000, halfdurEPSP*1000, meanAllStim.shape[0]) \n",
    "grey_shades = np.linspace(0.9, 0.1, len(meanAllStim.columns)) \n",
    "for i, col in enumerate(meanAllStim.columns):\n",
    "    axs[0,0].plot(time_axis, meanAllStim[col], color=(grey_shades[i], grey_shades[i], grey_shades[i]), label=f'{round(col,4)} ms')\n",
    "axs[0,0].plot(time_axis, np.mean(meanAllStim, axis= 1), color='red')\n",
    "axs[0,0].set(xlabel=\"Time (ms)\", ylabel=\"Averaged EPSPs\")\n",
    "#axs[0,0].set(ylim=(-750, 1000))\n",
    "axs[0,0].set(xlim=(-25, 50))\n",
    "\n",
    "axs[0,1].plot(DurStim,Amplitude, 'k')\n",
    "axs[0,1].set(xlabel=\"Opto stim duration (ms)\", ylabel=\"Amplitude \")\n",
    "\n",
    "axs[1,0].plot(DurStim,Max, 'k')\n",
    "axs[1,0].set(xlabel=\"Opto stim duration (ms)\", ylabel=\"Maximum \")\n",
    "\n",
    "axs[1,1].plot(DurStim, HalfMaxWidth, 'k')\n",
    "axs[1,1].set(xlabel=\"Opto stim duration (ms)\", ylabel=\"HalfWidth (ms)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "axs[0,0].legend(loc='upper center', bbox_to_anchor=(2.5, 1.2),\n",
    "          fancybox=True, shadow=True, ncol=max(int(nb_differentStim/18), 1))\n",
    "plt.subplots_adjust(right=.8)  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
