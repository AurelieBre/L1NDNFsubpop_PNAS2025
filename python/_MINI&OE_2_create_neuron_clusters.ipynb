{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import umap\n",
    "import hdbscan\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from IPython.display import display\n",
    "from ipyfilechooser import FileChooser\n",
    "%matplotlib widget\n",
    "from scipy.stats import zscore\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.manifold import Isomap\n",
    "import networkx as nx\n",
    "from scipy.stats import entropy\n",
    "import warnings\n",
    "import pickle\n",
    "import matplotlib.cm as cm\n",
    "import ast\n",
    "from pathlib import Path\n",
    "from scipy.stats import sem  # for standard error of the mean\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import ks_2samp\n",
    "import diptest\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # tries to retrieve dpath either from a previous run or from a previous notebook\n",
    "    %store -r dpath\n",
    "except:\n",
    "    print(\"the path was not defined in store\")\n",
    "    #dpath = \"/Users/mb/Documents/Syntuitio/AudreyHay/PlanB/ExampleRedLines/2022_08_06/13_30_01/My_V4_Miniscope/\"\n",
    "    dpath = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/\"\n",
    "\n",
    "fc1 = FileChooser(dpath,select_default=True, show_only_dirs = True, title = \"<b>Folder with videos</b>\")\n",
    "display(fc1)\n",
    "\n",
    "# Sample callback function\n",
    "def update_my_folder(chooser):\n",
    "    global dpath\n",
    "    dpath = chooser.selected\n",
    "    %store dpath\n",
    "    return \n",
    "\n",
    "# Register callback function\n",
    "fc1.register_callback(update_my_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    combined_df = pd.read_excel(f'{dpath}/VigStates_Global.xlsx', index_col=0)\n",
    "except:\n",
    "    with open(f'{dpath}/VigStates_Global.pkl', 'rb') as pickle_file:\n",
    "        combined_df = pickle.load(pickle_file)\n",
    "        \n",
    "desired_order = ['AW','QW', 'NREM', 'IS', 'REM', 'undefined']   \n",
    "\n",
    "NrSubtype='L2_3_mice' #['L1NDNF_mice','L2_3_mice']\n",
    "\n",
    "DataType='NormalizedAUC_calcium' # NormalizedAUC_calcium, SpikeActivityHz , DeconvSpikeMeanActivity, CalciumActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Unique_Unit'] = combined_df['Unique_Unit'].astype(int).astype(str)\n",
    "combined_df['UnitNumber'] = combined_df['UnitNumber'].astype(str)\n",
    "combined_df['UnitValue'] = combined_df['UnitValue'].astype(str)\n",
    "combined_df['Unit_ID'] = combined_df['Mice'] + combined_df['Unique_Unit']\n",
    "combined_df['Substate_ID'] = combined_df['Mice'] + combined_df['Session'] + combined_df['Substate'] + combined_df['SubstateNumber'].astype(str)\n",
    "combined_df['Session_ID'] = combined_df['Session_Date'] + '_' + combined_df['Session_Time'].astype(str)\n",
    "combined_df['NormalizedAUC_calcium'] = combined_df['AUC_calcium'] / combined_df['DurationSubstate']\n",
    "\n",
    "combined_df_Drug=combined_df.copy()\n",
    "combined_df_Drug = combined_df_Drug[combined_df_Drug['Drug'] == 'baseline']\n",
    "combined_df_Drug = combined_df_Drug[combined_df_Drug['NeuronType'] == NrSubtype]\n",
    "\n",
    "\n",
    "data_origin = combined_df_Drug.pivot_table(index='Unit_ID', columns='Substate', values=DataType, aggfunc='mean') \n",
    "\n",
    "try : data_origin = data_origin[desired_order]\n",
    "except: pass\n",
    "print(np.shape(data_origin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del data_origin['undefined']\n",
    "except : pass\n",
    "del data_origin['IS']\n",
    "data_origin=data_origin.dropna(axis=0)\n",
    "vigst_nb=np.shape(data_origin)[1]\n",
    "print(np.shape(data_origin))\n",
    "data=data_origin.div(data_origin.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDBSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors= 90 #8\n",
    "min_dist=.9 #.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=2, random_state=None) \n",
    "#n_neighbors=15: range 2 to 100. Controls the balance between local and global structure \n",
    "#n_components=2 : range 2 to 100.Reduces the data to 2D for visualization \n",
    "#min_dist=0.1: Controls the spread of points. Smaller values emphasize local structure\n",
    "X_umap = umap_model.fit_transform(data)\n",
    "\n",
    "hdbscan_model = hdbscan.HDBSCAN(min_cluster_size=15, min_samples=1, prediction_data=True).fit(X_umap)\n",
    "embedding_df = pd.DataFrame(X_umap, columns=['UMAP1', 'UMAP2'])\n",
    "labels = hdbscan_model.fit_predict(X_umap)\n",
    "embedding_df['Cluster'] = labels\n",
    "\n",
    "# Plotting the results\n",
    "\n",
    "cmap = sns.diverging_palette(10, 133, as_cmap=True)\n",
    "plt.close()\n",
    "plt.figure(figsize=(14, 3))\n",
    "\n",
    "# Plot Results\n",
    "plt.subplot(1,5,1)\n",
    "sns.scatterplot(x='UMAP1', y='UMAP2', hue='Cluster', palette='tab20', data=embedding_df, s=30, edgecolor='k', legend=False)\n",
    "plt.title('HDBSCAN ')\n",
    "\n",
    "plt.subplot(1,5,2)\n",
    "sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_df, s=30, edgecolor='k', hue=data['AW'].values, palette='rainbow', legend=False)\n",
    "plt.title('AW')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "\n",
    "plt.subplot(1,5,3)\n",
    "sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_df, s=30, edgecolor='k', hue=data['QW'].values, palette='rainbow', legend=False)\n",
    "plt.title('QW')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "\n",
    "plt.subplot(1,5,4)\n",
    "sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_df, s=30, edgecolor='k', hue=data['NREM'].values, palette='rainbow', legend=False)\n",
    "plt.title('NREM')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "\n",
    "plt.subplot(1,5,5)\n",
    "ax=sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_df, s=30, edgecolor='k', hue=data['REM'].values, palette='rainbow', legend=False)\n",
    "plt.title('REM')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0)\n",
    "plt.colorbar(plt.cm.ScalarMappable(cmap='rainbow'), cax=cax)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#X, color = make_swiss_roll(n_samples=2000, noise=0.1) ## Generate synthetic manifold data (Swiss Roll)\n",
    "X = X_umap\n",
    "\n",
    "# ---- Assumption 1: Uniform distribution (check density variation) ----\n",
    "def check_uniformity(X, n_bins=30):\n",
    "    hist, _ = np.histogramdd(X, bins=n_bins)\n",
    "    hist = hist.flatten()\n",
    "    hist = hist[hist > 0]\n",
    "    hist = hist / np.sum(hist)\n",
    "    ent = entropy(hist)\n",
    "    print(f\"Entropy of distribution: {ent:.2f} (higher = more uniform)\")\n",
    "    \n",
    "check_uniformity(X)\n",
    "\n",
    "# ---- Assumption 2: Locally Euclidean (constant metric) ----\n",
    "def check_local_metric(X, n_neighbors=n_neighbors):\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors).fit(X)\n",
    "    distances, indices = nbrs.kneighbors(X)\n",
    "\n",
    "    # Compute ratio of distances between nearest neighbor and farthest neighbor in local patch\n",
    "    ratios = distances[:, -1] / (distances[:, 1] + 1e-10)\n",
    "    print(f\"Avg. local distance ratio (max/min): {np.mean(ratios):.2f} (closer to 1 = more Euclidean-like)\")\n",
    "    \n",
    "check_local_metric(X)\n",
    "\n",
    "# ---- Assumption 3: Locally connected ----\n",
    "def check_local_connectivity(X, n_neighbors=n_neighbors):\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors).fit(X)\n",
    "    graph = nbrs.kneighbors_graph(X).tocoo()\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    for i, j in zip(graph.row, graph.col):\n",
    "        G.add_edge(i, j)\n",
    "    \n",
    "    n_components = nx.number_connected_components(G)\n",
    "    print(f\"Connected Components in k-NN graph: {n_components} (should be 1 for full connectivity)\")\n",
    "\n",
    "check_local_connectivity(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f\"C:/Users/Manip2/Documents/Manuscripts/Figures_PNASreviews/Figure1_revised/{NrSubtype}_{DataType}_UMAPcluster.svg\", format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouse repartition in cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_df, s=30, edgecolor='k', hue=data.index.str.replace(r'\\d+', '', regex=True).values, palette='tab20', legend=True)\n",
    "plt.title('Mice')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "plt.legend(loc='upper left')#, bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f\"C:/Users/Manip2/Documents/Manuscripts/Figures_PNASreviews/Figure1_revised/{NrSubtype}_UMAPcluster_{DataType}_permouse.svg\", format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate proportions\n",
    "data['Mice'] = data.index.str.replace(r'\\d+', '', regex=True).values\n",
    "data['Cluster'] = labels\n",
    "proportions = data.groupby([ 'Mice', 'Cluster']).size().unstack(fill_value=0)\n",
    "#proportions = proportions.div(proportions.sum(axis=1), axis=0)*100\n",
    "\n",
    "# Plot\n",
    "proportions.plot(kind='bar', stacked=True, figsize=(4, 4), colormap='tab20')\n",
    "plt.ylabel('Cell Count')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f\"C:/Users/Manip2/Documents/Manuscripts/Figures_PNASreviews/Figure1_revised/{NrSubtype}_{DataType}_CellCountCluster_permouse.svg\", format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(set(labels)) > 1 and -1 not in set(labels):\n",
    "    score = silhouette_score(embedding_df, labels)\n",
    "    print(f\"Silhouette Score: {score:.2f}.  Notes: 1 → Well-clustered. 0 → Overlapping clusters. -1 → Misclassified samples.\")\n",
    "else:\n",
    "    print(\"Silhouette Score cannot be calculated. Check for multiple clusters.\")\n",
    "    \n",
    "\n",
    "if len(set(labels)) > 1 and -1 not in set(labels):\n",
    "    db_score = davies_bouldin_score(embedding_df, labels)\n",
    "    print(f\"Davies-Bouldin Index: {db_score:.2f}.   Notes: Lower values indicate better clustering.\")\n",
    "else:\n",
    "    print(\"Davies-Bouldin Index cannot be calculated. Check for multiple clusters.\")\n",
    "\n",
    "\n",
    "if len(set(labels)) > 1 and -1 not in set(labels):\n",
    "    ch_score = calinski_harabasz_score(embedding_df, labels)\n",
    "    print(f\"Calinski-Harabasz Index: {ch_score:.2f}.    Notes: Higher values indicate better clustering.\")\n",
    "else:\n",
    "    print(\"Calinski-Harabasz Index cannot be calculated. Check for multiple clusters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_origin['ClusterHDBSCAN'] = labels if NrSubtype == 'L1NDNF_mice' else 0\n",
    "grouped = data_origin.groupby('ClusterHDBSCAN')\n",
    "means = grouped[data_origin.columns[:vigst_nb]].mean()\n",
    "sems = grouped[data_origin.columns[:vigst_nb]].sem()\n",
    "\n",
    "# Plot\n",
    "ax = means.plot(kind='bar', yerr=sems, capsize=4, figsize=(4, 4))\n",
    "plt.title('Cluster HDBSCAN')\n",
    "plt.ylabel(f'{DataType}')\n",
    "plt.xlabel('Cluster')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(grouped.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f\"C:/Users/Manip2/Documents/Manuscripts/Figures_PNASreviews/Figure1_revised/{NrSubtype}_{DataType}_percluster.svg\", format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sem  \n",
    "plt.figure(figsize=(2, 3))\n",
    "\n",
    "desired_order2=['AW','QW', 'NREM', 'REM']\n",
    "\n",
    "# Generate a color for each group\n",
    "groups = list(grouped.groups.keys())\n",
    "colors = ['#006666ff', '#51aeaeff', '#cbe6e6ff'] if NrSubtype == 'L1NDNF_mice' else ['#a60090ff']\n",
    "\n",
    "# Loop through each group\n",
    "for idx, (name, group) in enumerate(grouped):\n",
    "    color = colors[idx]\n",
    "    \n",
    "    epsilon = 1e-1\n",
    "    group = group.copy()  # avoid modifying original data\n",
    "    group[desired_order2] = group[desired_order2] #+ epsilon\n",
    "\n",
    "    # Plot individual lines\n",
    "    for i in range(len(group)):\n",
    "        values = group.loc[group.index[i], desired_order2]\n",
    "        plt.plot(desired_order2, values, color=color, alpha=1, linewidth=.5)\n",
    "\n",
    "    # Compute mean and SEM\n",
    "    means = group[desired_order2].mean()\n",
    "    errors = group[desired_order2].apply(sem)\n",
    "\n",
    "    # Plot mean circles with error bars\n",
    "    plt.errorbar(\n",
    "        desired_order2, means, yerr=errors, fmt='o', color='black',\n",
    "        capsize=4, markersize=6, markeredgewidth=1, markeredgecolor='black', markerfacecolor=color,\n",
    "        label=f'Cluster {name}'\n",
    "    )\n",
    "    # Connect means with a bold line\n",
    "    plt.plot(desired_order2, means, color='black', linewidth=1)\n",
    "\n",
    "plt.title('Cluster HDBSCAN')\n",
    "plt.ylabel(f'{DataType}')\n",
    "plt.xticks(rotation=0)\n",
    "#plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.ylim(0, 10e2)\n",
    "\n",
    "logpl='symlog' # log or linear\n",
    "plt.yscale(logpl)\n",
    "plt.show()\n",
    "\n",
    "print(grouped.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f\"C:/Users/Manip2/Documents/Manuscripts/Figures_PNASreviews/Figure1_revised/{NrSubtype}_{DataType}_percluster&cells_{logpl}.svg\", format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(combined_df, data_origin['ClusterHDBSCAN'], on='Unit_ID', how='outer') \n",
    "filenameOutAUC = f'{dpath}/VigStates_Global_cluster.xlsx'\n",
    "merged.to_excel(filenameOutAUC)\n",
    "\n",
    "filenameOut = f'{dpath}/VigStates_Global_cluster.pkl'\n",
    "with open(filenameOut, 'wb') as pickle_file:\n",
    "    pickle.dump(merged, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped=combined_df_Drug.groupby(['Unit_ID', 'Session_ID', 'Substate'])[DataType].mean()\n",
    "grouped = grouped.reset_index()\n",
    "grouped2=grouped.pivot_table(index=[grouped['Unit_ID'], grouped['Session_ID']], columns='Substate', values=DataType)\n",
    "try : grouped2 = grouped2[desired_order]\n",
    "except: pass\n",
    "try : del grouped2['IS']\n",
    "except: pass\n",
    "try : del grouped2['undefined']\n",
    "except: pass\n",
    "\n",
    "d=[]\n",
    "test=pd.DataFrame(d, columns=['Cluster_sessID'])\n",
    "\n",
    "for i in np.arange(len(grouped2)):\n",
    "    new_point=np.array(grouped2.iloc[i]).astype(float)\n",
    "    if not np.sum(np.isnan(new_point)): \n",
    "        new_point_umap = umap_model.transform(new_point.reshape(1, -1))\n",
    "        new_label, new_prob = hdbscan.approximate_predict(hdbscan_model, new_point_umap)\n",
    "        test.loc[i,'Cluster_sessID']=new_label[0].astype(str)\n",
    "    else:\n",
    "        test.loc[i,'Cluster_sessID']=None\n",
    "grouped2['Cluster_sessID'] = test['Cluster_sessID'].values\n",
    "\n",
    "grouped3 = grouped2.reset_index()\n",
    "grouped3 = grouped3.drop(columns=['AW', 'QW', 'NREM', 'REM'])\n",
    "grouped3 = grouped3.dropna(subset=['Cluster_sessID'])\n",
    "grouped3 = grouped3[grouped3['Unit_ID'].duplicated(keep=False)] #remove units that only appears in one sessionID\n",
    "\n",
    "\n",
    "# ⏱ Convert to datetime\n",
    "grouped3['Session_ID'] = pd.to_datetime(grouped3['Session_ID'], format='%Y-%m-%d_%H-%M-%S')\n",
    "df_sorted = grouped3.sort_values(['Unit_ID', 'Session_ID'])\n",
    "grouped = df_sorted.groupby('Unit_ID')\n",
    "\n",
    "# Build summary DataFrame\n",
    "summary_df = grouped.agg(\n",
    "    first_date=('Session_ID', 'first'),\n",
    "    last_date=('Session_ID', 'last'),\n",
    "    first_Cluster_sessID=('Cluster_sessID', 'first'),\n",
    "    last_Cluster_sessID=('Cluster_sessID', 'last')\n",
    ")\n",
    "\n",
    "# Calculate number of days between first and last\n",
    "summary_df['days_between'] = (\n",
    "    summary_df['last_date'].dt.floor('D') - summary_df['first_date'].dt.floor('D')\n",
    ").dt.days\n",
    "\n",
    "# Reorder and rename\n",
    "summary_df = summary_df.reset_index()[['Unit_ID', 'days_between', 'first_Cluster_sessID', 'last_Cluster_sessID']]\n",
    "summary_df.columns = ['Unit_ID', 'days_between', 'first', 'last']\n",
    "\n",
    "# Remove if on the same day?\n",
    "summary_df=summary_df[summary_df['days_between']>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Cluster0\", \"Cluster1\", \"Cluster2\", \"Cluster0\", \"Cluster1\", \"Cluster2\"]\n",
    "\n",
    "a=len(summary_df[(summary_df['first'] == '0') & (summary_df['last'] == '0')].index.tolist())\n",
    "b=len(summary_df[(summary_df['first'] == '0') & (summary_df['last'] == '1')].index.tolist())\n",
    "c=len(summary_df[(summary_df['first'] == '0') & (summary_df['last'] == '2')].index.tolist())\n",
    "d=len(summary_df[(summary_df['first'] == '1') & (summary_df['last'] == '0')].index.tolist())\n",
    "e=len(summary_df[(summary_df['first'] == '1') & (summary_df['last'] == '1')].index.tolist())\n",
    "f=len(summary_df[(summary_df['first'] == '1') & (summary_df['last'] == '2')].index.tolist())\n",
    "g=len(summary_df[(summary_df['first'] == '2') & (summary_df['last'] == '0')].index.tolist())\n",
    "h=len(summary_df[(summary_df['first'] == '2') & (summary_df['last'] == '1')].index.tolist())\n",
    "i=len(summary_df[(summary_df['first'] == '2') & (summary_df['last'] == '2')].index.tolist())\n",
    "\n",
    "# Indexes in the labels list\n",
    "source = [0, 0, 0, 1, 1, 1, 2, 2, 2]\n",
    "target = [3, 4, 5, 3, 4, 5, 3, 4, 5]\n",
    "value  = [a, b, c, d, e, f, g, h, i]\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node=dict(\n",
    "        label=labels,\n",
    "        pad=10,\n",
    "        thickness=20\n",
    "    ),\n",
    "    link=dict(source=source, target=target, value=value)\n",
    ")])\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    font_size=12,\n",
    "    width=300,  # Width of the figure\n",
    "    height=400,  # Height of the figure\n",
    "    title= f\"{np.round(np.mean(summary_df['days_between']),1)} +/- {np.round(np.std(summary_df['days_between']) / np.sqrt(len(summary_df['days_between'])), 1)} days<br>n = {len(summary_df)}<br>{np.round((a+e+i)/35*100)} % in same cluster\"\n",
    ")\n",
    "plt.tight_layout()\n",
    "fig.write_image(f\"C:/Users/Manip2/Documents/Manuscripts/Figures_PNASreviews/Figure1_revised/{NrSubtype}_{DataType}_cluster_stability.svg\")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a new point on the umap & get its cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_point=np.array([0, .1, .1, .1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_point_umap = umap_model.transform(new_point.reshape(1, -1))\n",
    "new_label, new_prob = hdbscan.approximate_predict(hdbscan_model, new_point_umap)\n",
    "\n",
    "# 6. Plot\n",
    "plt.figure(figsize=(3, 3))\n",
    "\n",
    "# Plot existing clustered points\n",
    "sns.scatterplot(x='UMAP1', y='UMAP2', hue='Cluster', palette='tab20', data=embedding_df, s=30, edgecolor='k', legend=False)\n",
    "\n",
    "# Plot the new point\n",
    "plt.scatter(new_point_umap[:, 0], new_point_umap[:, 1], c='red', s=100, marker='X', edgecolor='k')\n",
    "plt.title(f'Cluster n°{new_label[0]}')\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuron distances relative to cluster ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = pd.read_excel(f'{Path(dpath)}/VigStates_Global_cluster.xlsx', index_col=0)\n",
    "df_cluster = df_cluster[df_cluster['NeuronType'] == NrSubtype]\n",
    "df_cluster['ClusterHDBSCAN'] = '0' if NrSubtype == 'L2_3_mice' else df_cluster['ClusterHDBSCAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_c = df_cluster.drop_duplicates(subset='Unit_ID', keep='first')\n",
    "df_cluster_c = df_cluster_c.dropna(subset=['ClusterHDBSCAN'])\n",
    "\n",
    "def extract_xy(coord_str):\n",
    "    val = ast.literal_eval(coord_str)\n",
    "    # Handle nested list: [[x], [y]]\n",
    "    if isinstance(val[0], list):\n",
    "        x, y = val[0][0], val[1][0]\n",
    "    else:\n",
    "        x, y = val[0], val[1]\n",
    "    return pd.Series([x, y])\n",
    "\n",
    "df_cluster_c[['x', 'y']] = df_cluster_c['UnitLocation'].apply(extract_xy)\n",
    "\n",
    "within_dists_all = []\n",
    "within_dists_c0 = []\n",
    "within_dists_c1 = []\n",
    "within_dists_c2 = []\n",
    "between_dists_all = []\n",
    "between_dists_c0 = []\n",
    "between_dists_c1 = []\n",
    "between_dists_c2 = []\n",
    "\n",
    "for indiv_id, group in df_cluster_c.groupby('Mice'):\n",
    "    coords = group[['x', 'y']].values\n",
    "    labels = group['ClusterHDBSCAN'].values\n",
    "    dist_matrix = squareform(pdist(coords))    \n",
    "    for i in range(len(group)):\n",
    "        for j in range(i + 1, len(group)):\n",
    "            d = dist_matrix[i, j]\n",
    "            if labels[i] == labels[j]:\n",
    "                within_dists_all.append(d)\n",
    "                if labels[i] == 0:\n",
    "                    within_dists_c0.append(d)\n",
    "                elif labels[i] == 1:\n",
    "                    within_dists_c1.append(d)\n",
    "                elif labels[i] == 2:\n",
    "                    within_dists_c2.append(d)\n",
    "            else:\n",
    "                between_dists_all.append(d)\n",
    "                if labels[i] == 0:\n",
    "                    between_dists_c0.append(d)\n",
    "                elif labels[i] == 1:\n",
    "                    between_dists_c1.append(d)\n",
    "                elif labels[i] == 2:\n",
    "                    between_dists_c2.append(d)\n",
    "\n",
    "# --- Plot distributions ---\n",
    "fig, axes = plt.subplots(1, 4, figsize=(14, 3))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "sns.histplot(between_dists_c0, bins=30, binrange=(0, 600),color='black', label='0-others', kde=True, stat=\"density\", alpha=0.5, kde_kws={'bw_adjust': 0.5})\n",
    "sns.histplot(within_dists_c0, bins=30, binrange=(0, 600),color='orange', label='0-0', kde=True, stat=\"density\", kde_kws={'bw_adjust': 0.5})\n",
    "plt.legend()\n",
    "plt.xlabel(\"Distance in pixels\")\n",
    "plt.ylabel(\"Density\")\n",
    "stat, p =ks_2samp(within_dists_c0, between_dists_c0)\n",
    "plt.title(f\"C0 = K-S Test: p = {p:.2f}\")\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "sns.histplot(between_dists_c1, bins=30,binrange=(0, 600), color='black', label='1-others', kde=True, stat=\"density\", alpha=0.5, kde_kws={'bw_adjust': 0.5})\n",
    "sns.histplot(within_dists_c1, bins=30, binrange=(0, 600),color='blue', label='1-1', kde=True, stat=\"density\", alpha=0.5, kde_kws={'bw_adjust': 0.5})\n",
    "plt.legend()\n",
    "plt.xlabel(\"Distance in pixels\")\n",
    "plt.ylabel(\"Density\")\n",
    "stat, p =ks_2samp(within_dists_c1, between_dists_c1)\n",
    "plt.title(f\"C1 = K-S Test: p = {p:.2f}\")\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "sns.histplot(between_dists_c2, bins=30, binrange=(0, 600),color='black', label='2-others', kde=True, stat=\"density\", alpha=0.5, kde_kws={'bw_adjust': 0.5})\n",
    "sns.histplot(within_dists_c2, bins=30, binrange=(0, 600), color='purple', label='2-2', kde=True, stat=\"density\", alpha=0.5, kde_kws={'bw_adjust': 0.5})\n",
    "plt.legend()\n",
    "plt.xlabel(\"Distance in pixels\")\n",
    "plt.ylabel(\"Density\")\n",
    "stat, p =ks_2samp(within_dists_c2, between_dists_c2)\n",
    "plt.title(f\"C2 = K-S Test: p = {p:.2f}\")\n",
    "\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "sns.histplot(between_dists_all, bins=30, binrange=(0, 600),color='black', label='between', kde=True, stat=\"density\", alpha=0.5, kde_kws={'bw_adjust': 0.5})\n",
    "sns.histplot(within_dists_all, bins=30, binrange=(0, 600),color='red', label='within', kde=True, stat=\"density\", kde_kws={'bw_adjust': 0.5})\n",
    "plt.legend()\n",
    "plt.xlabel(\"Distance in pixels\")\n",
    "plt.ylabel(\"Density\")\n",
    "stat, p =ks_2samp(within_dists_all, between_dists_all)\n",
    "plt.title(f\"All = K-S Test: p = {p:.2f}\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#dip, pval = diptest.diptest(np.array(within_dists_c1))\n",
    "#print(f\"C1 = Bimodal distribution Test: p = {pval:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f\"C:/Users/Manip2/Documents/Manuscripts/Figures_PNASreviews/Figure1_revised/{NrSubtype}_distance_percluster.svg\", format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total activity (all vig states combined) for each cluster\n",
    "datatype=[ 'NormalizedAUC_calcium','DeconvSpikeMeanActivity', 'SpikeActivityHz', 'CalciumActivity']\n",
    "fig, axes = plt.subplots(1, len(datatype), figsize=(8, 2))\n",
    "\n",
    "for d,dt in enumerate(datatype): \n",
    "    data_ = df_cluster.pivot_table(index='Unit_ID', columns='ClusterHDBSCAN', values=dt, aggfunc='mean')   \n",
    "\n",
    "    means = data_.mean()\n",
    "    errors = data_.apply(lambda x: sem(x, nan_policy='omit'))\n",
    "    plt.subplot(1,len(datatype),d+1)\n",
    "\n",
    "    x_pos = np.arange(len(data_.columns))\n",
    "    plt.bar(x_pos, means, yerr=errors, capsize=5, color='lightblue', edgecolor='black')\n",
    "\n",
    "    # Plot individual dots\n",
    "    for i, col in enumerate(data_.columns):\n",
    "        y = data_[col].dropna()\n",
    "        x = np.random.normal(loc=x_pos[i], scale=0.05, size=len(y))  # jitter to avoid overlap\n",
    "        plt.scatter(x, y, color='black', alpha=0.7, s=30)\n",
    "\n",
    "    plt.ylabel(dt)\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f\"C:/Users/Manip2/Documents/Manuscripts/Figures_PNASreviews/Figure1_revised/{NrSubtype}_totactivity_percluster.svg\", format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Total activity (all vig states combined) for each cluster\n",
    "datatype=[ 'NormalizedAUC_calcium','DeconvSpikeMeanActivity', 'SpikeActivityHz', 'CalciumActivity']\n",
    "xl=[30,0.02,0.3,1.5]\n",
    "fig, axes = plt.subplots(1, len(datatype), figsize=(10, 3))\n",
    "\n",
    "statt=\"count\" #density or count\n",
    "\n",
    "for d,dt in enumerate(datatype): \n",
    "    data_ = df_cluster.pivot_table(index='Unit_ID', columns='ClusterHDBSCAN', values=dt, aggfunc='mean')   \n",
    "\n",
    "    means = data_.mean()\n",
    "    errors = data_.apply(lambda x: sem(x, nan_policy='omit'))\n",
    "\n",
    "    plt.subplot(1,len(datatype),d+1)\n",
    "    sns.histplot(data_, bins=20, binrange=(0, xl[d]),color='black', kde=True, alpha=0.5, kde_kws={'bw_adjust': 0.5}, stat=statt)\n",
    "    plt.xlabel(dt)\n",
    "    plt.ylabel(statt)\n",
    "    plt.xscale('linear') #linear, log, symlog, logit\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Force create legend from hue column\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    if not handles:\n",
    "        handles = [mpatches.Patch(color=sns.color_palette()[i], label=group) \n",
    "                for i, group in enumerate(data_.columns)]\n",
    "        plt.legend(handles=handles, title='Cluster')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f\"C:/Users/Manip2/Documents/Manuscripts/Figures_PNASreviews/Figure1_revised/{NrSubtype}_Distrib{statt}Totactivity_percluster.svg\", format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity per vig states for each cluster\n",
    "datatype=[ 'NormalizedAUC_calcium','DeconvSpikeMeanActivity', 'SpikeActivityHz', 'CalciumActivity']\n",
    "fig, axes = plt.subplots(1, len(datatype), figsize=(12, 3))\n",
    "\n",
    "for d,dt in enumerate(datatype):\n",
    "        \n",
    "    df = df_cluster.pivot_table(index='Unit_ID', columns=['ClusterHDBSCAN', 'Substate'], values=dt, aggfunc='mean') \n",
    "    try : df = df.drop(columns='undefined', level=1)\n",
    "    except: pass\n",
    "    try : df = df.drop(columns='IS', level=1)\n",
    "    except: pass\n",
    "\n",
    "    desired_order2=['AW','QW', 'NREM', 'REM']\n",
    "    df = df.loc[:, df.columns.reindex(desired_order2, level=1)[0]]\n",
    "    plt.subplot(1,len(datatype),d+1)\n",
    "    # Compute means and SEM\n",
    "    means = df.mean()\n",
    "    errors = df.apply(lambda x: sem(x, nan_policy='omit'))\n",
    "\n",
    "    # Setup bar positions\n",
    "    n_groups = len(df.columns.levels[0])  # Number of groups (e.g., Group1, Group2)\n",
    "    n_subcats = len(df.columns.levels[1])  # Number of subcategories (e.g., A, B, C, D)\n",
    "    bar_width = 0.35\n",
    "    group_width = n_subcats * bar_width + 0.2  # total width per group\n",
    "\n",
    "    # X positions per bar\n",
    "    positions = []\n",
    "    tick_labels = []\n",
    "    xtick_positions = []\n",
    "\n",
    "    # Plot bars and lines connecting individual points for all subcategories within each group\n",
    "    for g_idx, group in enumerate(df.columns.levels[0]):\n",
    "        group_cols = [col for col in df.columns if col[0] == group]\n",
    "        group_means = means[group_cols]\n",
    "        group_errors = errors[group_cols]\n",
    "        group_x = np.arange(len(group_cols)) * bar_width + g_idx * group_width\n",
    "\n",
    "        # Plot bars for the group\n",
    "        plt.bar(group_x, group_means, yerr=group_errors, capsize=4, width=bar_width,\n",
    "            color='#51aeae', edgecolor='black')\n",
    "\n",
    "        # Plot lines connecting corresponding individuals for each pair of subcategories\n",
    "        for i in range(len(group_cols) - 1):  # Loop through subcategories to connect each pair\n",
    "            # Get the data for the two subcategories\n",
    "            group1_values = df[group_cols[i]].dropna()\n",
    "            group2_values = df[group_cols[i + 1]].dropna()\n",
    "\n",
    "            # Loop through corresponding individual values in the two subcategories and plot lines between them\n",
    "            for j in range(min(len(group1_values), len(group2_values))):\n",
    "                plt.plot([group_x[i], group_x[i + 1]], \n",
    "                        [group1_values.iloc[j], group2_values.iloc[j]], \n",
    "                        color='black', alpha=0.6, lw=1, marker='o', markersize=1)\n",
    "\n",
    "        # Store positions for ticks\n",
    "        positions.extend(group_x)\n",
    "        tick_labels.extend([col[1] for col in group_cols])\n",
    "        xtick_positions.extend(group_x)\n",
    "\n",
    "    axes[d].set_xticks(xtick_positions)\n",
    "    axes[d].set_xticklabels(tick_labels, rotation=45)\n",
    "\n",
    "    # Add group labels (Group1, Group2) above bars\n",
    "    group_centers = [i * group_width + (n_subcats - 1) * bar_width / 2 for i in range(n_groups)]\n",
    "    for i, label in enumerate(df.columns.levels[0]):\n",
    "        axes[d].text(group_centers[i], axes[d].get_ylim()[1]*1.02, label, ha='center', va='bottom', fontsize=12,)\n",
    "\n",
    "    # Style\n",
    "    axes[d].set_ylabel(dt)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f\"C:/Users/Manip2/Documents/Manuscripts/Figures_PNASreviews/Figure1_revised/{NrSubtype}_vigstactivity_percluster.svg\", format='svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
