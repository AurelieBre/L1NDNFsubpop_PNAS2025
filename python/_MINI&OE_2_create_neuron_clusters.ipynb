{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import umap\n",
    "import hdbscan\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from IPython.display import display\n",
    "from ipyfilechooser import FileChooser\n",
    "%matplotlib widget\n",
    "from scipy.stats import zscore\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.manifold import Isomap\n",
    "import networkx as nx\n",
    "from scipy.stats import entropy\n",
    "import warnings\n",
    "import pickle\n",
    "import matplotlib.cm as cm\n",
    "import ast\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import ks_2samp\n",
    "import diptest\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # tries to retrieve dpath either from a previous run or from a previous notebook\n",
    "    %store -r dpath\n",
    "except:\n",
    "    print(\"the path was not defined in store\")\n",
    "    #dpath = \"/Users/mb/Documents/Syntuitio/AudreyHay/PlanB/ExampleRedLines/2022_08_06/13_30_01/My_V4_Miniscope/\"\n",
    "    dpath = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/\"\n",
    "\n",
    "fc1 = FileChooser(dpath,select_default=True, show_only_dirs = True, title = \"<b>Folder with videos</b>\")\n",
    "display(fc1)\n",
    "\n",
    "# Sample callback function\n",
    "def update_my_folder(chooser):\n",
    "    global dpath\n",
    "    dpath = chooser.selected\n",
    "    %store dpath\n",
    "    return \n",
    "\n",
    "# Register callback function\n",
    "fc1.register_callback(update_my_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    combined_df = pd.read_excel(f'{dpath}/VigStates_Global.xlsx', index_col=0)\n",
    "except:\n",
    "    with open(f'{dpath}/VigStates_Global.pkl', 'rb') as pickle_file:\n",
    "        combined_df = pickle.load(pickle_file)\n",
    "        \n",
    "desired_order = ['AW','QW', 'NREM', 'IS', 'REM', 'undefined']   \n",
    "NrSubtype='L1NDNF_mice' #['L1NDNF_mice','L2_3_mice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Unique_Unit'] = combined_df['Unique_Unit'].astype(int).astype(str)\n",
    "combined_df['UnitNumber'] = combined_df['UnitNumber'].astype(str)\n",
    "combined_df['UnitValue'] = combined_df['UnitValue'].astype(str)\n",
    "combined_df['Unit_ID'] = combined_df['Mice'] + combined_df['Unique_Unit']\n",
    "combined_df['Substate_ID'] = combined_df['Mice'] + combined_df['Session'] + combined_df['Substate'] + combined_df['SubstateNumber'].astype(str)\n",
    "combined_df['Session_ID'] = combined_df['Session_Date'] + '_' + combined_df['Session_Time'].astype(str)\n",
    "combined_df['NormalizedAUC_calcium'] = combined_df['AUC_calcium'] / combined_df['DurationSubstate']\n",
    "\n",
    "combined_df_Drug=combined_df.copy()\n",
    "combined_df_Drug = combined_df_Drug[combined_df_Drug['Drug'] == 'baseline']\n",
    "combined_df_Drug = combined_df_Drug[combined_df_Drug['NeuronType'] == NrSubtype]\n",
    "\n",
    "DataType='NormalizedAUC_calcium' # NormalizedAUC_calcium, SpikeActivityHz , DeconvSpikeMeanActivity, CalciumActivity\n",
    "\n",
    "data_origin = combined_df_Drug.pivot_table(index='Unit_ID', columns='Substate', values=DataType, aggfunc='mean')   \n",
    "try : data_origin = data_origin[desired_order]\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del data_origin['undefined']\n",
    "except : pass\n",
    "del data_origin['IS']\n",
    "data_origin=data_origin.dropna(axis=0)\n",
    "vigst_nb=np.shape(data_origin)[1]\n",
    "print(np.shape(data_origin))\n",
    "data=data_origin.div(data_origin.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDBSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors= 90 #8\n",
    "min_dist=.9 #.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=2, random_state=None) \n",
    "#n_neighbors=15: range 2 to 100. Controls the balance between local and global structure \n",
    "#n_components=2 : range 2 to 100.Reduces the data to 2D for visualization \n",
    "#min_dist=0.1: Controls the spread of points. Smaller values emphasize local structure\n",
    "X_umap = umap_model.fit_transform(data)\n",
    "\n",
    "hdbscan_model = hdbscan.HDBSCAN(min_cluster_size=15, min_samples=1, prediction_data=True).fit(X_umap)\n",
    "embedding_df = pd.DataFrame(X_umap, columns=['UMAP1', 'UMAP2'])\n",
    "labels = hdbscan_model.fit_predict(X_umap)\n",
    "embedding_df['Cluster'] = labels\n",
    "\n",
    "# Plotting the results\n",
    "\n",
    "cmap = sns.diverging_palette(10, 133, as_cmap=True)\n",
    "plt.close()\n",
    "plt.figure(figsize=(14, 3))\n",
    "\n",
    "# Plot Results\n",
    "plt.subplot(1,5,1)\n",
    "sns.scatterplot(x='UMAP1', y='UMAP2', hue='Cluster', palette='tab20', data=embedding_df, s=30, edgecolor='k', legend=False)\n",
    "plt.title('HDBSCAN ')\n",
    "\n",
    "plt.subplot(1,5,2)\n",
    "sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_df, s=30, edgecolor='k', hue=data['AW'].values, palette='rainbow', legend=False)\n",
    "plt.title('AW')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "\n",
    "plt.subplot(1,5,3)\n",
    "sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_df, s=30, edgecolor='k', hue=data['QW'].values, palette='rainbow', legend=False)\n",
    "plt.title('QW')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "\n",
    "plt.subplot(1,5,4)\n",
    "sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_df, s=30, edgecolor='k', hue=data['NREM'].values, palette='rainbow', legend=False)\n",
    "plt.title('NREM')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "\n",
    "plt.subplot(1,5,5)\n",
    "ax=sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_df, s=30, edgecolor='k', hue=data['REM'].values, palette='rainbow', legend=False)\n",
    "plt.title('REM')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0)\n",
    "plt.colorbar(plt.cm.ScalarMappable(cmap='rainbow'), cax=cax)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#X, color = make_swiss_roll(n_samples=2000, noise=0.1) ## Generate synthetic manifold data (Swiss Roll)\n",
    "X = X_umap\n",
    "\n",
    "# ---- Assumption 1: Uniform distribution (check density variation) ----\n",
    "def check_uniformity(X, n_bins=30):\n",
    "    hist, _ = np.histogramdd(X, bins=n_bins)\n",
    "    hist = hist.flatten()\n",
    "    hist = hist[hist > 0]\n",
    "    hist = hist / np.sum(hist)\n",
    "    ent = entropy(hist)\n",
    "    print(f\"Entropy of distribution: {ent:.2f} (higher = more uniform)\")\n",
    "    \n",
    "check_uniformity(X)\n",
    "\n",
    "# ---- Assumption 2: Locally Euclidean (constant metric) ----\n",
    "def check_local_metric(X, n_neighbors=n_neighbors):\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors).fit(X)\n",
    "    distances, indices = nbrs.kneighbors(X)\n",
    "\n",
    "    # Compute ratio of distances between nearest neighbor and farthest neighbor in local patch\n",
    "    ratios = distances[:, -1] / (distances[:, 1] + 1e-10)\n",
    "    print(f\"Avg. local distance ratio (max/min): {np.mean(ratios):.2f} (closer to 1 = more Euclidean-like)\")\n",
    "    \n",
    "check_local_metric(X)\n",
    "\n",
    "# ---- Assumption 3: Locally connected ----\n",
    "def check_local_connectivity(X, n_neighbors=n_neighbors):\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors).fit(X)\n",
    "    graph = nbrs.kneighbors_graph(X).tocoo()\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    for i, j in zip(graph.row, graph.col):\n",
    "        G.add_edge(i, j)\n",
    "    \n",
    "    n_components = nx.number_connected_components(G)\n",
    "    print(f\"Connected Components in k-NN graph: {n_components} (should be 1 for full connectivity)\")\n",
    "\n",
    "check_local_connectivity(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f\"C:/Users/Manip2/Documents/Manuscripts/{NrSubtype}_UMAPcluster.svg\", format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouse repartition in cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.scatterplot(x='UMAP1', y='UMAP2', data=embedding_df, s=30, edgecolor='k', hue=data.index.str.replace(r'\\d+', '', regex=True).values, palette='tab20', legend=True)\n",
    "plt.title('Mice')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "plt.legend(loc='upper left')#, bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f\"C:/Users/Manip2/Documents/Manuscripts/{NrSubtype}_UMAPcluster_permouse.svg\", format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate proportions\n",
    "data['Mice'] = data.index.str.replace(r'\\d+', '', regex=True).values\n",
    "data['Cluster'] = labels\n",
    "proportions = data.groupby([ 'Mice', 'Cluster']).size().unstack(fill_value=0)\n",
    "#proportions = proportions.div(proportions.sum(axis=1), axis=0)*100\n",
    "\n",
    "# Plot\n",
    "proportions.plot(kind='bar', stacked=True, figsize=(4, 4), colormap='tab20')\n",
    "plt.ylabel('Cell Count')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f\"C:/Users/Manip2/Documents/Manuscripts/{NrSubtype}_CellCountCluster_permouse.svg\", format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(set(labels)) > 1 and -1 not in set(labels):\n",
    "    score = silhouette_score(embedding_df, labels)\n",
    "    print(f\"Silhouette Score: {score:.2f}.  Notes: 1 → Well-clustered. 0 → Overlapping clusters. -1 → Misclassified samples.\")\n",
    "else:\n",
    "    print(\"Silhouette Score cannot be calculated. Check for multiple clusters.\")\n",
    "    \n",
    "\n",
    "if len(set(labels)) > 1 and -1 not in set(labels):\n",
    "    db_score = davies_bouldin_score(embedding_df, labels)\n",
    "    print(f\"Davies-Bouldin Index: {db_score:.2f}.   Notes: Lower values indicate better clustering.\")\n",
    "else:\n",
    "    print(\"Davies-Bouldin Index cannot be calculated. Check for multiple clusters.\")\n",
    "\n",
    "\n",
    "if len(set(labels)) > 1 and -1 not in set(labels):\n",
    "    ch_score = calinski_harabasz_score(embedding_df, labels)\n",
    "    print(f\"Calinski-Harabasz Index: {ch_score:.2f}.    Notes: Higher values indicate better clustering.\")\n",
    "else:\n",
    "    print(\"Calinski-Harabasz Index cannot be calculated. Check for multiple clusters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_origin['ClusterHDBSCAN'] = labels\n",
    "grouped = data_origin.groupby('ClusterHDBSCAN')\n",
    "means = grouped[data_origin.columns[:vigst_nb]].mean()\n",
    "sems = grouped[data_origin.columns[:vigst_nb]].sem()\n",
    "\n",
    "# Plot\n",
    "ax = means.plot(kind='bar', yerr=sems, capsize=4, figsize=(4, 4))\n",
    "plt.title('Cluster HDBSCAN')\n",
    "plt.ylabel('Average AUC')\n",
    "plt.xlabel('Cluster')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(grouped.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f\"C:/Users/Manip2/Documents/Manuscripts/{NrSubtype}_AUC_percluster.svg\", format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "# Generate a color for each group\n",
    "groups = list(grouped.groups.keys())\n",
    "colors = cm.get_cmap('Dark2', len(groups))\n",
    "\n",
    "# Loop through each group\n",
    "for idx, (name, group) in enumerate(grouped):\n",
    "    color = colors(idx)  # assign a color based on group index\n",
    "    for i in range(len(group)):\n",
    "        plt.plot(group.columns[:-1], group.iloc[i][:-1], color=color, alpha=0.5, linewidth=2)\n",
    "\n",
    "plt.title('Cluster HDBSCAN')\n",
    "plt.ylabel('AUC')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(grouped.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f\"C:/Users/Manip2/Documents/Manuscripts/{NrSubtype}_AUC_percluster&cells.svg\", format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(combined_df, data_origin['ClusterHDBSCAN'], on='Unit_ID', how='outer') \n",
    "filenameOutAUC = f'{dpath}/VigStates_Global_cluster.xlsx'\n",
    "merged.to_excel(filenameOutAUC)\n",
    "\n",
    "filenameOut = f'{dpath}/VigStates_Global_cluster.pkl'\n",
    "with open(filenameOut, 'wb') as pickle_file:\n",
    "    pickle.dump(merged, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped=combined_df_Drug.groupby(['Unit_ID', 'Session_ID', 'Substate'])['NormalizedAUC_calcium'].mean()\n",
    "grouped = grouped.reset_index()\n",
    "grouped2=grouped.pivot_table(index=[grouped['Unit_ID'], grouped['Session_ID']], columns='Substate', values='NormalizedAUC_calcium')\n",
    "try : grouped2 = grouped2[desired_order]\n",
    "except: pass\n",
    "del grouped2['IS']\n",
    "#del grouped2['undefined']\n",
    "\n",
    "d=[]\n",
    "test=pd.DataFrame(d, columns=['Cluster_sessID'])\n",
    "\n",
    "for i in np.arange(len(grouped2)):\n",
    "    new_point=np.array(grouped2.iloc[i]).astype(float)\n",
    "    if not np.sum(np.isnan(new_point)): \n",
    "        new_point_umap = umap_model.transform(new_point.reshape(1, -1))\n",
    "        new_label, new_prob = hdbscan.approximate_predict(hdbscan_model, new_point_umap)\n",
    "        test.loc[i,'Cluster_sessID']=new_label[0].astype(str)\n",
    "    else:\n",
    "        test.loc[i,'Cluster_sessID']=None\n",
    "grouped2['Cluster_sessID'] = test['Cluster_sessID'].values\n",
    "\n",
    "grouped3 = grouped2.reset_index()\n",
    "grouped3 = grouped3.drop(columns=['AW', 'QW', 'NREM', 'REM'])\n",
    "grouped3 = grouped3.dropna(subset=['Cluster_sessID'])\n",
    "grouped3 = grouped3[grouped3['Unit_ID'].duplicated(keep=False)] #remove units that only appears in one sessionID\n",
    "\n",
    "\n",
    "# ⏱ Convert to datetime\n",
    "grouped3['Session_ID'] = pd.to_datetime(grouped3['Session_ID'], format='%Y-%m-%d_%H-%M-%S')\n",
    "df_sorted = grouped3.sort_values(['Unit_ID', 'Session_ID'])\n",
    "grouped = df_sorted.groupby('Unit_ID')\n",
    "\n",
    "# Build summary DataFrame\n",
    "summary_df = grouped.agg(\n",
    "    first_date=('Session_ID', 'first'),\n",
    "    last_date=('Session_ID', 'last'),\n",
    "    first_Cluster_sessID=('Cluster_sessID', 'first'),\n",
    "    last_Cluster_sessID=('Cluster_sessID', 'last')\n",
    ")\n",
    "\n",
    "# Calculate number of days between first and last\n",
    "summary_df['days_between'] = (\n",
    "    summary_df['last_date'].dt.floor('D') - summary_df['first_date'].dt.floor('D')\n",
    ").dt.days\n",
    "\n",
    "# Reorder and rename\n",
    "summary_df = summary_df.reset_index()[['Unit_ID', 'days_between', 'first_Cluster_sessID', 'last_Cluster_sessID']]\n",
    "summary_df.columns = ['Unit_ID', 'days_between', 'first', 'last']\n",
    "\n",
    "# Remove if on the same day?\n",
    "summary_df=summary_df[summary_df['days_between']>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "labels = [\"Cluster0\", \"Cluster1\", \"Cluster2\", \"Cluster0\", \"Cluster1\", \"Cluster2\"]\n",
    "\n",
    "a=len(summary_df[(summary_df['first'] == '0') & (summary_df['last'] == '0')].index.tolist())\n",
    "b=len(summary_df[(summary_df['first'] == '0') & (summary_df['last'] == '1')].index.tolist())\n",
    "c=len(summary_df[(summary_df['first'] == '0') & (summary_df['last'] == '2')].index.tolist())\n",
    "d=len(summary_df[(summary_df['first'] == '1') & (summary_df['last'] == '0')].index.tolist())\n",
    "e=len(summary_df[(summary_df['first'] == '1') & (summary_df['last'] == '1')].index.tolist())\n",
    "f=len(summary_df[(summary_df['first'] == '1') & (summary_df['last'] == '2')].index.tolist())\n",
    "g=len(summary_df[(summary_df['first'] == '2') & (summary_df['last'] == '0')].index.tolist())\n",
    "h=len(summary_df[(summary_df['first'] == '2') & (summary_df['last'] == '1')].index.tolist())\n",
    "i=len(summary_df[(summary_df['first'] == '2') & (summary_df['last'] == '2')].index.tolist())\n",
    "\n",
    "# Indexes in the labels list\n",
    "source = [0, 0, 0, 1, 1, 1, 2, 2, 2]\n",
    "target = [3, 4, 5, 3, 4, 5, 3, 4, 5]\n",
    "value  = [a, b, c, d, e, f, g, h, i]\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node=dict(label=labels),\n",
    "    link=dict(source=source, target=target, value=value)\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    font_size=12,\n",
    "    width=300,  # Width of the figure\n",
    "    height=400,  # Height of the figure\n",
    "    title= f\"{np.round(np.mean(summary_df['days_between']),1)} +/- {np.round(np.std(summary_df['days_between']) / np.sqrt(len(summary_df['days_between'])), 1)} days<br>n = {len(summary_df)}<br>{np.round((a+e+i)/35*100)} % in same cluster\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f\"C:/Users/Manip2/Documents/Manuscripts/{NrSubtype}_cluster_stability.svg\", format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a new point on the umap & get its cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_point=np.array([0, .25, .25, .5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_point_umap = umap_model.transform(new_point.reshape(1, -1))\n",
    "new_label, new_prob = hdbscan.approximate_predict(hdbscan_model, new_point_umap)\n",
    "\n",
    "# 6. Plot\n",
    "plt.figure(figsize=(3, 3))\n",
    "\n",
    "# Plot existing clustered points\n",
    "sns.scatterplot(x='UMAP1', y='UMAP2', hue='Cluster', palette='tab20', data=embedding_df, s=30, edgecolor='k', legend=False)\n",
    "\n",
    "# Plot the new point\n",
    "plt.scatter(new_point_umap[:, 0], new_point_umap[:, 1], c='red', s=100, marker='X', edgecolor='k')\n",
    "plt.title(f'Cluster n°{new_label[0]}')\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuron distances relative to cluster ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = pd.read_excel(f'{Path(dpath)}/VigStates_Global_cluster.xlsx', index_col=0)\n",
    "df_cluster = df_cluster[df_cluster['NeuronType'] == 'L1NDNF_mice']\n",
    "df_cluster_c = df_cluster.drop_duplicates(subset='Unit_ID', keep='first')\n",
    "df_cluster_c = df_cluster_c.dropna(subset=['ClusterHDBSCAN'])\n",
    "\n",
    "def extract_xy(coord_str):\n",
    "    val = ast.literal_eval(coord_str)\n",
    "    # Handle nested list: [[x], [y]]\n",
    "    if isinstance(val[0], list):\n",
    "        x, y = val[0][0], val[1][0]\n",
    "    else:\n",
    "        x, y = val[0], val[1]\n",
    "    return pd.Series([x, y])\n",
    "\n",
    "df_cluster_c[['x', 'y']] = df_cluster_c['UnitLocation'].apply(extract_xy)\n",
    "\n",
    "within_dists_all = []\n",
    "within_dists_c0 = []\n",
    "within_dists_c1 = []\n",
    "within_dists_c2 = []\n",
    "between_dists_all = []\n",
    "between_dists_c0 = []\n",
    "between_dists_c1 = []\n",
    "between_dists_c2 = []\n",
    "\n",
    "for indiv_id, group in df_cluster_c.groupby('Mice'):\n",
    "    coords = group[['x', 'y']].values\n",
    "    labels = group['ClusterHDBSCAN'].values\n",
    "    dist_matrix = squareform(pdist(coords))    \n",
    "    for i in range(len(group)):\n",
    "        for j in range(i + 1, len(group)):\n",
    "            d = dist_matrix[i, j]\n",
    "            if labels[i] == labels[j]:\n",
    "                within_dists_all.append(d)\n",
    "                if labels[i] == 0:\n",
    "                    within_dists_c0.append(d)\n",
    "                elif labels[i] == 1:\n",
    "                    within_dists_c1.append(d)\n",
    "                elif labels[i] == 2:\n",
    "                    within_dists_c2.append(d)\n",
    "            else:\n",
    "                between_dists_all.append(d)\n",
    "                if labels[i] == 0:\n",
    "                    between_dists_c0.append(d)\n",
    "                elif labels[i] == 1:\n",
    "                    between_dists_c1.append(d)\n",
    "                elif labels[i] == 2:\n",
    "                    between_dists_c2.append(d)\n",
    "\n",
    "# --- Plot distributions ---\n",
    "fig, axes = plt.subplots(1, 4, figsize=(14, 3))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "sns.histplot(between_dists_c0, bins=30, binrange=(0, 600),color='black', label='0-others', kde=True, stat=\"density\", alpha=0.5, kde_kws={'bw_adjust': 0.5})\n",
    "sns.histplot(within_dists_c0, bins=30, binrange=(0, 600),color='orange', label='0-0', kde=True, stat=\"density\", kde_kws={'bw_adjust': 0.5})\n",
    "plt.legend()\n",
    "plt.xlabel(\"Distance in pixels\")\n",
    "plt.ylabel(\"Density\")\n",
    "stat, p =ks_2samp(within_dists_c0, between_dists_c0)\n",
    "plt.title(f\"C0 = K-S Test: p = {p:.2f}\")\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "sns.histplot(between_dists_c1, bins=30,binrange=(0, 600), color='black', label='1-others', kde=True, stat=\"density\", alpha=0.5, kde_kws={'bw_adjust': 0.5})\n",
    "sns.histplot(within_dists_c1, bins=30, binrange=(0, 600),color='blue', label='1-1', kde=True, stat=\"density\", alpha=0.5, kde_kws={'bw_adjust': 0.5})\n",
    "plt.legend()\n",
    "plt.xlabel(\"Distance in pixels\")\n",
    "plt.ylabel(\"Density\")\n",
    "stat, p =ks_2samp(within_dists_c1, between_dists_c1)\n",
    "plt.title(f\"C1 = K-S Test: p = {p:.2f}\")\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "sns.histplot(between_dists_c2, bins=30, binrange=(0, 600),color='black', label='2-others', kde=True, stat=\"density\", alpha=0.5, kde_kws={'bw_adjust': 0.5})\n",
    "sns.histplot(within_dists_c2, bins=30, binrange=(0, 600), color='purple', label='2-2', kde=True, stat=\"density\", alpha=0.5, kde_kws={'bw_adjust': 0.5})\n",
    "plt.legend()\n",
    "plt.xlabel(\"Distance in pixels\")\n",
    "plt.ylabel(\"Density\")\n",
    "stat, p =ks_2samp(within_dists_c2, between_dists_c2)\n",
    "plt.title(f\"C2 = K-S Test: p = {p:.2f}\")\n",
    "\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "sns.histplot(between_dists_all, bins=30, binrange=(0, 600),color='black', label='between', kde=True, stat=\"density\", alpha=0.5, kde_kws={'bw_adjust': 0.5})\n",
    "sns.histplot(within_dists_all, bins=30, binrange=(0, 600),color='red', label='within', kde=True, stat=\"density\", kde_kws={'bw_adjust': 0.5})\n",
    "plt.legend()\n",
    "plt.xlabel(\"Distance in pixels\")\n",
    "plt.ylabel(\"Density\")\n",
    "stat, p =ks_2samp(within_dists_all, between_dists_all)\n",
    "plt.title(f\"All = K-S Test: p = {p:.2f}\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#dip, pval = diptest.diptest(np.array(within_dists_c1))\n",
    "#print(f\"C1 = Bimodal distribution Test: p = {pval:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(f\"C:/Users/Manip2/Documents/Manuscripts/{NrSubtype}_distance_percluster.svg\", format='svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
