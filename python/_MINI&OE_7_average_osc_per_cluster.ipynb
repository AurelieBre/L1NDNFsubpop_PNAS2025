{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats on Ca2+ imaging with miniscope and Osc\n",
    "#######################################################################################\n",
    "                            # Define Experiment type #\n",
    "#######################################################################################\n",
    "\n",
    "DrugExperiment=0 # 1 if CGP Experiment, 0 if Baseline Experiment\n",
    "\n",
    "AnalysisID='byQuarter_baseline_Shuffled' \n",
    "\n",
    "choosed_folder='Osc_2025-06-05_00_31_06_byQuarter_Shuffled_pynapple' # both baseline and CGP\n",
    "choosed_folder2='VigSt_2025-05-21_15_47_42_CGP'\n",
    "\n",
    "Local=1\n",
    "#######################################################################################\n",
    "                                # Load packages #\n",
    "#######################################################################################\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import quantities as pq\n",
    "import numpy as np\n",
    "import math \n",
    "import neo\n",
    "import json\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "import pickle\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats import sem\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import warnings\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def column_with_max_single_per_row(row):\n",
    "    max_val = row.max()  # Find the max value in the row\n",
    "    max_columns = row == max_val  # Boolean Series of columns with max value\n",
    "    \n",
    "    if max_columns.sum() > 1:\n",
    "        return 'NoPref'  # More than one column has the max value\n",
    "    else:\n",
    "        return max_columns.idxmax()  # Return the name of the column with max value\n",
    "\n",
    "def divide_keys(data):\n",
    "    it=list(data.keys())[0]\n",
    "    d=data[it]\n",
    "    data[it]=d.replace(0, np.nan)\n",
    "    for sheet in list(data.keys())[1:]: \n",
    "        data[sheet].div(data[it][sheet], axis=0)\n",
    "    del data[it]\n",
    "    return data    \n",
    "\n",
    "########################################################################\n",
    "                            # Define Directories #\n",
    "########################################################################\n",
    "\n",
    "# Specify the directory containing the Excel files\n",
    "InitialDirectory1 = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_baseline_analysis\" if Local else \"/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_baseline_analysis\" \n",
    "directory1= f'{InitialDirectory1}/{choosed_folder}'\n",
    "InitialDirectory2 =\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_CGP_analysis\" if Local else \"/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_CGP_analysis\"\n",
    "directory2= f'{InitialDirectory2}/{choosed_folder}'\n",
    "\n",
    "\n",
    "InitialDirectorY = InitialDirectory2#InitialDirectory1 if DrugExperiment==0 else InitialDirectory2\n",
    "directory3= f'{InitialDirectorY}/{choosed_folder2}'\n",
    "\n",
    "# Get the current date and time\n",
    "FolderNameSave=str(datetime.now())[:19]\n",
    "FolderNameSave = FolderNameSave.replace(\" \", \"_\").replace(\".\", \"_\").replace(\":\", \"_\")\n",
    "destination_folder= f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_global_analysis/AVG_Osc_{FolderNameSave}{AnalysisID}\" if Local else f\"/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_global_analysis/AVG_Osc_{FolderNameSave}{AnalysisID}\"\n",
    "os.makedirs(destination_folder)\n",
    "folder_to_save=Path(destination_folder)\n",
    "\n",
    "# Copy the script file to the destination folder\n",
    "source_script = \"C:/Users/Manip2/SCRIPTS/CodePythonAudrey/CodePythonAurelie/HayLabAnalysis/python/_MINI&OE_7_average_osc_per_cluster.ipynb\" if Local else \"/python/_MINI&OE_7_average_osc_per_cluster.ipynb\" \n",
    "destination_file_path = f\"{destination_folder}/_MINI&OE_7_average_osc_per_cluster.txt\"\n",
    "shutil.copy(source_script, destination_file_path)\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "                            # Do the average per cluster #\n",
    "#######################################################################################\n",
    "\n",
    "CTX=['', 'S1', 'PFC', 'S1PFC']\n",
    "CouplingO=['', 'UnCoupled', 'PreCoupled', 'PostCoupled', 'PrePostCoupled']\n",
    "Coupling1=['', 'UnCoupled', 'Coupled', 'Coupled', 'Coupled']\n",
    "Coupling=['', 'UnCoupled', 'Coupled']\n",
    "OscList=['Spdl', 'SWR']\n",
    "Drugs= ['baseline', 'CGP'] if DrugExperiment else ['baseline']\n",
    "\n",
    "NrSubtypeList=['L1NDNF_mice','L2_3_mice']\n",
    "\n",
    "\n",
    "# Load Global Table \n",
    "with open(f'{directory3}/VigStates_Global_cluster.pkl', 'rb') as pickle_file:\n",
    "    Vig_cluster_dfO = pickle.load(pickle_file)\n",
    "\n",
    "for o, Osc in enumerate(OscList): \n",
    "    \n",
    "    print(Osc, 'oscillations analysis...')\n",
    "\n",
    "    AllOscStatut=pd.DataFrame()\n",
    "    AllOscDuration=pd.DataFrame()\n",
    "    AllOscDuration2=pd.DataFrame()\n",
    "    AllGlobalSpindle=pd.DataFrame()\n",
    "    AllOscStartLocation=pd.DataFrame()\n",
    "    AllOscSWRinside=pd.DataFrame()\n",
    "    AllOscCoupling=pd.DataFrame()\n",
    "\n",
    "                \n",
    "    # Initialize an empty list to store the dataframes\n",
    "    combined_df = []\n",
    "    filtered_df=[]\n",
    "\n",
    "    ###########################################################################\n",
    "                                ##### GLOBAL #####\n",
    "    ###########################################################################\n",
    "\n",
    "    # Load Global Table \n",
    "    directorY= directory2#directory1 if DrugExperiment==0 else directory2\n",
    "    try: \n",
    "        with open(f'{directorY}/{Osc}_Global.pkl', 'rb') as pickle_file:\n",
    "            combined_df = pickle.load(pickle_file)\n",
    "    except: \n",
    "        AllMiceList=['BlackLines', 'BlueLines', 'GreenDots', 'GreenLines', 'RedLines', 'PurpleSquare', 'ThreeColDots', 'ThreeBlueCrosses']\n",
    "        combined_df = pd.DataFrame()\n",
    "        for mouse in AllMiceList:\n",
    "            try: \n",
    "                with open(f'{directorY}/{Osc}_Global_{mouse}.pkl', 'rb') as pickle_file:\n",
    "                    combined_df_mouse = pickle.load(pickle_file)\n",
    "                    combined_df = pd.concat([combined_df, combined_df_mouse], ignore_index=True)\n",
    "            except: \n",
    "                print('No data for mouse:', mouse, 'in', Osc)\n",
    "        combined_df.to_pickle(f'{directorY}/{Osc}_Global.pkl')\n",
    "        writer = pd.ExcelWriter(f'{directorY}/{Osc}_Global.xlsx')\n",
    "        combined_df.to_excel(writer)\n",
    "        writer.close()\n",
    "    \n",
    "    combined_df['Unique_Unit'] = combined_df['Unique_Unit'].astype(str)\n",
    "    combined_df['UnitNumber'] = combined_df['UnitNumber'].astype(str)\n",
    "    combined_df['UnitValue'] = combined_df['UnitValue'].astype(str)\n",
    "\n",
    "    combined_df[f'{Osc}Statut'] = combined_df[f'{Osc}Statut'].astype(str)\n",
    "\n",
    "    combined_df['Unit_ID'] = combined_df['Mice'] + combined_df['Unique_Unit']\n",
    "    combined_df['Session_ID'] = combined_df['Mice'] + '_' + combined_df['Session_Date'] + '_' + combined_df['Session_Time']\n",
    "\n",
    "    unique_count = combined_df['Unit_ID'].nunique()\n",
    "    print(unique_count, f'Total neurons in the cross-registration') \n",
    "    \n",
    "    combined_df[f'{Osc}_ID'] = combined_df['Mice'] + '_' + combined_df['Session_Date'] + '_' + combined_df['Session_Time'] + '_' +combined_df[f'{Osc}Number'].astype(str)\n",
    "    \n",
    "    unique_count = combined_df[f'{Osc}_ID'].nunique()\n",
    "    print(unique_count, f'{Osc} recorded in total')\n",
    "\n",
    "    Vig_cluster_dfO['Unit_ID'] = Vig_cluster_dfO['Mice'] + Vig_cluster_dfO['Unique_Unit']\n",
    "    merged = pd.merge(combined_df, Vig_cluster_dfO[['ClusterHDBSCAN', 'Unit_ID']].drop_duplicates(), on='Unit_ID', how='outer')\n",
    "\n",
    "    writer = pd.ExcelWriter(f'{folder_to_save}/{Osc}_Global.xlsx')\n",
    "    merged.to_excel(writer)\n",
    "    writer.close()\n",
    "    \n",
    "    ###########################################################################\n",
    "                                ##### GLOBAL #####\n",
    "    ###########################################################################\n",
    "\n",
    "    for NrSubtype in NrSubtypeList: \n",
    "\n",
    "        if NrSubtype=='L1NDNF_mice':\n",
    "            MiceList=['BlackLines', 'BlueLines', 'GreenDots', 'GreenLines', 'RedLines']\n",
    "        else:\n",
    "            MiceList=['PurpleSquare', 'ThreeColDots', 'ThreeBlueCrosses']\n",
    "\n",
    "        Data=['Ca', 'Sp']\n",
    "        for data in Data:\n",
    "            for drug in Drugs: \n",
    "                for ctx in CTX:\n",
    "                    locals()[f'{data}PSTH{Osc}_{ctx}{drug}']={}\n",
    "                    locals()[f'{data}PSTH{Osc}_UnCoupled{ctx}{drug}']={}\n",
    "                    locals()[f'{data}PSTH{Osc}_Coupled{ctx}{drug}']={}\n",
    "                    \n",
    "                    for ci, coup in enumerate(CouplingO):  \n",
    "                        coup2= Coupling1[ci]            \n",
    "                        dfsPSTH_per_sheet = locals()[f'{data}PSTH{Osc}_{coup2}{ctx}{drug}']\n",
    "                        nametofind2=f'{Osc}_{data}PSTH_{coup}{ctx}{drug}'\n",
    "                        print(nametofind2)\n",
    "                        # Recursively traverse the directory structure\n",
    "                        for directory in [directorY]:\n",
    "                            for root, _, files in os.walk(directory):\n",
    "                                for filename in files:\n",
    "                                    if filename.endswith('.pkl') and nametofind2 in filename: \n",
    "                                        if any(name in filename for name in MiceList): \n",
    "                                            # Construct the full path to the file\n",
    "                                            filepath = os.path.join(root, filename)\n",
    "                                            with open(filepath, 'rb') as pickle_file:\n",
    "                                                df = pickle.load(pickle_file)\n",
    "                                            for key, value in df.items():\n",
    "                                                if key in dfsPSTH_per_sheet:\n",
    "                                                    dfsPSTH_per_sheet[key]=pd.concat([pd.DataFrame(dfsPSTH_per_sheet[key]),pd.DataFrame(value)], ignore_index=False, axis=0)\n",
    "                                                else:\n",
    "                                                    dfsPSTH_per_sheet[key]=pd.DataFrame(value)\n",
    "\n",
    "\n",
    "        ###########################################################################\n",
    "                                ##### PREFERENCE #####\n",
    "        ###########################################################################\n",
    "        \n",
    "        print(NrSubtype, '...') \n",
    "        \n",
    "        Vig_cluster_df = Vig_cluster_dfO.copy()\n",
    "        Vig_cluster_df = Vig_cluster_df[Vig_cluster_df['NeuronType'] == NrSubtype]\n",
    "        Vig_cluster_df_Drug = Vig_cluster_df.copy()   \n",
    "        Vig_cluster_df_Drug = Vig_cluster_df_Drug[Vig_cluster_df_Drug['Drug'] == 'baseline']     \n",
    "        AllUnits = Vig_cluster_df_Drug['Unit_ID'].unique()  \n",
    "\n",
    "        Cluster0units = Vig_cluster_df_Drug[Vig_cluster_df_Drug['ClusterHDBSCAN'] == 0]['Unit_ID'].unique()\n",
    "        Cluster1units = Vig_cluster_df_Drug[Vig_cluster_df_Drug['ClusterHDBSCAN'] == 1]['Unit_ID'].unique()\n",
    "        Cluster2units = Vig_cluster_df_Drug[Vig_cluster_df_Drug['ClusterHDBSCAN'] == 2]['Unit_ID'].unique()\n",
    "        \n",
    "        # Only keep units that appears in CGP & Baseline    \n",
    "        if DrugExperiment>=1 :\n",
    "            Vig_cluster_df_Drug_CGP=Vig_cluster_df.copy()\n",
    "            Vig_cluster_df_Drug_CGP = Vig_cluster_df_Drug_CGP[Vig_cluster_df_Drug_CGP['Drug'] == 'CGP'] \n",
    "            AllCGPUnits = Vig_cluster_df_Drug_CGP['Unit_ID'].unique()\n",
    "\n",
    "            AllBaselineUnits= np.intersect1d(AllUnits,AllCGPUnits)\n",
    "            Cluster0units= np.intersect1d(Cluster0units,AllBaselineUnits)\n",
    "            Cluster1units= np.intersect1d(Cluster1units,AllBaselineUnits)\n",
    "            Cluster2units= np.intersect1d(Cluster2units,AllBaselineUnits)\n",
    " \n",
    "        for drug in Drugs: \n",
    "            \n",
    "            combined_df_Drug = combined_df.copy()\n",
    "            try:\n",
    "                combined_df_Drug = combined_df_Drug[combined_df_Drug['Drug'] == drug]\n",
    "            except: \n",
    "                combined_df_Drug=combined_df_Drug\n",
    "            \n",
    "            folder_to_save2= f'{folder_to_save}/{drug}/'\n",
    "            if NrSubtype=='L1NDNF_mice' and o==0 :\n",
    "                os.makedirs(folder_to_save2)  \n",
    "\n",
    "            if DrugExperiment==1:\n",
    "                listCluster=['AllUnits', 'AllBaselineUnits', 'Cluster0units', 'Cluster1units', 'Cluster2units'] if NrSubtype=='L1NDNF_mice' else ['AllUnits', 'AllBaselineUnits']\n",
    "            else:\n",
    "                listCluster=['AllUnits', 'Cluster0units', 'Cluster1units', 'Cluster2units'] if NrSubtype=='L1NDNF_mice' else ['AllUnits']\n",
    "\n",
    "            NbNr=pd.DataFrame()  \n",
    "            \n",
    "            fig0, axes0 = plt.subplots(len(listCluster), len(Coupling), figsize=(7, 3*len(listCluster)))      \n",
    "            axes0 = axes0.flatten() \n",
    "            ii=0\n",
    "\n",
    "            # Print the names of the sheets and their corresponding DataFrames\n",
    "            for l,List_name in enumerate(listCluster):\n",
    "                \n",
    "                thelist=locals()[f'{List_name}']\n",
    "                filtered_df = combined_df_Drug[combined_df_Drug['Unit_ID'].isin(thelist)]\n",
    "                GroupList=['AllUnits', 'SignMod', 'NoModNr', 'PsNr', 'NgNr']\n",
    "\n",
    "                if NrSubtype=='L1NDNF_mice' :#and o==0:\n",
    "                    new_folder= f\"{folder_to_save2}/{List_name}/{Osc}/\"\n",
    "                    os.makedirs(new_folder)\n",
    "\n",
    "                ###########################################################################\n",
    "                                        ##### AVERAGE PSTH #####\n",
    "                ###########################################################################\n",
    "\n",
    "                for coup in Coupling:\n",
    "                    filenameOutAVG = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_{coup}AVG&SEM.xlsx'\n",
    "                    locals()[f'excel_writerAVG{coup}']= pd.ExcelWriter(filenameOutAVG)\n",
    "\n",
    "                    filenameOutMean = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_{coup}During.xlsx'\n",
    "                    locals()[f'excel_writerMean{coup}']= pd.ExcelWriter(filenameOutMean)\n",
    "\n",
    "                    \"\"\"\n",
    "                    filenameOutMean = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_{coup}Baseline.xlsx'\n",
    "                    locals()[f'excel_writerMeanBase{coup}']= pd.ExcelWriter(filenameOutMean)\n",
    "\n",
    "                    filenameOutMean = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_{coup}Before.xlsx'\n",
    "                    locals()[f'excel_writerMeanBef{coup}']= pd.ExcelWriter(filenameOutMean)\n",
    "\n",
    "                    filenameOutMean = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_{coup}AllBefore.xlsx'\n",
    "                    locals()[f'excel_writerMeanAllBef{coup}']= pd.ExcelWriter(filenameOutMean)\n",
    "\n",
    "                    filenameOutMean = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_{coup}PSTH.xlsx'\n",
    "                    locals()[f'excel_writer{coup}']= pd.ExcelWriter(filenameOutMean)\n",
    "                    \"\"\"\n",
    "                \n",
    "                for data in Data:\n",
    "                    \n",
    "                    if data=='Ca':\n",
    "                        filenameOutPN = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_NrProportion.xlsx'\n",
    "                        excel_writerPN= pd.ExcelWriter(filenameOutPN)                 \n",
    "                                   \n",
    "\n",
    "                    for cp, coup in enumerate(Coupling):                         \n",
    "\n",
    "                        BigArray=pd.DataFrame()\n",
    "                        BigArrayBSL=pd.DataFrame()\n",
    "                        AVGArray=pd.DataFrame()\n",
    "                        AVGArrayBSL=pd.DataFrame()\n",
    "                        AVGArraybefore=pd.DataFrame()\n",
    "                        AVGArrayallbefore=pd.DataFrame()\n",
    "                        AVGArrayBSLbefore=pd.DataFrame()\n",
    "                        AVGArrayBSLallbefore=pd.DataFrame()\n",
    "                        AVGArraybaseline=pd.DataFrame()\n",
    "                        AVGArrayBSLbaseline=pd.DataFrame()\n",
    "                        \n",
    "                        for ctx in CTX:\n",
    "                            \n",
    "                            if f'{data}PSTH{Osc}_{coup}{ctx}{drug}' in locals(): #cause no ctx if uncoupled\n",
    "\n",
    "                                df_per_sheet=locals()[f'{data}PSTH{Osc}_{coup}{ctx}{drug}']\n",
    "\n",
    "                                #filenameOut = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_{data}PSTH_{coup}{ctx}_{drug}.pkl' #keep each responses of each cells for all rec Osc\n",
    "                                #with open(filenameOut, 'wb') as pickle_file:\n",
    "                                #    pickle.dump(df_per_sheet, pickle_file)\n",
    "\n",
    "                                if len(df_per_sheet.keys()): # not empty\n",
    "\n",
    "                                    # if PSTH is full lenght\n",
    "                                    arrayLen = 0\n",
    "                                    for key, value in df_per_sheet.items():\n",
    "                                        if value.size > 0:\n",
    "                                            arrayLen = np.shape(value)[1]\n",
    "                                            break  \n",
    "                                    # if PSTH is 2 sec lenght    \n",
    "                                    arrayLen=40 #40\n",
    "                                    \n",
    "                                    for group in GroupList:\n",
    "                                        locals()[f'{group}Array']=pd.DataFrame(columns=np.arange(0,arrayLen,1))\n",
    "                                    \n",
    "                                    for nr in df_per_sheet.keys():\n",
    "                                        #print(nr, '=', df_per_sheet[nr].shape[0], ctx,  Osc, coup, 'recorded') # print the neuron ID\n",
    "                                    \n",
    "                                        if df_per_sheet[nr].shape[0] >= 10 : # at least 10 oscillations recorded\n",
    "\n",
    "                                            if df_per_sheet[nr].shape[1] != 40:\n",
    "                                                print('/!/ Issue with the length of the PSTH !')\n",
    "                                                break\n",
    "                                            \n",
    "                                            #if arrayLen==40: # All Osc at 1 second \n",
    "                                            #    if Osc== 'Spdl':\n",
    "                                            #        PSTH=df_per_sheet[nr].iloc[:, df_per_sheet[nr].shape[1] // 10 *4  : df_per_sheet[nr].shape[1] // 10 * 6] # -1 to 1 sec for Spdl (-5 to 5s)\n",
    "                                            #    else:\n",
    "                                            #        PSTH=df_per_sheet[nr].iloc[:, df_per_sheet[nr].shape[1] // 6 *2  : df_per_sheet[nr].shape[1] // 6 * 4] # -1 to 1 sec for SWR & DS (-3 to 3s)\n",
    "                                            \n",
    "                                            PSTH=df_per_sheet[nr]\n",
    "                                            n_quarter = PSTH.shape[1] // 4  # integer division\n",
    "                                            \n",
    "                                            _1stQuarter= PSTH.iloc[:, :n_quarter].mean(axis=1)\n",
    "                                            _2ndQuarter= PSTH.iloc[:, n_quarter:n_quarter*2].mean(axis=1)\n",
    "                                            _3rdQuarter= PSTH.iloc[:, n_quarter*2:n_quarter*3].mean(axis=1)\n",
    "                                            _4thQuarter= PSTH.iloc[:, n_quarter*3:].mean(axis=1)\n",
    "                                                                                        \n",
    "                                            PSTH2 =pd.concat([_1stQuarter, _2ndQuarter, _3rdQuarter, _4thQuarter], axis=1)\n",
    "\n",
    "                                            AVGtrace=np.nanmean(PSTH, axis=0) #np.nanmean(PSTH, axis=0) \n",
    "\n",
    "                                            BaselineSTD=np.std(AVGtrace[:n_quarter], axis=0)\n",
    "\n",
    "                                            upperThrs=np.nanmean(AVGtrace[:n_quarter], axis=0) + BaselineSTD*2\n",
    "                                            lowerThrs=np.nanmean(AVGtrace[:n_quarter], axis=0) - BaselineSTD*2\n",
    "\n",
    "                                            AVGbefore=np.nanmean(AVGtrace[n_quarter:n_quarter*2], axis=0)\n",
    "                                            AVGafter=np.nanmean(AVGtrace[n_quarter*2:n_quarter*4], axis=0)\n",
    "                                            \n",
    "                                            AVGearly=np.nanmean(AVGtrace[n_quarter*2:n_quarter*3], axis=0)\n",
    "                                            AVGlate=np.nanmean(AVGtrace[n_quarter*3:n_quarter*4], axis=0)\n",
    "                                            \n",
    "                                            #AVGtrace=np.nanmean(PSTH2, axis=0) #np.nanmean(PSTH, axis=0) \n",
    "\n",
    "                                            if AVGafter > upperThrs:\n",
    "                                                group='PsNr'\n",
    "                                                Array=locals()[f'SignModArray']\n",
    "                                                Array.loc[nr]=AVGtrace\n",
    "                                            elif AVGafter < lowerThrs:\n",
    "                                                group='NgNr'\n",
    "                                                Array=locals()[f'SignModArray']\n",
    "                                                Array.loc[nr]=AVGtrace\n",
    "                                            else: \n",
    "                                                group='NoModNr'\n",
    "                                            \n",
    "                                            Array=locals()[f'{group}Array']\n",
    "                                            Array.loc[nr]=AVGtrace\n",
    "                                            Array=locals()[f'AllUnitsArray']\n",
    "                                            Array.loc[nr]=AVGtrace\n",
    "\n",
    "                                    for group in GroupList:\n",
    "\n",
    "                                        ArrayO=locals()[f'{group}Array']\n",
    "\n",
    "                                        if not ArrayO.isna().all().all():\n",
    "\n",
    "                                            # Only keep the neurons belonging to the list (All units, NREM active, REM active, etc)\n",
    "                                            present_indices = [idx for idx in thelist if idx in ArrayO.index]\n",
    "                                            Array = ArrayO.loc[present_indices] \n",
    "\n",
    "                                            n=Array.shape[0]\n",
    "                                            NbNr.loc[group,f'{ctx}{coup}']=n\n",
    "\n",
    "                                            # Leave a blanck space for units not recorded in that condition\n",
    "                                            missing_indexes = set(thelist) - set(Array.index)\n",
    "                                            Array = Array.reindex(Array.index.union(missing_indexes))\n",
    "                                            Array = Array.sort_index()\n",
    "\n",
    "                                            ArrayO=Array.copy()\n",
    "                                            mArray=Array.mean(axis=0)\n",
    "                                            semArray = stats.sem(Array, axis=0, ddof=1, nan_policy='omit')\n",
    "                                            icArray = norm.ppf((1 +  0.95) / 2) * (np.std(Array, axis=0) / np.sqrt(Array.shape[0]))\n",
    "                                            #SmallArray=pd.DataFrame(np.transpose([mArray,semArray,icArray]), columns=[f'{ctx}{coup}{Osc} Mean', f'{ctx}{coup}{Osc} SEM', f'{ctx}{coup}{Osc} IC'])\n",
    "                                            SmallArray=pd.DataFrame(np.transpose([mArray,semArray]), columns=[f'{group}{ctx}mean', f'{group}{ctx}sem'])\n",
    "                                        \n",
    "                                            BigArray=pd.concat([BigArray,SmallArray], axis=1)\n",
    "\n",
    "                                            SecondHalf_columns = Array.iloc[:, Array.shape[1] //2:]\n",
    "                                            mean_baseline = SecondHalf_columns.mean(axis=1)\n",
    "                                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{group}{ctx}'])\n",
    "                                            AVGArray=pd.concat([AVGArray,avgarray], axis=1)\n",
    "\n",
    "                                            FirstQuarter_columns = Array.iloc[:, :Array.shape[1] //4]\n",
    "                                            mean_baseline = FirstQuarter_columns.mean(axis=1)\n",
    "                                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{group}{ctx}'])\n",
    "                                            AVGArraybaseline=pd.concat([AVGArraybaseline,avgarray], axis=1)\n",
    "\n",
    "                                            SecondQuarter_columns = Array.iloc[:, Array.shape[1]//4:Array.shape[1]//4*2]\n",
    "                                            mean_baseline = SecondQuarter_columns.mean(axis=1)\n",
    "                                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{group}{ctx}'])\n",
    "                                            AVGArraybefore=pd.concat([AVGArraybefore,avgarray], axis=1)\n",
    "\n",
    "                                            FirstHalf_columns = Array.iloc[:, :Array.shape[1]//2]\n",
    "                                            mean_baseline = FirstHalf_columns.mean(axis=1)\n",
    "                                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{group}{ctx}'])\n",
    "                                            AVGArrayallbefore=pd.concat([AVGArrayallbefore,avgarray], axis=1)\n",
    "                                            \n",
    "                                            # Baseline signals\n",
    "                                            baseline_columns = Array.iloc[:, :Array.shape[1] // 4]\n",
    "                                            mean_baseline = baseline_columns.mean(axis=1)\n",
    "                                            Array = Array.sub(mean_baseline, axis=0)\n",
    "                                        \n",
    "                                            #excel_writer=locals()[f'excel_writer{coup}']\n",
    "                                            #Array.to_excel(excel_writer, sheet_name=f'{data}BSL_{group}{ctx}', index=True, header=False)\n",
    "                                            #ArrayO.to_excel(excel_writer, sheet_name=f'{data}{group}{ctx}', index=True, header=False)\n",
    "\n",
    "                                            mArray=Array.mean(axis=0)\n",
    "                                            semArray = stats.sem(Array, axis=0, ddof=1, nan_policy='omit')\n",
    "                                            icArray = norm.ppf((1 +  0.95) / 2) * (np.std(Array, axis=0) / np.sqrt(Array.shape[0]))\n",
    "                                            #SmallArray=pd.DataFrame(np.transpose([mArray,semArray,icArray]), columns=[f'{ctx}{coup}{Osc} Mean', f'{ctx}{coup}{Osc} SEM', f'{ctx}{coup}{Osc} IC'])\n",
    "                                            SmallArray=pd.DataFrame(np.transpose([mArray,semArray]), columns=[f'{group}{ctx}mean', f'{group}{ctx}sem'])\n",
    "                                            \n",
    "                                            BigArrayBSL=pd.concat([BigArrayBSL,SmallArray], axis=1)\n",
    "\n",
    "                                            SecondHalf_columns = Array.iloc[:, Array.shape[1]//2:]\n",
    "                                            mean_baseline = SecondHalf_columns.mean(axis=1)\n",
    "                                            #mean_baseline = Array.iloc[:, -1] \n",
    "                                            #mean_baseline.name = f'{group}{ctx}'\n",
    "                                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{group}{ctx}'])\n",
    "                                            AVGArrayBSL=pd.concat([AVGArrayBSL,avgarray], axis=1)\n",
    "\n",
    "                                            FirstQuarter_columns = Array.iloc[:, :Array.shape[1]//4]\n",
    "                                            mean_baseline = FirstQuarter_columns.mean(axis=1)\n",
    "                                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{group}{ctx}'])\n",
    "                                            AVGArrayBSLbaseline=pd.concat([AVGArrayBSLbaseline,avgarray], axis=1)\n",
    "\n",
    "                                            SecondQuarter_columns = Array.iloc[:, Array.shape[1]//4:Array.shape[1]//4*2]\n",
    "                                            mean_baseline = SecondQuarter_columns.mean(axis=1)\n",
    "                                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{group}{ctx}'])\n",
    "                                            AVGArrayBSLbefore=pd.concat([AVGArrayBSLbefore,avgarray], axis=1)\n",
    "\n",
    "                                            FirstHalf_columns = Array.iloc[:, :Array.shape[1]//2]\n",
    "                                            mean_baseline = FirstHalf_columns.mean(axis=1)\n",
    "                                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{group}{ctx}'])\n",
    "                                            AVGArrayBSLallbefore=pd.concat([AVGArrayBSLallbefore,avgarray], axis=1)\n",
    "                                            \n",
    "                        #excel_writer=locals()[f'excel_writer{coup}']\n",
    "                        #excel_writer.close()\n",
    "                        excel_writerAVGn=locals()[f'excel_writerAVG{coup}']\n",
    "                        excel_writerMeann=locals()[f'excel_writerMean{coup}']\n",
    "                        \n",
    "                        #excel_writerMeannBase=locals()[f'excel_writerMeanBase{coup}']\n",
    "                        #excel_writerMeannBef=locals()[f'excel_writerMeanBef{coup}']\n",
    "                        #excel_writerMeannAllBef=locals()[f'excel_writerMeanAllBef{coup}']\n",
    "                        \n",
    "                        \n",
    "                        BigArrayBSL = BigArrayBSL.sort_index(axis=1)\n",
    "                        AVGArrayBSL = AVGArrayBSL.sort_index(axis=1)\n",
    "                        BigArrayBSL.to_excel(excel_writerAVGn, sheet_name=f'BSL_{data}PSTH', index=True, header=True)\n",
    "                        AVGArrayBSL.to_excel(excel_writerMeann, sheet_name=f'BSL_{data}PSTH', index=True, header=True)\n",
    "                        #AVGArrayBSLbaseline.to_excel(excel_writerMeannBase, sheet_name=f'BSL_{data}PSTH', index=True, header=True)\n",
    "                        #AVGArrayBSLbefore.to_excel(excel_writerMeannBef, sheet_name=f'BSL_{data}PSTH', index=True, header=True)\n",
    "                        #AVGArrayBSLallbefore.to_excel(excel_writerMeannAllBef, sheet_name=f'BSL_{data}PSTH', index=True, header=True)\n",
    "\n",
    "                        BigArray = BigArray.sort_index(axis=1)\n",
    "                        AVGArray = AVGArray.sort_index(axis=1)\n",
    "                        BigArray.to_excel(excel_writerAVGn, sheet_name=f'{data}PSTH', index=True, header=True)\n",
    "                        AVGArray.to_excel(excel_writerMeann, sheet_name=f'{data}PSTH', index=True, header=True)\n",
    "                        #AVGArraybaseline.to_excel(excel_writerMeannBase, sheet_name=f'{data}PSTH', index=True, header=True)\n",
    "                        #AVGArraybefore.to_excel(excel_writerMeannBef, sheet_name=f'{data}PSTH', index=True, header=True)\n",
    "                        #AVGArrayallbefore.to_excel(excel_writerMeannAllBef, sheet_name=f'{data}PSTH', index=True, header=True)\n",
    "\n",
    "                        if data=='Ca': # \"Ca\" or \"Sp\"\n",
    "                            nbc = 8 if Osc=='SWR' else 6\n",
    "                            nbc = 2 if Osc=='SWR' and (coup=='' or coup=='UnCoupled') else nbc\n",
    "                            subset = BigArrayBSL.iloc[:, :nbc]\n",
    "                            #subset = BigArray.iloc[:, :nbc]\n",
    "                            \n",
    "                            subset = subset*100\n",
    "                            mean_cols = subset.iloc[:, ::2]\n",
    "                            sem_cols = subset.iloc[:, 1::2]\n",
    "\n",
    "                            axes0[ii].axvline(x=0, color='grey', linestyle='--', linewidth=1)\n",
    "\n",
    "                            axes0[ii].axvline(x=0, color='grey', linestyle='--', linewidth=1)\n",
    "                            axes0[ii].axhline(y=0, color='grey', linestyle='--', linewidth=1)\n",
    "                            time = time = np.linspace(-1, 1, len(subset))  # or use df['Time'] if time is a column\n",
    "                            custom_cmap =  ListedColormap(['green', 'grey', 'purple', 'cyan']) if Osc=='SWR' else ListedColormap(['green', 'grey', 'purple'])\n",
    "                            custom_cmap =  ListedColormap(['blue']) if Osc=='SWR' and (coup=='' or coup=='UnCoupled') else custom_cmap\n",
    "\n",
    "                            NbNr2 = NbNr[NbNr.index.isin(['PsNr', 'NoModNr', 'NgNr'])]   \n",
    "                            new_order = ['NgNr', 'NoModNr', 'PsNr']\n",
    "                            NbNr2 = NbNr2.reindex(new_order)\n",
    "                            #locs=['upper right', 'center right', 'lower right', 'lower center']\n",
    "                            locs=['lower left', 'lower center', 'lower right', 'center right']\n",
    "\n",
    "                            colors = [ 'white', 'gray', 'black']\n",
    "                            ctxmap =  ['PFC', 'S1PFC', 'S1', ''] if Osc=='SWR' else ['PFC', 'S1PFC', 'S1']\n",
    "                            ctxmap =  [''] if Osc=='SWR' and (coup=='' or coup=='UnCoupled') else ctxmap\n",
    "                            for i, col in enumerate(mean_cols.columns):\n",
    "                                mean = mean_cols[col]\n",
    "                                sem = sem_cols.iloc[:, i]  # corresponding SEM column\n",
    "                                label = str(col).replace(\"AllUnits\", \"\").replace(\"mean\", \"\")  # or provide a better label\n",
    "                                label = \"all\" if label==\"\" else label\n",
    "                                \n",
    "                                axes0[ii].plot(time, mean, label=label, color=custom_cmap(i))\n",
    "                                axes0[ii].fill_between(time, mean - sem, mean + sem, color=custom_cmap(i), alpha=0.3)   \n",
    "                                \n",
    "                                #axes0[ii].plot(time, mean, label=label, color=custom_cmap(i))\n",
    "                                #axes0[ii].errorbar(time, mean, yerr=sem, fmt='o', capsize=5, color=custom_cmap(i))      \n",
    "\n",
    "                                if f'{ctxmap[i]}{coup}' in NbNr2:\n",
    "                                    if sum(NbNr2[f'{ctxmap[i]}{coup}'])>0:                                 \n",
    "                                        #inset_ax = inset_axes(axes0[ii], width=\"35%\", height=\"35%\", loc=locs[i])  # can also use (x0, y0, width, height)\n",
    "                                        #inset_ax.pie(NbNr2[f'{ctxmap[i]}{coup}'], startangle=90, colors=colors, wedgeprops={'edgecolor': custom_cmap(i), 'linewidth': 2}, counterclock=False)\n",
    "                                        inset_ax = inset_axes(axes0[ii], width=\"15%\", height=\"25%\", loc=locs[i])  # can also use (x0, y0, width, height)\n",
    "                                        bottom = 0\n",
    "                                        for uu, v in enumerate(NbNr2[f'{ctxmap[i]}{coup}']):\n",
    "                                            inset_ax.bar(label, v, bottom=bottom, color=colors[uu], edgecolor =custom_cmap(i))\n",
    "                                            bottom += v\n",
    "                                        inset_ax.axis('off')\n",
    "\n",
    "                            axes0[ii].set_xlabel(f\"Time from {Osc} (s)\")\n",
    "                            axes0[ii].set_ylabel(f\"{data}{NrSubtype}{List_name}\")\n",
    "                            axes0[ii].set_title(f'{coup}_{drug}')\n",
    "                            axes0[ii].set_ylim(-1, 1)\n",
    "                            axes0[ii].set_ylim(-10, 10) if Osc == 'Spdl' else axes0[ii].set_ylim(-10, 10)                         \n",
    "                            axes0[ii].legend(loc='upper left')    \n",
    "                            ii+=1                        \n",
    "                        \n",
    "                    if data=='Ca':\n",
    "                        try: \n",
    "                            NbNr.loc['PsNr %'] = round(NbNr.loc['PsNr'] / NbNr.loc['AllNr'] *100)\n",
    "                            NbNr.loc['NoModNr %'] = round(NbNr.loc['NoModNr'] / NbNr.loc['AllNr'] *100)\n",
    "                            NbNr.loc['NgNr %'] = round(NbNr.loc['NgNr'] / NbNr.loc['AllNr']*100)\n",
    "                        except:                        \n",
    "                            None\n",
    "                        NbNr.to_excel(excel_writerPN, sheet_name=f'{data}', index=True, header=True)\n",
    "                        excel_writerPN.close() \n",
    "                               \n",
    "                for coup in Coupling:\n",
    "                    excel_writerAVGn=locals()[f'excel_writerAVG{coup}']\n",
    "                    excel_writerMeann=locals()[f'excel_writerMean{coup}']\n",
    "                    #excel_writerMeannBase=locals()[f'excel_writerMeanBase{coup}']\n",
    "                    #excel_writerMeannBef=locals()[f'excel_writerMeanBef{coup}']\n",
    "                    #excel_writerMeannAllBef=locals()[f'excel_writerMeanAllBef{coup}']\n",
    "                    excel_writerAVGn.close()                   \n",
    "                    excel_writerMeann.close() \n",
    "                    #excel_writerMeannBase.close()     \n",
    "                    #excel_writerMeannBef.close()                   \n",
    "                    #excel_writerMeannAllBef.close()\n",
    "            \n",
    "            fig0.tight_layout()   \n",
    "            inset_ax.legend(NbNr2.index)                                           \n",
    "            fig0.savefig(f'{folder_to_save}/AvgPSTH_{NrSubtype}_{Osc}_{drug}.svg', format='svg', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "            fig0.savefig(f'{folder_to_save}/AvgPSTH_{NrSubtype}_{Osc}_{drug}.png', format='png', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "            fig0.show()                  \n",
    "            \n",
    "    #######################\n",
    "    # Propreties Osc\n",
    "    #######################\n",
    "    filenameOut = f'{folder_to_save}/{Osc}Propreties.xlsx'\n",
    "    writer = pd.ExcelWriter(filenameOut)\n",
    "\n",
    "    combined_dfOsc = combined_df.drop_duplicates(subset=f'{Osc}_ID', keep='first')\n",
    "    \n",
    "    combined_dfOsc = combined_dfOsc.replace('PreCoupled', 'Coupled', regex=True)\n",
    "    combined_dfOsc = combined_dfOsc.replace('PrePostCoupled', 'Coupled', regex=True)\n",
    "    combined_dfOsc = combined_dfOsc.replace('PostCoupled', 'Coupled', regex=True)\n",
    "\n",
    "    if Osc== 'SWR':\n",
    "        Count = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'SWR_inside_Spdl']])\n",
    "        AllOscSWRinside=pd.concat([AllOscSWRinside, Count], axis=0) \n",
    "        Count = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'{Osc}Statut']])\n",
    "        AllOscStatut=pd.concat([AllOscStatut, Count], axis=0)    \n",
    "        OscDuration = combined_dfOsc.pivot_table(index='Mice', columns=[combined_dfOsc['Drug'],combined_dfOsc[f'{Osc}Statut']] , values=f'{Osc}Duration', aggfunc='mean')\n",
    "        AllOscDuration=pd.concat([AllOscDuration, OscDuration], axis=0)       \n",
    "        OscDuration2 = combined_dfOsc.pivot_table(index='Mice', columns=[combined_dfOsc['Drug']] , values=f'{Osc}Duration', aggfunc='mean')\n",
    "        AllOscDuration2=pd.concat([AllOscDuration2, OscDuration2], axis=0)   \n",
    "    elif Osc== 'Spdl':\n",
    "        Count = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'SWR_inside_Spdl']])\n",
    "        AllOscSWRinside=pd.concat([AllOscSWRinside, Count], axis=0) \n",
    "        OscDuration = combined_dfOsc.pivot_table(index='Mice', columns=[combined_dfOsc['Drug'],combined_dfOsc['GlobalSpindle']] , values=f'{Osc}Duration', aggfunc='mean')\n",
    "        AllGlobalSpindle=pd.concat([AllGlobalSpindle, OscDuration], axis=0)\n",
    "        Count = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'],combined_dfOsc['GlobalSpindle'], combined_dfOsc[f'{Osc}StartLocation']])\n",
    "        AllOscStartLocation=pd.concat([AllOscStartLocation, Count], axis=0)\n",
    "        OscDuration = combined_dfOsc.pivot_table(index='Mice', columns=[combined_dfOsc['Drug'],combined_dfOsc['GlobalSpindle'], combined_dfOsc[f'{Osc}StartLocation']] , values=f'{Osc}Duration', aggfunc='mean')\n",
    "        AllOscDuration=pd.concat([AllOscDuration, OscDuration], axis=0)\n",
    "        Count = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'GlobalSpindle'],  combined_dfOsc[f'{Osc}StartLocation'], combined_dfOsc[f'{Osc}Statut']])\n",
    "        AllOscCoupling=pd.concat([AllOscCoupling, Count], axis=0)\n",
    "        Count = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'GlobalSpindle'],  combined_dfOsc[f'{Osc}Statut']])\n",
    "        AllOscStatut=pd.concat([AllOscStatut, Count], axis=0)\n",
    "          \n",
    "    AllOscDuration.to_excel(writer, sheet_name=f'MeanDurationperCoupling')\n",
    "    AllOscSWRinside.to_excel(writer, sheet_name=f'SWR_inside_Spdl')\n",
    "    AllOscStatut.to_excel(writer, sheet_name=f'CouplingStatut')\n",
    "    if Osc== 'SWR':\n",
    "        AllOscDuration.to_excel(writer, sheet_name=f'MeanDuration')\n",
    "    if Osc== 'Spdl':\n",
    "        AllOscCoupling.to_excel(writer, sheet_name=f'CouplingPerSpdlLoc')    \n",
    "        AllGlobalSpindle.to_excel(writer, sheet_name=f'MeanDuration')\n",
    "        AllOscStartLocation.to_excel(writer, sheet_name=f'StartLocation')\n",
    "       \n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
