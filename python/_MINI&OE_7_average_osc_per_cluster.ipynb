{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spdl oscillations analysis...\n",
      "1322 Total neurons in the cross-registration\n",
      "4115 Spdl recorded in total\n",
      "Spdl_CaPSTH_baseline\n",
      "Spdl_CaPSTH_UnCoupledbaseline\n",
      "Spdl_CaPSTH_Coupledbaseline\n",
      "Spdl_CaPSTH_S1baseline\n",
      "Spdl_CaPSTH_UnCoupledS1baseline\n",
      "Spdl_CaPSTH_CoupledS1baseline\n",
      "Spdl_CaPSTH_PFCbaseline\n",
      "Spdl_CaPSTH_UnCoupledPFCbaseline\n",
      "Spdl_CaPSTH_CoupledPFCbaseline\n",
      "Spdl_CaPSTH_S1PFCbaseline\n",
      "Spdl_CaPSTH_UnCoupledS1PFCbaseline\n",
      "Spdl_CaPSTH_CoupledS1PFCbaseline\n",
      "Spdl_CaPSTH_CGP\n",
      "Spdl_CaPSTH_UnCoupledCGP\n",
      "Spdl_CaPSTH_CoupledCGP\n",
      "Spdl_CaPSTH_S1CGP\n",
      "Spdl_CaPSTH_UnCoupledS1CGP\n",
      "Spdl_CaPSTH_CoupledS1CGP\n",
      "Spdl_CaPSTH_PFCCGP\n",
      "Spdl_CaPSTH_UnCoupledPFCCGP\n",
      "Spdl_CaPSTH_CoupledPFCCGP\n",
      "Spdl_CaPSTH_S1PFCCGP\n",
      "Spdl_CaPSTH_UnCoupledS1PFCCGP\n",
      "Spdl_CaPSTH_CoupledS1PFCCGP\n",
      "Spdl_SpPSTH_baseline\n",
      "Spdl_SpPSTH_UnCoupledbaseline\n",
      "Spdl_SpPSTH_Coupledbaseline\n",
      "Spdl_SpPSTH_S1baseline\n",
      "Spdl_SpPSTH_UnCoupledS1baseline\n",
      "Spdl_SpPSTH_CoupledS1baseline\n",
      "Spdl_SpPSTH_PFCbaseline\n",
      "Spdl_SpPSTH_UnCoupledPFCbaseline\n",
      "Spdl_SpPSTH_CoupledPFCbaseline\n",
      "Spdl_SpPSTH_S1PFCbaseline\n",
      "Spdl_SpPSTH_UnCoupledS1PFCbaseline\n",
      "Spdl_SpPSTH_CoupledS1PFCbaseline\n",
      "Spdl_SpPSTH_CGP\n",
      "Spdl_SpPSTH_UnCoupledCGP\n",
      "Spdl_SpPSTH_CoupledCGP\n",
      "Spdl_SpPSTH_S1CGP\n",
      "Spdl_SpPSTH_UnCoupledS1CGP\n",
      "Spdl_SpPSTH_CoupledS1CGP\n",
      "Spdl_SpPSTH_PFCCGP\n",
      "Spdl_SpPSTH_UnCoupledPFCCGP\n",
      "Spdl_SpPSTH_CoupledPFCCGP\n",
      "Spdl_SpPSTH_S1PFCCGP\n",
      "Spdl_SpPSTH_UnCoupledS1PFCCGP\n",
      "Spdl_SpPSTH_CoupledS1PFCCGP\n",
      "Spdl_CaPSTH_baseline\n",
      "Spdl_CaPSTH_UnCoupledbaseline\n",
      "Spdl_CaPSTH_Coupledbaseline\n",
      "Spdl_CaPSTH_S1baseline\n",
      "Spdl_CaPSTH_UnCoupledS1baseline\n",
      "Spdl_CaPSTH_CoupledS1baseline\n",
      "Spdl_CaPSTH_PFCbaseline\n",
      "Spdl_CaPSTH_UnCoupledPFCbaseline\n",
      "Spdl_CaPSTH_CoupledPFCbaseline\n",
      "Spdl_CaPSTH_S1PFCbaseline\n",
      "Spdl_CaPSTH_UnCoupledS1PFCbaseline\n",
      "Spdl_CaPSTH_CoupledS1PFCbaseline\n",
      "Spdl_CaPSTH_CGP\n",
      "Spdl_CaPSTH_UnCoupledCGP\n",
      "Spdl_CaPSTH_CoupledCGP\n",
      "Spdl_CaPSTH_S1CGP\n",
      "Spdl_CaPSTH_UnCoupledS1CGP\n",
      "Spdl_CaPSTH_CoupledS1CGP\n",
      "Spdl_CaPSTH_PFCCGP\n",
      "Spdl_CaPSTH_UnCoupledPFCCGP\n",
      "Spdl_CaPSTH_CoupledPFCCGP\n",
      "Spdl_CaPSTH_S1PFCCGP\n",
      "Spdl_CaPSTH_UnCoupledS1PFCCGP\n",
      "Spdl_CaPSTH_CoupledS1PFCCGP\n",
      "Spdl_SpPSTH_baseline\n",
      "Spdl_SpPSTH_UnCoupledbaseline\n",
      "Spdl_SpPSTH_Coupledbaseline\n",
      "Spdl_SpPSTH_S1baseline\n",
      "Spdl_SpPSTH_UnCoupledS1baseline\n",
      "Spdl_SpPSTH_CoupledS1baseline\n",
      "Spdl_SpPSTH_PFCbaseline\n",
      "Spdl_SpPSTH_UnCoupledPFCbaseline\n",
      "Spdl_SpPSTH_CoupledPFCbaseline\n",
      "Spdl_SpPSTH_S1PFCbaseline\n",
      "Spdl_SpPSTH_UnCoupledS1PFCbaseline\n",
      "Spdl_SpPSTH_CoupledS1PFCbaseline\n",
      "Spdl_SpPSTH_CGP\n",
      "Spdl_SpPSTH_UnCoupledCGP\n",
      "Spdl_SpPSTH_CoupledCGP\n",
      "Spdl_SpPSTH_S1CGP\n",
      "Spdl_SpPSTH_UnCoupledS1CGP\n",
      "Spdl_SpPSTH_CoupledS1CGP\n",
      "Spdl_SpPSTH_PFCCGP\n",
      "Spdl_SpPSTH_UnCoupledPFCCGP\n",
      "Spdl_SpPSTH_CoupledPFCCGP\n",
      "Spdl_SpPSTH_S1PFCCGP\n",
      "Spdl_SpPSTH_UnCoupledS1PFCCGP\n",
      "Spdl_SpPSTH_CoupledS1PFCCGP\n",
      "SWR oscillations analysis...\n",
      "1322 Total neurons in the cross-registration\n",
      "21004 SWR recorded in total\n",
      "SWR_CaPSTH_baseline\n",
      "SWR_CaPSTH_UnCoupledbaseline\n",
      "SWR_CaPSTH_Coupledbaseline\n",
      "SWR_CaPSTH_S1baseline\n",
      "SWR_CaPSTH_UnCoupledS1baseline\n",
      "SWR_CaPSTH_CoupledS1baseline\n",
      "SWR_CaPSTH_PFCbaseline\n",
      "SWR_CaPSTH_UnCoupledPFCbaseline\n",
      "SWR_CaPSTH_CoupledPFCbaseline\n",
      "SWR_CaPSTH_S1PFCbaseline\n",
      "SWR_CaPSTH_UnCoupledS1PFCbaseline\n",
      "SWR_CaPSTH_CoupledS1PFCbaseline\n",
      "SWR_CaPSTH_CGP\n",
      "SWR_CaPSTH_UnCoupledCGP\n",
      "SWR_CaPSTH_CoupledCGP\n",
      "SWR_CaPSTH_S1CGP\n",
      "SWR_CaPSTH_UnCoupledS1CGP\n",
      "SWR_CaPSTH_CoupledS1CGP\n",
      "SWR_CaPSTH_PFCCGP\n",
      "SWR_CaPSTH_UnCoupledPFCCGP\n",
      "SWR_CaPSTH_CoupledPFCCGP\n",
      "SWR_CaPSTH_S1PFCCGP\n",
      "SWR_CaPSTH_UnCoupledS1PFCCGP\n",
      "SWR_CaPSTH_CoupledS1PFCCGP\n",
      "SWR_SpPSTH_baseline\n",
      "SWR_SpPSTH_UnCoupledbaseline\n",
      "SWR_SpPSTH_Coupledbaseline\n",
      "SWR_SpPSTH_S1baseline\n",
      "SWR_SpPSTH_UnCoupledS1baseline\n",
      "SWR_SpPSTH_CoupledS1baseline\n",
      "SWR_SpPSTH_PFCbaseline\n",
      "SWR_SpPSTH_UnCoupledPFCbaseline\n",
      "SWR_SpPSTH_CoupledPFCbaseline\n",
      "SWR_SpPSTH_S1PFCbaseline\n",
      "SWR_SpPSTH_UnCoupledS1PFCbaseline\n",
      "SWR_SpPSTH_CoupledS1PFCbaseline\n",
      "SWR_SpPSTH_CGP\n",
      "SWR_SpPSTH_UnCoupledCGP\n",
      "SWR_SpPSTH_CoupledCGP\n",
      "SWR_SpPSTH_S1CGP\n",
      "SWR_SpPSTH_UnCoupledS1CGP\n",
      "SWR_SpPSTH_CoupledS1CGP\n",
      "SWR_SpPSTH_PFCCGP\n",
      "SWR_SpPSTH_UnCoupledPFCCGP\n",
      "SWR_SpPSTH_CoupledPFCCGP\n",
      "SWR_SpPSTH_S1PFCCGP\n",
      "SWR_SpPSTH_UnCoupledS1PFCCGP\n",
      "SWR_SpPSTH_CoupledS1PFCCGP\n",
      "SWR_CaPSTH_baseline\n",
      "SWR_CaPSTH_UnCoupledbaseline\n",
      "SWR_CaPSTH_Coupledbaseline\n",
      "SWR_CaPSTH_S1baseline\n",
      "SWR_CaPSTH_UnCoupledS1baseline\n",
      "SWR_CaPSTH_CoupledS1baseline\n",
      "SWR_CaPSTH_PFCbaseline\n",
      "SWR_CaPSTH_UnCoupledPFCbaseline\n",
      "SWR_CaPSTH_CoupledPFCbaseline\n",
      "SWR_CaPSTH_S1PFCbaseline\n",
      "SWR_CaPSTH_UnCoupledS1PFCbaseline\n",
      "SWR_CaPSTH_CoupledS1PFCbaseline\n",
      "SWR_CaPSTH_CGP\n",
      "SWR_CaPSTH_UnCoupledCGP\n",
      "SWR_CaPSTH_CoupledCGP\n",
      "SWR_CaPSTH_S1CGP\n",
      "SWR_CaPSTH_UnCoupledS1CGP\n",
      "SWR_CaPSTH_CoupledS1CGP\n",
      "SWR_CaPSTH_PFCCGP\n",
      "SWR_CaPSTH_UnCoupledPFCCGP\n",
      "SWR_CaPSTH_CoupledPFCCGP\n",
      "SWR_CaPSTH_S1PFCCGP\n",
      "SWR_CaPSTH_UnCoupledS1PFCCGP\n",
      "SWR_CaPSTH_CoupledS1PFCCGP\n",
      "SWR_SpPSTH_baseline\n",
      "SWR_SpPSTH_UnCoupledbaseline\n",
      "SWR_SpPSTH_Coupledbaseline\n",
      "SWR_SpPSTH_S1baseline\n",
      "SWR_SpPSTH_UnCoupledS1baseline\n",
      "SWR_SpPSTH_CoupledS1baseline\n",
      "SWR_SpPSTH_PFCbaseline\n",
      "SWR_SpPSTH_UnCoupledPFCbaseline\n",
      "SWR_SpPSTH_CoupledPFCbaseline\n",
      "SWR_SpPSTH_S1PFCbaseline\n",
      "SWR_SpPSTH_UnCoupledS1PFCbaseline\n",
      "SWR_SpPSTH_CoupledS1PFCbaseline\n",
      "SWR_SpPSTH_CGP\n",
      "SWR_SpPSTH_UnCoupledCGP\n",
      "SWR_SpPSTH_CoupledCGP\n",
      "SWR_SpPSTH_S1CGP\n",
      "SWR_SpPSTH_UnCoupledS1CGP\n",
      "SWR_SpPSTH_CoupledS1CGP\n",
      "SWR_SpPSTH_PFCCGP\n",
      "SWR_SpPSTH_UnCoupledPFCCGP\n",
      "SWR_SpPSTH_CoupledPFCCGP\n",
      "SWR_SpPSTH_S1PFCCGP\n",
      "SWR_SpPSTH_UnCoupledS1PFCCGP\n",
      "SWR_SpPSTH_CoupledS1PFCCGP\n"
     ]
    }
   ],
   "source": [
    "# Stats on Ca2+ imaging with miniscope and Osc\n",
    "#######################################################################################\n",
    "                            # Define Experiment type #\n",
    "#######################################################################################\n",
    "\n",
    "DrugExperiment=1 # 1 if CGP Experiment, 0 if Baseline Experiment\n",
    "\n",
    "AnalysisID='' \n",
    "\n",
    "Local=1\n",
    "\n",
    "choosed_folder1='Osc_2025-05-04_10_45_30_likeAH' # for Baseline Expe\n",
    "choosed_folder2='Osc_2025-05-04_10_45_30_likeAH' # for CGP Expe\n",
    "\n",
    "choosed_folder3='VigSt_2025-05-03_10_01_32'\n",
    "\n",
    "#######################################################################################\n",
    "                                # Load packages #\n",
    "#######################################################################################\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import quantities as pq\n",
    "import numpy as np\n",
    "import math \n",
    "import neo\n",
    "import json\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "import pickle\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats import sem\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def column_with_max_single_per_row(row):\n",
    "    max_val = row.max()  # Find the max value in the row\n",
    "    max_columns = row == max_val  # Boolean Series of columns with max value\n",
    "    \n",
    "    if max_columns.sum() > 1:\n",
    "        return 'NoPref'  # More than one column has the max value\n",
    "    else:\n",
    "        return max_columns.idxmax()  # Return the name of the column with max value\n",
    "\n",
    "def divide_keys(data):\n",
    "    it=list(data.keys())[0]\n",
    "    d=data[it]\n",
    "    data[it]=d.replace(0, np.nan)\n",
    "    for sheet in list(data.keys())[1:]: \n",
    "        data[sheet].div(data[it][sheet], axis=0)\n",
    "    del data[it]\n",
    "    return data    \n",
    "\n",
    "########################################################################\n",
    "                            # Define Directories #\n",
    "########################################################################\n",
    "\n",
    "# Specify the directory containing the Excel files\n",
    "InitialDirectory1 = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_baseline_analysis\" if Local else \"/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_baseline_analysis\" \n",
    "directory1= f'{InitialDirectory1}/{choosed_folder1}'\n",
    "InitialDirectory2 =\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_CGP_analysis\" if Local else \"/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_CGP_analysis\"\n",
    "directory2= f'{InitialDirectory2}/{choosed_folder2}'\n",
    "\n",
    "directory3= f'{InitialDirectory1}/{choosed_folder3}'\n",
    "\n",
    "# Get the current date and time\n",
    "FolderNameSave=str(datetime.now())[:19]\n",
    "FolderNameSave = FolderNameSave.replace(\" \", \"_\").replace(\".\", \"_\").replace(\":\", \"_\")\n",
    "destination_folder= f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_global_analysis/AVG_Osc_{FolderNameSave}{AnalysisID}\" if Local else f\"/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_global_analysis/AVG_Osc_{FolderNameSave}{AnalysisID}\"\n",
    "os.makedirs(destination_folder)\n",
    "folder_to_save=Path(destination_folder)\n",
    "\n",
    "# Copy the script file to the destination folder\n",
    "source_script = \"C:/Users/Manip2/SCRIPTS/CodePythonAudrey/CodePythonAurelie/HayLabAnalysis/python/_MINI&OE_7_average_osc_per_cluster.ipynb\" if Local else \"/python/_MINI&OE_7_average_osc_per_cluster.ipynb\" \n",
    "destination_file_path = f\"{destination_folder}/_MINI&OE_7_average_osc_per_cluster.txt\"\n",
    "shutil.copy(source_script, destination_file_path)\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "                            # Do the average per cluster #\n",
    "#######################################################################################\n",
    "\n",
    "CTX=['', 'S1', 'PFC', 'S1PFC']\n",
    "Coupling=['', 'UnCoupled', 'Coupled']\n",
    "OscList=['Spdl', 'SWR']\n",
    "Drugs= ['baseline', 'CGP'] if DrugExperiment else ['baseline']\n",
    "\n",
    "NrSubtypeList=['L1NDNF_mice','L2_3_mice']\n",
    "\n",
    "\n",
    "# Load Global Table \n",
    "with open(f'{directory3}/VigStates_Global_cluster.pkl', 'rb') as pickle_file:\n",
    "    Vig_cluster_dfO = pickle.load(pickle_file)\n",
    "\n",
    "for o, Osc in enumerate(OscList): \n",
    "    \n",
    "    print(Osc, 'oscillations analysis...')\n",
    "\n",
    "    AllOscStatut=pd.DataFrame()\n",
    "    AllOscDuration=pd.DataFrame()\n",
    "    AllGlobalSpindle=pd.DataFrame()\n",
    "    AllOscStartLocation=pd.DataFrame()\n",
    "    AllOscSWRinside=pd.DataFrame()\n",
    "    AllOscCoupling=pd.DataFrame()\n",
    "\n",
    "                \n",
    "    # Initialize an empty list to store the dataframes\n",
    "    combined_df = []\n",
    "    filtered_df=[]\n",
    "\n",
    "    ###########################################################################\n",
    "                                ##### GLOBAL #####\n",
    "    ###########################################################################\n",
    "\n",
    "    # Load Global Table \n",
    "    with open(f'{directory2}/{Osc}_Global.pkl', 'rb') as pickle_file:\n",
    "        combined_df = pickle.load(pickle_file)\n",
    "\n",
    "    combined_df['Unique_Unit'] = combined_df['Unique_Unit'].astype(str)\n",
    "    combined_df['UnitNumber'] = combined_df['UnitNumber'].astype(str)\n",
    "    combined_df['UnitValue'] = combined_df['UnitValue'].astype(str)\n",
    "\n",
    "    combined_df[f'{Osc}Statut'] = combined_df[f'{Osc}Statut'].astype(str)\n",
    "\n",
    "    combined_df['Unit_ID'] = combined_df['Mice'] + combined_df['Unique_Unit']\n",
    "    combined_df['Session_ID'] = combined_df['Mice'] + '_' + combined_df['Session_Date'] + '_' + combined_df['Session_Time']\n",
    "\n",
    "    unique_count = combined_df['Unit_ID'].nunique()\n",
    "    print(unique_count, f'Total neurons in the cross-registration') \n",
    "    \n",
    "    combined_df[f'{Osc}_ID'] = combined_df['Mice'] + '_' + combined_df['Session_Date'] + '_' + combined_df['Session_Time'] + '_' +combined_df[f'{Osc}Number'].astype(str)\n",
    "    \n",
    "    unique_count = combined_df[f'{Osc}_ID'].nunique()\n",
    "    print(unique_count, f'{Osc} recorded in total')\n",
    "\n",
    "    writer = pd.ExcelWriter(f'{folder_to_save}/{Osc}_Global.xlsx')\n",
    "    combined_df.to_excel(writer)\n",
    "    writer.close()\n",
    "    \n",
    "    ###########################################################################\n",
    "                                ##### GLOBAL #####\n",
    "    ###########################################################################\n",
    "\n",
    "    for NrSubtype in NrSubtypeList: \n",
    "\n",
    "        if NrSubtype=='L1NDNF_mice':\n",
    "            MiceList=['BlackLines', 'BlueLines', 'GreenDots', 'GreenLines', 'RedLines']\n",
    "        else:\n",
    "            MiceList=['PurpleSquare', 'ThreeColDots', 'ThreeBlueCrosses']\n",
    "\n",
    "        Data=['Ca', 'Sp']\n",
    "        for data in Data:\n",
    "            for drug in Drugs: \n",
    "                for ctx in CTX:\n",
    "                    for coup in Coupling:  \n",
    "                        #ctx= '' if Osc=='SWR' else ctx                      \n",
    "                        locals()[f'{data}PSTH{Osc}_{coup}{ctx}{drug}']={}\n",
    "                        dfsPSTH_per_sheet = locals()[f'{data}PSTH{Osc}_{coup}{ctx}{drug}']\n",
    "                        nametofind2=f'{Osc}_{data}PSTH_{coup}{ctx}{drug}'\n",
    "                        print(nametofind2)\n",
    "                        # Recursively traverse the directory structure\n",
    "                        for directory in [directory2]:\n",
    "                            for root, _, files in os.walk(directory):\n",
    "                                for filename in files:\n",
    "                                    if filename.endswith('.pkl') and nametofind2 in filename: \n",
    "                                        if any(name in filename for name in MiceList): \n",
    "                                            # Construct the full path to the file\n",
    "                                            filepath = os.path.join(root, filename)\n",
    "                                            with open(filepath, 'rb') as pickle_file:\n",
    "                                                df = pickle.load(pickle_file)\n",
    "                                            for key, value in df.items():\n",
    "                                                if key in dfsPSTH_per_sheet:\n",
    "                                                    dfsPSTH_per_sheet[key]=pd.concat([pd.DataFrame(dfsPSTH_per_sheet[key]),pd.DataFrame(value)], ignore_index=False, axis=0)\n",
    "                                                else:\n",
    "                                                    dfsPSTH_per_sheet[key]=pd.DataFrame(value)\n",
    "\n",
    "\n",
    "        ###########################################################################\n",
    "                                ##### PREFERENCE #####\n",
    "        ########################################################################### \n",
    "        Vig_cluster_df = Vig_cluster_dfO.copy()\n",
    "        Vig_cluster_df = Vig_cluster_df[Vig_cluster_df['NeuronType'] == NrSubtype]\n",
    "        Vig_cluster_df_Drug = Vig_cluster_df.copy()        \n",
    "        AllUnits = Vig_cluster_df['Unit_ID'].unique()\n",
    "\n",
    "        Vig_cluster_df_Drug = Vig_cluster_df_Drug[Vig_cluster_df_Drug['Drug'] == 'baseline']    \n",
    "        AllBaselineUnits = Vig_cluster_df_Drug['Unit_ID'].unique()\n",
    "\n",
    "        Cluster0units = Vig_cluster_df_Drug[Vig_cluster_df_Drug['ClusterHDBSCAN'] == 0]['Unit_ID'].unique()\n",
    "        Cluster1units = Vig_cluster_df_Drug[Vig_cluster_df_Drug['ClusterHDBSCAN'] == 1]['Unit_ID'].unique()\n",
    "        Cluster2units = Vig_cluster_df_Drug[Vig_cluster_df_Drug['ClusterHDBSCAN'] == 2]['Unit_ID'].unique()\n",
    "\n",
    "        for drug in Drugs: \n",
    "            \n",
    "            combined_df_Drug = combined_df.copy()\n",
    "            try:\n",
    "                combined_df_Drug = combined_df_Drug[combined_df_Drug['Drug'] == drug]\n",
    "            except: \n",
    "                combined_df_Drug=combined_df_Drug\n",
    "            \n",
    "            folder_to_save2= f'{folder_to_save}/{drug}/'\n",
    "            if NrSubtype=='L1NDNF_mice' and o==0 :\n",
    "                os.makedirs(folder_to_save2)  \n",
    "\n",
    "            listCluster=['AllUnits', 'AllBaselineUnits', 'Cluster0units', 'Cluster1units', 'Cluster2units'] if NrSubtype=='L1NDNF_mice' else ['AllUnits', 'AllBaselineUnits']\n",
    "\n",
    "            # Print the names of the sheets and their corresponding DataFrames\n",
    "            for List_name in listCluster:\n",
    "                \n",
    "                thelist=locals()[f'{List_name}']\n",
    "                filtered_df = combined_df_Drug[combined_df_Drug['Unit_ID'].isin(thelist)]\n",
    "                GroupList=['AllNr', 'PsNr', 'NoModNr', 'NgNr']\n",
    "\n",
    "                if NrSubtype=='L1NDNF_mice' :#and o==0:\n",
    "                    new_folder= f\"{folder_to_save2}/{List_name}/{Osc}/\"\n",
    "                    os.makedirs(new_folder)\n",
    "\n",
    "                ###########################################################################\n",
    "                                        ##### AVERAGE PSTH #####\n",
    "                ###########################################################################\n",
    "\n",
    "                for coup in Coupling:\n",
    "                    filenameOutAVG = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_{coup}AVG&SEM.xlsx'\n",
    "                    locals()[f'excel_writerAVG{coup}']= pd.ExcelWriter(filenameOutAVG)\n",
    "\n",
    "                    filenameOutMean = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_{coup}During.xlsx'\n",
    "                    locals()[f'excel_writerMean{coup}']= pd.ExcelWriter(filenameOutMean)\n",
    "\n",
    "                    filenameOutMean = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_{coup}Baseline.xlsx'\n",
    "                    locals()[f'excel_writerMeanBase{coup}']= pd.ExcelWriter(filenameOutMean)\n",
    "\n",
    "                    filenameOutMean = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_{coup}Before.xlsx'\n",
    "                    locals()[f'excel_writerMeanBef{coup}']= pd.ExcelWriter(filenameOutMean)\n",
    "\n",
    "                    filenameOutMean = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_{coup}AllBefore.xlsx'\n",
    "                    locals()[f'excel_writerMeanAllBef{coup}']= pd.ExcelWriter(filenameOutMean)\n",
    "\n",
    "                    filenameOutMean = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_{coup}PSTH.xlsx'\n",
    "                    locals()[f'excel_writer{coup}']= pd.ExcelWriter(filenameOutMean)\n",
    "                \n",
    "                for data in Data:\n",
    "                    \n",
    "                    if data=='Ca':\n",
    "                        filenameOutPN = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_NrProportion.xlsx'\n",
    "                        excel_writerPN= pd.ExcelWriter(filenameOutPN)\n",
    "                    \n",
    "                    NbNr=pd.DataFrame()\n",
    "\n",
    "                    for coup in Coupling:  \n",
    "\n",
    "                        BigArray=pd.DataFrame()\n",
    "                        BigArrayBSL=pd.DataFrame()\n",
    "                        AVGArray=pd.DataFrame()\n",
    "                        AVGArrayBSL=pd.DataFrame()\n",
    "                        AVGArraybefore=pd.DataFrame()\n",
    "                        AVGArrayallbefore=pd.DataFrame()\n",
    "                        AVGArrayBSLbefore=pd.DataFrame()\n",
    "                        AVGArrayBSLallbefore=pd.DataFrame()\n",
    "                        AVGArraybaseline=pd.DataFrame()\n",
    "                        AVGArrayBSLbaseline=pd.DataFrame()\n",
    "                        \n",
    "                        for ctx in CTX:\n",
    "                            \n",
    "                            if f'{data}PSTH{Osc}_{coup}{ctx}{drug}' in locals(): #cause no ctx if uncoupled\n",
    "\n",
    "                                df_per_sheet=locals()[f'{data}PSTH{Osc}_{coup}{ctx}{drug}']\n",
    "\n",
    "                                #filenameOut = f'{folder_to_save2}/{List_name}/{Osc}/{NrSubtype}_{data}PSTH_{coup}{ctx}_{drug}.pkl' #keep each responses of each cells for all rec Osc\n",
    "                                #with open(filenameOut, 'wb') as pickle_file:\n",
    "                                #    pickle.dump(df_per_sheet, pickle_file)\n",
    "\n",
    "                                if len(df_per_sheet.keys()): # not empty\n",
    "\n",
    "                                    # if PSTH is full lenght\n",
    "                                    arrayLen = 0\n",
    "                                    for key, value in df_per_sheet.items():\n",
    "                                        if value.size > 0:\n",
    "                                            arrayLen = np.shape(value)[1]\n",
    "                                            break  \n",
    "                                    # if PSTH is 2 sec lenght    \n",
    "                                    arrayLen=40\n",
    "                                    \n",
    "                                    for group in GroupList:\n",
    "                                        locals()[f'{group}Array']=pd.DataFrame(columns=np.arange(0,arrayLen,1))\n",
    "                                    \n",
    "                                    for nr in df_per_sheet.keys():\n",
    "                                    \n",
    "                                        if df_per_sheet[nr].shape[0] >= 10 : # at least 10 oscillations recorded\n",
    "                                            \n",
    "                                            if arrayLen==40: # All Osc at 1second \n",
    "                                                if Osc== 'Spdl':\n",
    "                                                    PSTH=df_per_sheet[nr].iloc[:, df_per_sheet[nr].shape[1] // 10 *4  : df_per_sheet[nr].shape[1] // 10 * 6] # -1 to 1 sec for Spdl (-5 to 5s)\n",
    "                                                else:\n",
    "                                                    PSTH=df_per_sheet[nr].iloc[:, df_per_sheet[nr].shape[1] // 6 *2  : df_per_sheet[nr].shape[1] // 6 * 4] # -1 to 1 sec for SWR & DS (-3 to 3s)\n",
    "                                            else: # full lenght\n",
    "                                                PSTH=df_per_sheet[nr]\n",
    "\n",
    "                                            AVGtrace=np.nanmean(PSTH, axis=0)\n",
    "                                            \n",
    "                                            BaselineSTD=np.std(AVGtrace[:PSTH.shape[1]//4], axis=0)\n",
    "\n",
    "                                            upperThrs=np.nanmean(AVGtrace[:PSTH.shape[1]//4], axis=0) + BaselineSTD*2\n",
    "                                            lowerThrs=np.nanmean(AVGtrace[:PSTH.shape[1]//4], axis=0) - BaselineSTD*2\n",
    "\n",
    "                                            AVGbefore=np.nanmean(AVGtrace[PSTH.shape[1]//4:PSTH.shape[1]//4*2], axis=0)\n",
    "                                            AVGearly=np.nanmean(AVGtrace[PSTH.shape[1]//4*2:PSTH.shape[1]//4*3], axis=0)\n",
    "                                            AVGlate=np.nanmean(AVGtrace[PSTH.shape[1]//4*3:PSTH.shape[1]//4*4], axis=0)\n",
    "                                            \n",
    "                                            if AVGearly > upperThrs:\n",
    "                                                group='PsNr'\n",
    "                                            elif AVGearly < lowerThrs:\n",
    "                                                group='NgNr'\n",
    "                                            else: \n",
    "                                                group='NoModNr'\n",
    "                                            \n",
    "                                            Array=locals()[f'{group}Array']\n",
    "                                            Array.loc[nr]=AVGtrace\n",
    "                                            Array=locals()[f'AllNrArray']\n",
    "                                            Array.loc[nr]=AVGtrace\n",
    "\n",
    "                                    for group in GroupList:\n",
    "\n",
    "                                        ArrayO=locals()[f'{group}Array']\n",
    "\n",
    "                                        if not ArrayO.isna().all().all():\n",
    "\n",
    "                                            # Only keep the neurons belonging to the list (All units, NREM active, REM active, etc)\n",
    "                                            present_indices = [idx for idx in thelist if idx in ArrayO.index]\n",
    "                                            Array = ArrayO.loc[present_indices] \n",
    "\n",
    "                                            n=Array.shape[0]\n",
    "                                            NbNr.loc[group,f'{ctx}{coup}']=n\n",
    "\n",
    "                                            # Leave a blanck space for units not recorded in that condition\n",
    "                                            missing_indexes = set(thelist) - set(Array.index)\n",
    "                                            Array = Array.reindex(Array.index.union(missing_indexes))\n",
    "                                            Array = Array.sort_index()\n",
    "\n",
    "                                            ArrayO=Array.copy()\n",
    "                                            mArray=Array.mean(axis=0)\n",
    "                                            semArray = stats.sem(Array, axis=0, ddof=1, nan_policy='omit')\n",
    "                                            icArray = norm.ppf((1 +  0.95) / 2) * (np.std(Array, axis=0) / np.sqrt(Array.shape[0]))\n",
    "                                            #SmallArray=pd.DataFrame(np.transpose([mArray,semArray,icArray]), columns=[f'{ctx}{coup}{Osc} Mean', f'{ctx}{coup}{Osc} SEM', f'{ctx}{coup}{Osc} IC'])\n",
    "                                            SmallArray=pd.DataFrame(np.transpose([mArray,semArray]), columns=[f'{group}{ctx}mean', f'{group}{ctx}sem'])\n",
    "                                        \n",
    "                                            BigArray=pd.concat([BigArray,SmallArray], axis=1)\n",
    "\n",
    "                                            SecondHalf_columns = Array.iloc[:, Array.shape[1] //2:]\n",
    "                                            mean_baseline = SecondHalf_columns.mean(axis=1)\n",
    "                                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{group}{ctx}'])\n",
    "                                            AVGArray=pd.concat([AVGArray,avgarray], axis=1)\n",
    "\n",
    "                                            FirstQuarter_columns = Array.iloc[:, :Array.shape[1] //4]\n",
    "                                            mean_baseline = FirstQuarter_columns.mean(axis=1)\n",
    "                                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{group}{ctx}'])\n",
    "                                            AVGArraybaseline=pd.concat([AVGArraybaseline,avgarray], axis=1)\n",
    "\n",
    "                                            SecondQuarter_columns = Array.iloc[:, Array.shape[1]//4:Array.shape[1]//4*2]\n",
    "                                            mean_baseline = SecondQuarter_columns.mean(axis=1)\n",
    "                                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{group}{ctx}'])\n",
    "                                            AVGArraybefore=pd.concat([AVGArraybefore,avgarray], axis=1)\n",
    "\n",
    "                                            FirstHalf_columns = Array.iloc[:, :Array.shape[1]//2]\n",
    "                                            mean_baseline = FirstHalf_columns.mean(axis=1)\n",
    "                                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{group}{ctx}'])\n",
    "                                            AVGArrayallbefore=pd.concat([AVGArrayallbefore,avgarray], axis=1)\n",
    "                                            \n",
    "                                            # Baseline signals\n",
    "                                            baseline_columns = Array.iloc[:, :Array.shape[1] // 4]\n",
    "                                            mean_baseline = baseline_columns.mean(axis=1)\n",
    "                                            Array = Array.sub(mean_baseline, axis=0)\n",
    "                                        \n",
    "                                            excel_writer=locals()[f'excel_writer{coup}']\n",
    "                                            Array.to_excel(excel_writer, sheet_name=f'{data}BSL_{group}{ctx}', index=True, header=False)\n",
    "                                            ArrayO.to_excel(excel_writer, sheet_name=f'{data}{group}{ctx}', index=True, header=False)\n",
    "\n",
    "                                            mArray=Array.mean(axis=0)\n",
    "                                            semArray = stats.sem(Array, axis=0, ddof=1, nan_policy='omit')\n",
    "                                            icArray = norm.ppf((1 +  0.95) / 2) * (np.std(Array, axis=0) / np.sqrt(Array.shape[0]))\n",
    "                                            #SmallArray=pd.DataFrame(np.transpose([mArray,semArray,icArray]), columns=[f'{ctx}{coup}{Osc} Mean', f'{ctx}{coup}{Osc} SEM', f'{ctx}{coup}{Osc} IC'])\n",
    "                                            SmallArray=pd.DataFrame(np.transpose([mArray,semArray]), columns=[f'{group}{ctx}mean', f'{group}{ctx}sem'])\n",
    "                                            \n",
    "                                            BigArrayBSL=pd.concat([BigArrayBSL,SmallArray], axis=1)\n",
    "\n",
    "                                            SecondHalf_columns = Array.iloc[:, Array.shape[1]//2:]\n",
    "                                            mean_baseline = SecondHalf_columns.mean(axis=1)\n",
    "                                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{group}{ctx}'])\n",
    "                                            AVGArrayBSL=pd.concat([AVGArrayBSL,avgarray], axis=1)\n",
    "\n",
    "                                            FirstQuarter_columns = Array.iloc[:, :Array.shape[1]//4]\n",
    "                                            mean_baseline = FirstQuarter_columns.mean(axis=1)\n",
    "                                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{group}{ctx}'])\n",
    "                                            AVGArrayBSLbaseline=pd.concat([AVGArrayBSLbaseline,avgarray], axis=1)\n",
    "\n",
    "                                            SecondQuarter_columns = Array.iloc[:, Array.shape[1]//4:Array.shape[1]//4*2]\n",
    "                                            mean_baseline = SecondQuarter_columns.mean(axis=1)\n",
    "                                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{group}{ctx}'])\n",
    "                                            AVGArrayBSLbefore=pd.concat([AVGArrayBSLbefore,avgarray], axis=1)\n",
    "\n",
    "                                            FirstHalf_columns = Array.iloc[:, :Array.shape[1]//2]\n",
    "                                            mean_baseline = FirstHalf_columns.mean(axis=1)\n",
    "                                            avgarray=pd.DataFrame(mean_baseline, columns=[f'{group}{ctx}'])\n",
    "                                            AVGArrayBSLallbefore=pd.concat([AVGArrayBSLallbefore,avgarray], axis=1)\n",
    "                                            \n",
    "                        excel_writer=locals()[f'excel_writer{coup}']\n",
    "                        excel_writer.close()\n",
    "                        excel_writerAVGn=locals()[f'excel_writerAVG{coup}']\n",
    "                        excel_writerMeann=locals()[f'excel_writerMean{coup}']\n",
    "                        excel_writerMeannBase=locals()[f'excel_writerMeanBase{coup}']\n",
    "                        excel_writerMeannBef=locals()[f'excel_writerMeanBef{coup}']\n",
    "                        excel_writerMeannAllBef=locals()[f'excel_writerMeanAllBef{coup}']\n",
    "                        \n",
    "                        \n",
    "                        BigArrayBSL = BigArrayBSL.sort_index(axis=1)\n",
    "                        AVGArrayBSL = AVGArrayBSL.sort_index(axis=1)\n",
    "                        BigArrayBSL.to_excel(excel_writerAVGn, sheet_name=f'BSL_{data}PSTH', index=True, header=True)\n",
    "                        AVGArrayBSL.to_excel(excel_writerMeann, sheet_name=f'BSL_{data}PSTH', index=True, header=True)\n",
    "                        AVGArrayBSLbaseline.to_excel(excel_writerMeannBase, sheet_name=f'BSL_{data}PSTH', index=True, header=True)\n",
    "                        AVGArrayBSLbefore.to_excel(excel_writerMeannBef, sheet_name=f'BSL_{data}PSTH', index=True, header=True)\n",
    "                        AVGArrayBSLallbefore.to_excel(excel_writerMeannAllBef, sheet_name=f'BSL_{data}PSTH', index=True, header=True)\n",
    "\n",
    "                        BigArray = BigArray.sort_index(axis=1)\n",
    "                        AVGArray = AVGArray.sort_index(axis=1)\n",
    "                        BigArray.to_excel(excel_writerAVGn, sheet_name=f'{data}PSTH', index=True, header=True)\n",
    "                        AVGArray.to_excel(excel_writerMeann, sheet_name=f'{data}PSTH', index=True, header=True)\n",
    "                        AVGArraybaseline.to_excel(excel_writerMeannBase, sheet_name=f'{data}PSTH', index=True, header=True)\n",
    "                        AVGArraybefore.to_excel(excel_writerMeannBef, sheet_name=f'{data}PSTH', index=True, header=True)\n",
    "                        AVGArrayallbefore.to_excel(excel_writerMeannAllBef, sheet_name=f'{data}PSTH', index=True, header=True)\n",
    "\n",
    "                    if data=='Ca':\n",
    "                        try: \n",
    "                            NbNr.loc['PsNr %'] = round(NbNr.loc['PsNr'] / NbNr.loc['AllNr'] *100)\n",
    "                            NbNr.loc['NoModNr %'] = round(NbNr.loc['NoModNr'] / NbNr.loc['AllNr'] *100)\n",
    "                            NbNr.loc['NgNr %'] = round(NbNr.loc['NgNr'] / NbNr.loc['AllNr']*100)\n",
    "                        except:                        \n",
    "                            None\n",
    "                        NbNr.to_excel(excel_writerPN, sheet_name=f'{data}', index=True, header=True)\n",
    "                        excel_writerPN.close()\n",
    "\n",
    "                for coup in Coupling:\n",
    "                    excel_writerAVGn=locals()[f'excel_writerAVG{coup}']\n",
    "                    excel_writerMeann=locals()[f'excel_writerMean{coup}']\n",
    "                    excel_writerMeannBase=locals()[f'excel_writerMeanBase{coup}']\n",
    "                    excel_writerMeannBef=locals()[f'excel_writerMeanBef{coup}']\n",
    "                    excel_writerMeannAllBef=locals()[f'excel_writerMeanAllBef{coup}']\n",
    "                    excel_writerAVGn.close()                   \n",
    "                    excel_writerMeann.close() \n",
    "                    excel_writerMeannBase.close()     \n",
    "                    excel_writerMeannBef.close()                   \n",
    "                    excel_writerMeannAllBef.close()                   \n",
    "            \n",
    "    #######################\n",
    "    # Propreties Osc\n",
    "    #######################\n",
    "    filenameOut = f'{folder_to_save}/{Osc}Propreties.xlsx'\n",
    "    writer = pd.ExcelWriter(filenameOut)\n",
    "\n",
    "    combined_dfOsc = combined_df.drop_duplicates(subset=f'{Osc}_ID', keep='first')\n",
    "\n",
    "    if Osc== 'SWR':\n",
    "        Count = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'SWR_inside_Spdl']])\n",
    "        AllOscSWRinside=pd.concat([AllOscSWRinside, Count], axis=0) \n",
    "        Count = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'{Osc}Statut']])\n",
    "        AllOscStatut=pd.concat([AllOscStatut, Count], axis=0)    \n",
    "        OscDuration = combined_dfOsc.pivot_table(index='Mice', columns=[combined_dfOsc['Drug'],combined_dfOsc[f'{Osc}Statut']] , values=f'{Osc}Duration', aggfunc='mean')\n",
    "        AllOscDuration=pd.concat([AllOscDuration, OscDuration], axis=0)       \n",
    "    elif Osc== 'Spdl':\n",
    "        Count = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'SWR_inside_Spdl']])\n",
    "        AllOscSWRinside=pd.concat([AllOscSWRinside, Count], axis=0) \n",
    "        GlobalSpindle = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'GlobalSpindle'], combined_dfOsc[f'{Osc}StartLocation']])\n",
    "        AllGlobalSpindle=pd.concat([AllGlobalSpindle, GlobalSpindle], axis=0)\n",
    "        Count = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'],combined_dfOsc['GlobalSpindle'], combined_dfOsc[f'{Osc}StartLocation']])\n",
    "        AllOscStartLocation=pd.concat([AllOscStartLocation, Count], axis=0)\n",
    "        OscDuration = combined_dfOsc.pivot_table(index='Mice', columns=[combined_dfOsc['Drug'],combined_dfOsc['GlobalSpindle'], combined_dfOsc[f'{Osc}StartLocation']] , values=f'{Osc}Duration', aggfunc='mean')\n",
    "        AllOscDuration=pd.concat([AllOscDuration, OscDuration], axis=0)\n",
    "        Count = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'GlobalSpindle'],  combined_dfOsc[f'{Osc}StartLocation'], combined_dfOsc[f'{Osc}Statut']])\n",
    "        AllOscCoupling=pd.concat([AllOscCoupling, Count], axis=0)\n",
    "        Count = pd.crosstab(index=combined_dfOsc['Mice'],columns=[combined_dfOsc['Drug'], combined_dfOsc[f'GlobalSpindle'],  combined_dfOsc[f'{Osc}Statut']])\n",
    "        AllOscStatut=pd.concat([AllOscStatut, Count], axis=0)\n",
    "          \n",
    "    AllOscDuration.to_excel(writer, sheet_name=f'MeanDuration')\n",
    "    AllOscSWRinside.to_excel(writer, sheet_name=f'SWR_inside_Spdl')\n",
    "    AllOscStatut.to_excel(writer, sheet_name=f'CouplingStatut')\n",
    "    if Osc== 'Spdl':\n",
    "        AllOscCoupling.to_excel(writer, sheet_name=f'CouplingPerSpdlLoc')    \n",
    "        AllGlobalSpindle.to_excel(writer, sheet_name=f'GlobalSpindle')\n",
    "        AllOscStartLocation.to_excel(writer, sheet_name=f'StartLocation')\n",
    "       \n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
