{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38784a29",
   "metadata": {},
   "source": [
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4125e588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "from scipy import fftpack\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "from IPython.display import display\n",
    "from ipyfilechooser import FileChooser\n",
    "from ephyviewer import mkQApp, MainViewer, TraceViewer\n",
    "from ephyviewer import AnalogSignalSourceWithScatter\n",
    "import ephyviewer\n",
    "from scipy.stats import zscore\n",
    "from scipy.interpolate import interp1d\n",
    "from itertools import groupby\n",
    "import sys \n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import chirp, find_peaks, peak_widths\n",
    "from scipy import stats\n",
    "import matplotlib.colors as mcolors\n",
    "import warnings\n",
    "from scipy import interpolate\n",
    "import re\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import ks_2samp\n",
    "import diptest\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "import ast\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ef8488",
   "metadata": {},
   "source": [
    "### Correlation across vigilance states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f1a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # tries to retrieve dfilepath either from a previous run or from a previous notebook\n",
    "    %store -r dfilepath\n",
    "except:\n",
    "    print(\"the path was not defined in store\")\n",
    "    #dpath = \"/Users/mb/Documents/Syntuitio/AudreyHay/PlanB/ExampleRedLines/2022_08_06/13_30_01/My_V4_Miniscope/\"\n",
    "dfilepath = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/\"\n",
    "\n",
    "fc1 = FileChooser(dfilepath,select_default=True, show_only_dirs = False, title = \"<b>Load excel or pkl file</b>\")\n",
    "display(fc1)\n",
    "\n",
    "# Sample callback function\n",
    "def update_my_folder(chooser):\n",
    "    global dfilepath\n",
    "    dfilepath = chooser.selected\n",
    "    %store dfilepath\n",
    "    return \n",
    "\n",
    "# Register callback function\n",
    "fc1.register_callback(update_my_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a002fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    combined_df = pd.read_excel(dfilepath, index_col=0 , sheet_name=None)\n",
    "except:\n",
    "    with open(dfilepath, 'rb') as pickle_file:\n",
    "        combined_df = pickle.load(pickle_file)\n",
    "        \n",
    "# dfilepath=\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_global_analysis/AVG_VigSt_2025-04-17_15_22_48_TEST/Baseline/Cluster0units/L1NDNF_mice_VigSt_PairCorrCa_Cluster0units.xlsx\"\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "VMAX=1\n",
    "VMIN=-.2\n",
    "\n",
    "CaCorrMatrix=combined_df['baseline_AW']\n",
    "df = CaCorrMatrix.apply(pd.to_numeric, errors='coerce')\n",
    "ax = sns.heatmap(df, ax=axes[0], square=True, vmin=VMIN , vmax=VMAX , cmap='viridis',\n",
    "                                  cbar_kws={'shrink': 0.6, 'aspect': 20})\n",
    "# Set only the first and last ticks for x and y axes\n",
    "# Get the number of ticks\n",
    "x_ticks = ax.get_xticks()\n",
    "y_ticks = ax.get_yticks()\n",
    "ax.set_xticks([x_ticks[0], x_ticks[-1]])\n",
    "ax.set_yticks([y_ticks[0], y_ticks[-1]])\n",
    "\n",
    "# Optionally, set the labels for these ticks if needed\n",
    "ax.set_xticklabels([f'#{int(x_ticks[0])+1}', f'#{int(x_ticks[-1])+1}'],size=6)\n",
    "ax.set_yticklabels([f'#{int(y_ticks[0])+1}', f'#{int(y_ticks[-1])+1}'],size=6)\n",
    "\n",
    "# Optionally, add labels for the axes if needed\n",
    "ax.set_xlabel('Neurons', labelpad=-2,size=8) \n",
    "ax.set_ylabel('Neurons', labelpad=-8,size=8) \n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=6)  # Adjust the font size here\n",
    "cbar.set_label('Correlation coefficient (r)', fontsize=8, font='Arial', rotation=-90, labelpad=10)\n",
    "ax.xaxis.set_ticks_position('top')  # Move ticks to the top\n",
    "ax.xaxis.set_label_position('top')  # Move label to the top\n",
    "axes[0].set_title(f'AW (r={(np.round(np.nanmean(CaCorrMatrix),2))})', fontsize=12)\n",
    "\n",
    "\n",
    "CaCorrMatrix=combined_df['baseline_QW']\n",
    "df = CaCorrMatrix.apply(pd.to_numeric, errors='coerce')\n",
    "ax = sns.heatmap(df, ax=axes[1], square=True, vmin=VMIN , vmax=VMAX , cmap='viridis',\n",
    "                                  cbar_kws={'shrink': 0.6, 'aspect': 20})\n",
    "# Set only the first and last ticks for x and y axes\n",
    "# Get the number of ticks\n",
    "x_ticks = ax.get_xticks()\n",
    "y_ticks = ax.get_yticks()\n",
    "ax.set_xticks([x_ticks[0], x_ticks[-1]])\n",
    "ax.set_yticks([y_ticks[0], y_ticks[-1]])\n",
    "\n",
    "# Optionally, set the labels for these ticks if needed\n",
    "ax.set_xticklabels([f'#{int(x_ticks[0])+1}', f'#{int(x_ticks[-1])+1}'],size=6)\n",
    "ax.set_yticklabels([f'#{int(y_ticks[0])+1}', f'#{int(y_ticks[-1])+1}'],size=6)\n",
    "\n",
    "# Optionally, add labels for the axes if needed\n",
    "ax.set_xlabel('Neurons', labelpad=-2,size=8) \n",
    "ax.set_ylabel('Neurons', labelpad=-8,size=8) \n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=6)  # Adjust the font size here\n",
    "cbar.set_label('Correlation coefficient (r)', fontsize=8, font='Arial', rotation=-90, labelpad=10)\n",
    "ax.xaxis.set_ticks_position('top')  # Move ticks to the top\n",
    "ax.xaxis.set_label_position('top')  # Move label to the top\n",
    "axes[1].set_title(f'QW (r={(np.round(np.nanmean(CaCorrMatrix),2))})', fontsize=12)\n",
    "\n",
    "\n",
    "CaCorrMatrix=combined_df['baseline_NREM']\n",
    "df = CaCorrMatrix.apply(pd.to_numeric, errors='coerce')\n",
    "ax = sns.heatmap(df, ax=axes[2], square=True, vmin=VMIN , vmax=VMAX , cmap='viridis',\n",
    "                                  cbar_kws={'shrink': 0.6, 'aspect': 20})\n",
    "# Set only the first and last ticks for x and y axes\n",
    "# Get the number of ticks\n",
    "x_ticks = ax.get_xticks()\n",
    "y_ticks = ax.get_yticks()\n",
    "ax.set_xticks([x_ticks[0], x_ticks[-1]])\n",
    "ax.set_yticks([y_ticks[0], y_ticks[-1]])\n",
    "\n",
    "# Optionally, set the labels for these ticks if needed\n",
    "ax.set_xticklabels([f'#{int(x_ticks[0])+1}', f'#{int(x_ticks[-1])+1}'],size=6)\n",
    "ax.set_yticklabels([f'#{int(y_ticks[0])+1}', f'#{int(y_ticks[-1])+1}'],size=6)\n",
    "\n",
    "# Optionally, add labels for the axes if needed\n",
    "ax.set_xlabel('Neurons', labelpad=-2,size=8) \n",
    "ax.set_ylabel('Neurons', labelpad=-8,size=8) \n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=6)  # Adjust the font size here\n",
    "cbar.set_label('Correlation coefficient (r)', fontsize=8, font='Arial', rotation=-90, labelpad=10)\n",
    "ax.xaxis.set_ticks_position('top')  # Move ticks to the top\n",
    "ax.xaxis.set_label_position('top')  # Move label to the top\n",
    "axes[2].set_title(f'NREM (r={(np.round(np.nanmean(CaCorrMatrix),2))})', fontsize=12)\n",
    "\n",
    "\n",
    "\n",
    "CaCorrMatrix=combined_df['baseline_REM']\n",
    "df = CaCorrMatrix.apply(pd.to_numeric, errors='coerce')\n",
    "ax = sns.heatmap(df, ax=axes[3], square=True, vmin=VMIN , vmax=VMAX , cmap='viridis',\n",
    "                                  cbar_kws={'shrink': 0.6, 'aspect': 20})\n",
    "# Set only the first and last ticks for x and y axes\n",
    "# Get the number of ticks\n",
    "x_ticks = ax.get_xticks()\n",
    "y_ticks = ax.get_yticks()\n",
    "ax.set_xticks([x_ticks[0], x_ticks[-1]])\n",
    "ax.set_yticks([y_ticks[0], y_ticks[-1]])\n",
    "\n",
    "# Optionally, set the labels for these ticks if needed\n",
    "ax.set_xticklabels([f'#{int(x_ticks[0])+1}', f'#{int(x_ticks[-1])+1}'],size=6)\n",
    "ax.set_yticklabels([f'#{int(y_ticks[0])+1}', f'#{int(y_ticks[-1])+1}'],size=6)\n",
    "\n",
    "# Optionally, add labels for the axes if needed\n",
    "ax.set_xlabel('Neurons', labelpad=-2,size=8) \n",
    "ax.set_ylabel('Neurons', labelpad=-8,size=8) \n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=6)  # Adjust the font size here\n",
    "cbar.set_label('Correlation coefficient (r)', fontsize=8, font='Arial', rotation=-90, labelpad=10)\n",
    "ax.xaxis.set_ticks_position('top')  # Move ticks to the top\n",
    "ax.xaxis.set_label_position('top')  # Move label to the top\n",
    "axes[3].set_title(f'REM (r={np.round(np.nanmean(CaCorrMatrix),2)})', fontsize=12)\n",
    "\n",
    "\n",
    "#plt.savefig(f'C:/Users/Manip2/Documents/ElifePaper/Rawdata/Extract{mice}_{folder_base.parts[-2]}_3VigSt_{beg}to{fin}s_2heatmap.svg', format='svg', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f8d562",
   "metadata": {},
   "source": [
    "### Cell assemblies activity across vigilance states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe30b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # tries to retrieve dfilepath either from a previous run or from a previous notebook\n",
    "    %store -r dfilepath\n",
    "except:\n",
    "    print(\"the path was not defined in store\")\n",
    "    #dpath = \"/Users/mb/Documents/Syntuitio/AudreyHay/PlanB/ExampleRedLines/2022_08_06/13_30_01/My_V4_Miniscope/\"\n",
    "    dfilepath = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/\"\n",
    "\n",
    "fc1 = FileChooser(Path(dfilepath).parent, select_default=True, show_only_dirs = False, title = \"<b>Load excel file</b>\")\n",
    "display(fc1)\n",
    "\n",
    "# Sample callback function\n",
    "def update_my_folder(chooser):\n",
    "    global dfilepath\n",
    "    dfilepath = chooser.selected\n",
    "    %store dfilepath\n",
    "    return \n",
    "\n",
    "# Register callback function\n",
    "fc1.register_callback(update_my_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be71041a",
   "metadata": {},
   "source": [
    "Plot Cell assembly activity relative to Vig States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3e653",
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    combined_df0 = pd.read_excel(dfilepath, index_col=0)\n",
    "except:\n",
    "    with open(dfilepath, 'rb') as pickle_file:\n",
    "        combined_df0 = pickle.load(pickle_file)\n",
    "#dfilepath=\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_baseline_analysis/VigSt_2025-04-21_09_46_24_noCorr/CellAssembly_Global.xlsx\"\n",
    "\n",
    "combined_df00=combined_df0.copy()\n",
    "combined_df00['Cells_in_Assembly']=combined_df00['Cells_in_Assembly'] = combined_df00['Cells_in_Assembly'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "combined_df00 = combined_df00[combined_df00['Cells_in_Assembly'].apply(len) == combined_df00['Assembly_size']]\n",
    "try :\n",
    "    combined_df00.to_excel(dfilepath)\n",
    "except:\n",
    "    with open(dfilepath, 'wb') as pickle_file:\n",
    "        pickle.dump(combined_df00, pickle_file)\n",
    "\n",
    "#combined_df00 = combined_df00[combined_df00['ExpeType'] == 'baseline']\n",
    "\n",
    "NrSubtype='L2_3_mice' # L1NDNF_mice OR L2_3_mice\n",
    "combined_df= combined_df00[combined_df00['NeuronType']==NrSubtype]\n",
    "plt.figure(figsize=(6, 6))\n",
    "combined_df2 = combined_df.pivot_table(index='Assembly_ID', columns=[combined_df['Substate']], values='Avg_Activity', aggfunc='mean', fill_value=None)\n",
    "desired_order = ['AW','QW', 'NREM', 'IS', 'REM', 'undefined']   \n",
    "try: combined_df2 = combined_df2[desired_order]\n",
    "except: pass\n",
    "try:del combined_df2['undefined']\n",
    "except: pass\n",
    "try:del combined_df2['IS']\n",
    "except: pass\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(combined_df2.columns, combined_df2.values.T, alpha=0.5, linewidth=2)\n",
    "plt.ylabel('Avg activity per cell assemblies')\n",
    "plt.title(f'{NrSubtype}, n={len(combined_df2)}')\n",
    "plt.tight_layout()\n",
    "\n",
    "combined_df2 = combined_df.pivot_table(index='Assembly_ID', columns=[combined_df['Substate']], values='EventFreq', aggfunc='mean', fill_value=None)\n",
    "try: combined_df2 = combined_df2[desired_order]\n",
    "except: pass\n",
    "try:del combined_df2['undefined']\n",
    "except: pass\n",
    "try:del combined_df2['IS']\n",
    "except: pass\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(combined_df2.columns, combined_df2.values.T, alpha=0.5, linewidth=2)\n",
    "plt.ylabel('Event frequency per cell assemblies')\n",
    "\n",
    "NrSubtype='L1NDNF_mice' # L1NDNF_mice OR L2_3_mice\n",
    "combined_df= combined_df00[combined_df00['NeuronType']==NrSubtype]\n",
    "combined_df2 = combined_df.pivot_table(index='Assembly_ID', columns=[combined_df['Substate']], values='Avg_Activity', aggfunc='mean', fill_value=None)\n",
    "desired_order = ['AW','QW', 'NREM', 'IS', 'REM', 'undefined']   \n",
    "try: combined_df2 = combined_df2[desired_order]\n",
    "except: pass\n",
    "try:del combined_df2['undefined']\n",
    "except: pass\n",
    "try:del combined_df2['IS']\n",
    "except: pass\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(combined_df2.columns, combined_df2.values.T, alpha=0.5, linewidth=2)\n",
    "plt.ylabel('Avg activity per cell assemblies')\n",
    "plt.title(f'{NrSubtype}, n={len(combined_df2)}')\n",
    "plt.tight_layout()\n",
    "\n",
    "combined_df2 = combined_df.pivot_table(index='Assembly_ID', columns=[combined_df['Substate']], values='EventFreq', aggfunc='mean', fill_value=None)\n",
    "try: combined_df2 = combined_df2[desired_order]\n",
    "except: pass\n",
    "try:del combined_df2['undefined']\n",
    "except: pass\n",
    "try:del combined_df2['IS']\n",
    "except: pass\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(combined_df2.columns, combined_df2.values.T, alpha=0.5, linewidth=2)\n",
    "plt.ylabel('Event frequency per cell assemblies')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba658cd2",
   "metadata": {},
   "source": [
    "### Cell assembly identity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb4c635",
   "metadata": {},
   "source": [
    "Load VigSt_Global_cluster file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7046e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{Path(dfilepath).parent}/VigStates_Global_cluster.pkl', 'rb') as pickle_file:\n",
    "    df_cluster = pickle.load(pickle_file)\n",
    "\n",
    "df_cluster = df_cluster[df_cluster['NeuronType'] == 'L1NDNF_mice']\n",
    "df_cluster_Drug = df_cluster.copy()\n",
    "\n",
    "#df_cluster_Drug = df_cluster_Drug[df_cluster_Drug['Drug'] == 'baseline']\n",
    "\n",
    "AllBaselineUnits = df_cluster_Drug['Unit_ID'].unique()\n",
    "Cluster0units = df_cluster_Drug[df_cluster_Drug['ClusterHDBSCAN'] == 0]['Unit_ID'].unique()\n",
    "Cluster1units = df_cluster_Drug[df_cluster_Drug['ClusterHDBSCAN'] == 1]['Unit_ID'].unique()\n",
    "Cluster2units = df_cluster_Drug[df_cluster_Drug['ClusterHDBSCAN'] == 2]['Unit_ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de062dec",
   "metadata": {},
   "source": [
    "Identify Cell assembly Cluster ID and test proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829e8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup: Individuals and clusters\n",
    "new_df2 = combined_df.drop_duplicates(subset='Assembly_ID', keep='first')\n",
    "new_df2 = new_df2[new_df2['Cells_in_Assembly'].apply(len) == new_df2['Assembly_size']]\n",
    "groups = new_df2['Cells_in_Assembly'].tolist()\n",
    "df_unique = df_cluster_Drug.drop_duplicates(subset='Unit_ID', keep='first')\n",
    "df_unique = df_unique.dropna(subset=['ClusterHDBSCAN'])\n",
    "ids=df_unique['Unit_ID'].tolist()\n",
    "id_to_cluster = dict(zip(df_unique['Unit_ID'], np.floor(df_unique['ClusterHDBSCAN']).astype(str)))\n",
    "cluster_labels = ['0.0']*len(Cluster0units) + ['1.0']*len(Cluster1units) + ['2.0']*len(Cluster2units)\n",
    "#cluster_labels = new_df2_c['Assembly_Cluster_ID'].tolist()\n",
    "\n",
    "def classify_groups(groups, id_to_cluster):\n",
    "    labels = []\n",
    "    for group in groups:\n",
    "        clusters = [id_to_cluster.get(i, np.nan) for i in group]\n",
    "        if len(clusters) >= 1:\n",
    "            count = Counter(clusters)\n",
    "            top, n_top = count.most_common(1)[0]\n",
    "            top_clusters = [k for k, v in count.items() if v == n_top]        \n",
    "            # If there are multiple top clusters or the majority is less than 50%, label as \"mixte\"\n",
    "            if len(top_clusters) == 1 and (n_top / len(group) * 100) > 50 and not pd.isna(top):\n",
    "                labels.append(top)\n",
    "            else:\n",
    "                labels.append(\"mixte\")  \n",
    "        else:\n",
    "            labels.append(\"mixte\")    \n",
    "    return labels\n",
    "\n",
    "# --- Observed classification\n",
    "observed_labels = classify_groups(groups, id_to_cluster)\n",
    "observed_counts = Counter(observed_labels)\n",
    "new_df2['Assembly_Cluster_ID']= observed_labels\n",
    "\n",
    "# --- Permutation test\n",
    "n_perms = 5000\n",
    "null_dists = defaultdict(list)\n",
    "\n",
    "for _ in range(n_perms):\n",
    "    # Shuffle cluster labels across individuals\n",
    "    shuffled_clusters = dict(zip(ids, random.sample(cluster_labels, len(cluster_labels))))\n",
    "    shuffled_labels = classify_groups(groups, shuffled_clusters)\n",
    "    counts = Counter(shuffled_labels)\n",
    "    for label in observed_counts:\n",
    "        null_dists[label].append(counts.get(label, 0))\n",
    "\n",
    "# --- Z-scores and p-values\n",
    "results = []\n",
    "for label in observed_counts:\n",
    "    obs = observed_counts[label]\n",
    "    null = null_dists[label]\n",
    "    mean = np.mean(null)\n",
    "    std = np.std(null)\n",
    "    z = (obs - mean) / std if std > 0 else 0\n",
    "    # Two-tailed p-value\n",
    "    p = (np.sum(np.abs(np.array(null) - mean) >= abs(obs - mean)) + 1) / (n_perms + 1)\n",
    "    results.append((label, obs, mean, std, z, p))\n",
    "\n",
    "# --- Output\n",
    "print(\"\\nAssembly Cluster ID Distribution Test\")\n",
    "print(f\"{'ID':>10} {'Obs':>5} {'Mean':>7} {'Std':>7} {'Z':>6} {'p-value':>8}\")\n",
    "for label, obs, mean, std, z, p in sorted(results, key=lambda x: x[-1]):\n",
    "    print(f\"{label:>10} {obs:5} {mean:7.2f} {std:7.2f} {z:6.2f} {p:8.4f}\")\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\"Cell_Assembly_ID\", \"Obs\", \"PermMean\", \"Std\", \"Z\", \"p\"])\n",
    "df['Obs_prop'] = df['Obs'] / df['Obs'].sum() *100\n",
    "df['Perm_prop'] = df['PermMean'] / df['PermMean'].sum() *100\n",
    "df[\"Perm_std\"] = df[\"Std\"] / df[\"PermMean\"].sum() *100\n",
    "\n",
    "df = df.sort_values(\"Cell_Assembly_ID\")  # or use a custom order\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.errorbar(df[\"Cell_Assembly_ID\"], df[\"Perm_prop\"], yerr=df[\"Perm_std\"], fmt='o', color='gray', label='Permuted ± std')\n",
    "plt.scatter(df[\"Cell_Assembly_ID\"], df[\"Obs_prop\"], color='black', label='Observed')\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.title(\"Observed vs Permuted Proportions\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2dff61",
   "metadata": {},
   "source": [
    "Save cell assembly ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe5f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(combined_df0, new_df2[['Assembly_ID', 'Assembly_Cluster_ID']], on='Assembly_ID', how='outer')\n",
    "merged.to_excel(f'{Path(dfilepath).parent}/CellAssembly_Global_cluster_ID.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9965d2",
   "metadata": {},
   "source": [
    "Activity of cell assemblies per ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d67d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged[merged['Substate'] != 'IS']\n",
    "merged = merged[merged['Substate'] != 'undefined']\n",
    "combined_df2 = merged.pivot_table(index='Assembly_ID', columns=[merged['Assembly_Cluster_ID'], merged['Substate']], values='Avg_Activity', aggfunc='mean', fill_value=None)\n",
    "custom_order = ['AW', 'QW', 'NREM', 'REM']\n",
    "sort_key = {val: i for i, val in enumerate(custom_order)}\n",
    "sorted_cols = sorted(combined_df2.columns, key=lambda x: (x[0], sort_key.get(x[1], float('inf'))))\n",
    "combined_df2 = combined_df2[sorted_cols]\n",
    "\n",
    "plt.figure(figsize=(7, 3))\n",
    "for idx, row in combined_df2.iterrows():\n",
    "    plt.plot(row.values, label=f'{idx}', alpha=0.5, linewidth=2)  # `idx` is the MultiIndex for each row\n",
    "plt.ylabel('Avg activity per cell assemblies')\n",
    "plt.tight_layout()\n",
    "plt.xticks(ticks= np.arange(len(combined_df2.columns.get_level_values(1))),  labels=combined_df2.columns.get_level_values(1)) \n",
    "plt.title('Cluster0                Cluster1                Cluster2                   Mixte')\n",
    "\n",
    "\n",
    "combined_df2 = merged.pivot_table(index='Assembly_ID', columns=[merged['Assembly_Cluster_ID'], merged['Substate']], values='EventFreq', aggfunc='mean', fill_value=None)\n",
    "custom_order = ['AW', 'QW', 'NREM', 'REM']\n",
    "sort_key = {val: i for i, val in enumerate(custom_order)}\n",
    "sorted_cols = sorted(combined_df2.columns, key=lambda x: (x[0], sort_key.get(x[1], float('inf'))))\n",
    "combined_df2 = combined_df2[sorted_cols]\n",
    "\n",
    "plt.figure(figsize=(7, 3))\n",
    "for idx, row in combined_df2.iterrows():\n",
    "    plt.plot(row.values, label=f'{idx}', alpha=0.5, linewidth=2)  # `idx` is the MultiIndex for each row\n",
    "plt.ylabel('Event frequency per cell assemblies')\n",
    "plt.tight_layout()\n",
    "plt.xticks(ticks= np.arange(len(combined_df2.columns.get_level_values(1))),  labels=combined_df2.columns.get_level_values(1)) \n",
    "plt.title('Cluster0                Cluster1                Cluster2                   Mixte')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
