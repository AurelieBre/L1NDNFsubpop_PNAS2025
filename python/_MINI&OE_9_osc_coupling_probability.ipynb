{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff7bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Associate Ca2+ signal with spindles for each session & subsessions using crossregistration\n",
    "\n",
    "#######################################################################################\n",
    "                            # Define Experiment type #\n",
    "#######################################################################################\n",
    "\n",
    "DrugExperiment=0 # 0 if Baseline Experiment / 1 if CGP Experiment\n",
    "\n",
    "saveexcel=1\n",
    "\n",
    "AHmethod=0 # 0 if using the method of Aurelie B (2025) / 1 if using the method of Audrey Hay (2025)\n",
    "\n",
    "AnalysisID='_likeAH' if AHmethod else '_pynapple' # '_pynapple' if using the method of Aurelie Hay (2025) / '_minian' if using the method of Audrey Hay (2025)\n",
    "suffix='_fineDetection'\n",
    "\n",
    "CTX=['S1', 'PFC', 'S1PFC']\n",
    "Coupling=['', 'UnCoupled', 'PreCoupled', 'PostCoupled', 'PrePostCoupled']\n",
    "dir = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/\"\n",
    "\n",
    "drugs=['baseline', 'CGP'] if DrugExperiment else ['baseline']\n",
    "\n",
    "#######################################################################################\n",
    "                                # Load packages #\n",
    "#######################################################################################\n",
    "\n",
    "import os\n",
    "import quantities as pq\n",
    "import numpy as np\n",
    "import math \n",
    "import neo\n",
    "import json\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "from scipy.interpolate import interp2d\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import zscore\n",
    "import pickle\n",
    "import os\n",
    "from scipy.interpolate import griddata\n",
    "import logging\n",
    "import sys \n",
    "import shutil\n",
    "from bisect import bisect_left\n",
    "from ast import literal_eval\n",
    "from scipy import interpolate\n",
    "import time\n",
    "\n",
    "from itertools import groupby\n",
    "from ephyviewer import mkQApp, MainViewer, TraceViewer\n",
    "from IPython.display import display\n",
    "from ipyfilechooser import FileChooser\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "minian_path = os.path.join(os.path.abspath('.'),'minian')\n",
    "print(\"The folder used for minian procedures is : {}\".format(minian_path))\n",
    "sys.path.append(minian_path)\n",
    "\n",
    "#######################################################################################\n",
    "                                # Define functions #\n",
    "#######################################################################################\n",
    "\n",
    "def is_between(myList, starttime, endtime):\n",
    "    IsTrue=False\n",
    "    for ind in range(len(myList)):\n",
    "        if starttime <= myList[ind] <= endtime:\n",
    "            IsTrue=True\n",
    "    return IsTrue\n",
    "\n",
    "def is_overlapping(starttime, endtime, starttimeList, endtimeList):\n",
    "    IsTrue='False'\n",
    "    for ind in starttimeList.index: #range(len(starttimeList)):\n",
    "        if starttime<=starttimeList[ind] and starttimeList[ind]<=endtime: # event n°2 begins after the start n°1               \n",
    "            if (endtime-starttimeList[ind])>=int(0.5*(endtime-starttime)): # overlapp > to 50% of the duration of the event n°1\n",
    "                IsTrue='True'\n",
    "                break                \n",
    "        elif starttime<=endtimeList[ind] and endtimeList[ind]<=endtime: # event n°2 ends before the end n°1 \n",
    "            if (endtimeList[ind]-starttime)>=int(0.5*(endtime-starttime)): # overlapp > to 50% of the duration of the event n°1\n",
    "                IsTrue='True'\n",
    "                break\n",
    "    return IsTrue, ind\n",
    "\n",
    "def find_session_folders(root_path):\n",
    "    sessions = []\n",
    "    sessions_path=[]\n",
    "    # Iterate through items in the root_path\n",
    "    for item in os.listdir(root_path):\n",
    "        item_path = os.path.join(root_path, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            # Check if the directory name contains \"session\"\n",
    "            if \"session\" in item:\n",
    "                sessions.append(item)\n",
    "                sessions_path.append(item_path)\n",
    "            else:\n",
    "                # Check the subdirectories of the current directory\n",
    "                for sub_item in os.listdir(item_path):\n",
    "                    sub_item_path = os.path.join(item_path, sub_item)\n",
    "                    if os.path.isdir(sub_item_path) and \"session\" in sub_item:\n",
    "                        sessions.append(sub_item)\n",
    "                        sessions_path.append(sub_item_path)\n",
    "                        \n",
    "    return sessions, sessions_path\n",
    "\n",
    "def restriction_parameter(All_Spindle):\n",
    "    nb_spindle = All_Spindle.shape[0]\n",
    "    listtodrop = []\n",
    "    for tt in range(nb_spindle-1):\n",
    "        # merge spdl that starts within a spdl\n",
    "        if(All_Spindle['end time'][tt]>All_Spindle['start time'][tt + 1]):\n",
    "            if(All_Spindle['Duration'][tt]<All_Spindle['Duration'][tt + 1]):\n",
    "                if(All_Spindle['start time'][tt]<All_Spindle['start time'][tt + 1]):\n",
    "                    All_Spindle['start time'][tt+1] = All_Spindle['start time'][tt]\n",
    "                    listtodrop.append(tt)\n",
    "                else:\n",
    "                    listtodrop.append(tt)\n",
    "            if(All_Spindle['Duration'][tt]>All_Spindle['Duration'][tt + 1]):\n",
    "                if(All_Spindle['end time'][tt]<All_Spindle['end time'][tt + 1]):\n",
    "                    All_Spindle['end time'][tt] = All_Spindle['end time'][tt + 1]\n",
    "                    listtodrop.append(tt+1)\n",
    "                else:\n",
    "                    listtodrop.append(tt+1)\n",
    "    \"\"\"\n",
    "    for tt in range(nb_spindle-1):\n",
    "        # merge spdls that are 200ms apart\n",
    "        if((All_Spindle['start time'][tt + 1] - All_Spindle['end time'][tt])<200):\n",
    "            if((All_Spindle['Duration'][tt])<All_Spindle['Duration'][tt + 1]): #first spdl longer so remove/merge the second one\n",
    "                All_Spindle['start time'][tt + 1] = min(All_Spindle['start time'][tt], All_Spindle['start time'][tt+1])\n",
    "                All_Spindle['end time'][tt+ 1] = max(All_Spindle['end time'][tt + 1], All_Spindle['end time'][tt])\n",
    "                listtodrop.append(tt)\n",
    "            if((All_Spindle['Duration'][tt+1])<All_Spindle['Duration'][tt]): #second spdl longer so remove/merge the first one\n",
    "                All_Spindle['start time'][tt] = min(All_Spindle['start time'][tt], All_Spindle['start time'][tt+1])\n",
    "                All_Spindle['end time'][tt] = max(All_Spindle['end time'][tt + 1], All_Spindle['end time'][tt])\n",
    "                listtodrop.append(tt+1)\n",
    "    \"\"\"\n",
    "    for tt in range(nb_spindle):\n",
    "        #Update duration because of the merging\n",
    "        All_Spindle['Duration'][tt]=All_Spindle['end time'][tt]-All_Spindle['start time'][tt]\n",
    "\n",
    "    for tt in range(nb_spindle): #All_Spindle.index:\n",
    "        #Remove Spdl that last less than 500ms\n",
    "        if (All_Spindle['Duration'][tt]<500):\n",
    "            listtodrop.append(tt)        \n",
    "    \n",
    "    All_Spindle = All_Spindle.drop(listtodrop) \n",
    "    All_Spindle = All_Spindle.reset_index(drop=True)\n",
    "    return All_Spindle\n",
    "\n",
    "#######################################################################################\n",
    "                # Load sleep score and Ca2+ time series numpy arrays #\n",
    "#######################################################################################\n",
    "\n",
    "all_expe_types=['baseline', 'preCGP', 'postCGP'] if DrugExperiment else ['baseline', 'preCGP']\n",
    "\n",
    "# Get the current date and time\n",
    "FolderNameSave=str(datetime.now())[:19]\n",
    "FolderNameSave = FolderNameSave.replace(\" \", \"_\").replace(\".\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "destination_folder= f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_CGP_analysis/Osc_{FolderNameSave}{suffix}{AnalysisID}\" if DrugExperiment else f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_baseline_analysis/Osc_{FolderNameSave}{suffix}{AnalysisID}\"\n",
    "os.makedirs(destination_folder)\n",
    "folder_to_save=Path(destination_folder)\n",
    "\n",
    "# Copy the script file to the destination folder\n",
    "source_script = \"C:/Users/Manip2/SCRIPTS/CodePythonAudrey/CodePythonAurelie/HayLabAnalysis/python/_MINI&OE_9_osc_coupling_probability.ipynb\"\n",
    "destination_file_path = f\"{destination_folder}/_MINI&OE_9_osc_coupling_probability.txt\"\n",
    "shutil.copy(source_script, destination_file_path)\n",
    "     \n",
    "\n",
    "for dpath in Path(dir).glob('**/mappingsAB.pkl'):\n",
    "    \n",
    "    mappfile = open(dpath.parents[0]/ f'mappingsAB.pkl', 'rb')\n",
    "    mapping = pickle.load(mappfile)\n",
    "    mapping_sess = mapping['session']   \n",
    "\n",
    "    mice = dpath.parents[0].parts[-1]\n",
    "    NeuronType = dpath.parents[1].parts[-1]\n",
    "    \n",
    "    print(f\"####################################################################################\")\n",
    "    print(f\"################################### {mice} ####################################\")\n",
    "    print(f\"####################################################################################\")\n",
    "\n",
    "    subsessions = []\n",
    "    dict_SWRprop = {}\n",
    "    dict_Spindleprop = {}\n",
    "    dict_Path={}\n",
    "\n",
    "    AllSWRPFC=[]\n",
    "    AllSWRS1=[]\n",
    "    AllSpdlS1=[]\n",
    "    AllSpdlPFC=[]\n",
    "\n",
    "\n",
    "    minian_folders = [f for f in dpath.parents[0].rglob('minian') if f.is_dir()]\n",
    "\n",
    "    for minianpath in minian_folders: # for each minian folders found in this mouse\n",
    "\n",
    "        if any(p in all_expe_types for p in minianpath.parts): # have to be to the expe_types\n",
    "\n",
    "            start = time.time()\n",
    "            \n",
    "            session=minianpath.parents[0].name if len(minianpath.parts)==12 else minianpath.parents[1].name.split(\"_\")[-1]\n",
    "            session_path=minianpath.parents[2] if len(minianpath.parts)==12 else minianpath.parents[1]\n",
    "            expe_type=minianpath.parents[3].name if len(minianpath.parts)==12 else minianpath.parents[2].name\n",
    "\n",
    "            drug='CGP' if expe_type == 'postCGP' else 'baseline'\n",
    "            dict_Path[session] = session_path\n",
    "            \n",
    "            SWRlist= pd.read_csv(session_path / f'OpenEphys/SWRproperties.csv' ) if AHmethod else pd.read_csv(session_path / f'OpenEphys/SWR_finedetection.csv' ) \n",
    "            SWRlist['toKeep'] = 'True' # SWRlist['toKeep'].astype(str)\n",
    "            SWRprop  =SWRlist[SWRlist['toKeep'].isin(['VRAI', 'True'])]\n",
    "\n",
    "\n",
    "            Spdllist = pd.read_csv(session_path / f'OpenEphys/Spindleproperties_PFC.csv') if AHmethod else pd.read_csv(session_path / f'OpenEphys/SpindlesPFC_finedetection.csv' ) \n",
    "            Spdllist['toKeep'] = 'True' # Spdllist['toKeep'].astype(str)\n",
    "            PFClist  = Spdllist[Spdllist['toKeep'].isin(['VRAI', 'True'])]\n",
    "\n",
    "\n",
    "            Spdllist = pd.read_csv(session_path / f'OpenEphys/Spindleproperties_S1.csv') if AHmethod else pd.read_csv(session_path / f'OpenEphys/SpindlesS1_finedetection.csv' ) \n",
    "            Spdllist['toKeep'] = 'True' # Spdllist['toKeep'].astype(str)\n",
    "            S1list  = Spdllist[Spdllist['toKeep'].isin(['VRAI', 'True'])]\n",
    "            \n",
    "\n",
    "\n",
    "            if DrugExperiment: \n",
    "                PFClist['toKeep'] = PFClist['toKeep'].astype(str)\n",
    "                PFClist  = PFClist[PFClist['toKeep'].isin(['VRAI', 'True'])]\n",
    "            else: \n",
    "                PFClist['toKeep'] ='VRAI'\n",
    "            PFClist['CTX']='PFC'\n",
    "            PFClist['StartingLoc']='PFC'\n",
    "            PFClist = PFClist.reset_index(drop=True)\n",
    "            NewPFClist=PFClist#restriction_parameter(PFClist)                    \n",
    "            NewPFClist = NewPFClist[NewPFClist['toKeep'].isin(['True', 'VRAI'])]\n",
    "            NewPFClist = NewPFClist.sort_values(by='start time')\n",
    "            NewPFClist = NewPFClist.reset_index(drop=True)\n",
    "\n",
    "\n",
    "            if DrugExperiment: \n",
    "                S1list['toKeep'] = S1list['toKeep'].astype(str)\n",
    "                S1list  = S1list[S1list['toKeep'].isin(['VRAI', 'True'])]\n",
    "            else: \n",
    "                S1list['toKeep'] ='VRAI'\n",
    "            S1list['CTX']='S1'\n",
    "            S1list['StartingLoc']='S1'\n",
    "            S1list = S1list.reset_index(drop=True)\n",
    "            NewS1list=S1list#restriction_parameter(S1list)\n",
    "            NewS1list = NewS1list[NewS1list['toKeep'].isin(['True', 'VRAI'])]\n",
    "            NewS1list = NewS1list.sort_values(by='start time')\n",
    "            NewS1list = NewS1list.reset_index(drop=True)\n",
    "\n",
    "\n",
    "            #Aurelie's script\n",
    "            for spdl1 in NewS1list.index : # range(len(Spdllist)) :\n",
    "                start1=NewS1list[\"start time\"][spdl1]\n",
    "                end1=NewS1list[\"end time\"][spdl1]\n",
    "                start2list=NewPFClist[\"start time\"]\n",
    "                if len(start2list)>0:\n",
    "                    distancePFCspdl=min(start2list-start1, key=abs)      \n",
    "                    my_list=start2list-start1 \n",
    "                    filtered_listSpdl = [value for value in my_list if -5000 <= value <= 5000] # more or less 5 sec from the spdl\n",
    "                    AllSpdlS1+=filtered_listSpdl\n",
    "                else: \n",
    "                    distancePFCspdl=None        \n",
    "                start2list=SWRprop[\"start time\"]\n",
    "                if len(start2list)>0:\n",
    "                    distancSWR=min(start2list-start1, key=abs)\n",
    "                    my_list=start2list-start1 \n",
    "                    filtered_listSWR = [value for value in my_list if -5000 <= value <= 5000] # more or less 5 sec from the spdl\n",
    "                    AllSWRS1+=filtered_listSWR\n",
    "                else: \n",
    "                    distancSWR=None\n",
    "\n",
    "            for spdl1 in NewPFClist.index : # range(len(Spdllist)) :\n",
    "                start1=NewPFClist[\"start time\"][spdl1]\n",
    "                end1=NewPFClist[\"end time\"][spdl1]\n",
    "                \n",
    "                start2list=NewS1list[\"start time\"]\n",
    "                if len(start2list)>0:\n",
    "                    distanceS1spdl=min(start2list-start1, key=abs)  \n",
    "                    my_list=start2list-start1 \n",
    "                    filtered_listSpdl = [value for value in my_list if -5000 <= value <= 5000] # more or less 5 sec from the spdl\n",
    "                    AllSpdlPFC+=filtered_listSpdl \n",
    "                else: \n",
    "                    distanceS1spdl=None             \n",
    "                \n",
    "                start2list=SWRprop[\"start time\"]\n",
    "                if len(start2list)>0:\n",
    "                    distancSWR=min(start2list-start1, key=abs)\n",
    "                    my_list=start2list-start1 \n",
    "                    filtered_listSWR = [value for value in my_list if -5000 <= value <= 5000] # more or less 5 sec from the spdl\n",
    "                    AllSWRPFC+=filtered_listSWR\n",
    "                else: \n",
    "                    distancSWR=None\n",
    "\n",
    "    #######################################################################################\n",
    "                            # Save Spindles & SWR & DS analysis #\n",
    "    #######################################################################################\n",
    "    if saveexcel: \n",
    "\n",
    "        filenameOut = folder_to_save / f'SpdlPFC_couplinglist_{mice}.xlsx'\n",
    "        writer = pd.ExcelWriter(filenameOut)\n",
    "        df = pd.DataFrame(AllSpdlPFC, columns=['S1occurence'])\n",
    "        df.to_excel(writer)\n",
    "        writer.close()\n",
    "\n",
    "        filenameOut = folder_to_save / f'SpdlS1_couplinglist_{mice}.xlsx'\n",
    "        writer = pd.ExcelWriter(filenameOut)\n",
    "        df = pd.DataFrame(AllSpdlS1, columns=['PFCoccurence'])\n",
    "        df.to_excel(writer)\n",
    "        writer.close()\n",
    "        \n",
    "        filenameOut = folder_to_save / f'SWR_PFCcouplinglist_{mice}.xlsx'\n",
    "        writer = pd.ExcelWriter(filenameOut)\n",
    "        df = pd.DataFrame(AllSWRPFC, columns=['SWRoccurence'])\n",
    "        df.to_excel(writer)\n",
    "        writer.close()\n",
    "\n",
    "        filenameOut = folder_to_save / f'SWR_S1couplinglist_{mice}.xlsx'\n",
    "        writer = pd.ExcelWriter(filenameOut)\n",
    "        df = pd.DataFrame(AllSWRS1, columns=['SWRoccurence'])\n",
    "        df.to_excel(writer)\n",
    "        writer.close()\n",
    "    \n",
    "    filenameOut = folder_to_save / f'SpdlPFC_couplinglist_{mice}.pkl'\n",
    "    with open(filenameOut, 'wb') as pickle_file:\n",
    "        pickle.dump(AllSpdlPFC, pickle_file)          \n",
    "        \n",
    "    filenameOut = folder_to_save / f'SpdlS1_couplinglist_{mice}.pkl'\n",
    "    with open(filenameOut, 'wb') as pickle_file:\n",
    "        pickle.dump(AllSpdlS1, pickle_file)   \n",
    "\n",
    "    filenameOut = folder_to_save / f'SWR_PFCcouplinglist_{mice}.pkl'\n",
    "    with open(filenameOut, 'wb') as pickle_file:\n",
    "        pickle.dump(AllSWRPFC, pickle_file)           \n",
    "        \n",
    "    filenameOut = folder_to_save / f'SWR_S1couplinglist_{mice}.pkl'\n",
    "    with open(filenameOut, 'wb') as pickle_file:\n",
    "        pickle.dump(AllSWRS1, pickle_file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae699e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats on Ca2+ imaging with miniscope and Osc\n",
    "#######################################################################################\n",
    "                            # Define Experiment type #\n",
    "#######################################################################################\n",
    "\n",
    "DrugExperiment=0 # 1 if CGP Experiment, 0 if Baseline Experiment\n",
    "\n",
    "suffix='_fineDetectionAVG'\n",
    "\n",
    "Local=1\n",
    "\n",
    "choosed_folder1='Osc_2025-05-26_13_23_16_fineDetection_pynapple' # for Baseline Expe\n",
    "choosed_folder2='Osc_2025-05-26_13_23_16_fineDetection_pynapple' # for CGP Expe\n",
    "\n",
    "\n",
    "choosed_folder='Osc_2025-05-26_13_23_16_fineDetection_pynapple' if DrugExperiment else 'Osc_2025-05-26_13_23_16_fineDetection_pynapple'\n",
    "\n",
    "\n",
    "def column_with_max_single_per_row(row):\n",
    "    max_val = row.max()  # Find the max value in the row\n",
    "    max_columns = row == max_val  # Boolean Series of columns with max value\n",
    "    \n",
    "    if max_columns.sum() > 1:\n",
    "        return 'NoPref'  # More than one column has the max value\n",
    "    else:\n",
    "        return max_columns.idxmax()  # Return the name of the column with max value\n",
    "\n",
    "def divide_keys(data):\n",
    "    it=list(data.keys())[0]\n",
    "    d=data[it]\n",
    "    data[it]=d.replace(0, np.nan)\n",
    "    for sheet in list(data.keys())[1:]: \n",
    "        data[sheet].div(data[it][sheet], axis=0)\n",
    "    del data[it]\n",
    "    return data    \n",
    "\n",
    "########################################################################\n",
    "        # SCRIPT 27AB_GrandAverages&Stats_for_Osc\n",
    "########################################################################\n",
    "all_expe_types=['baseline', 'preCGP', 'postCGP'] if DrugExperiment else ['baseline', 'preCGP']\n",
    "\n",
    "# Get the current date and time\n",
    "FolderNameSave=str(datetime.now())[:19]\n",
    "FolderNameSave = FolderNameSave.replace(\" \", \"_\").replace(\".\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "destination_folder= f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_CGP_analysis/Osc_{FolderNameSave}{suffix}{AnalysisID}\" if DrugExperiment else f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_baseline_analysis/Osc_{FolderNameSave}{suffix}{AnalysisID}\"\n",
    "os.makedirs(destination_folder)\n",
    "folder_to_save=Path(destination_folder)\n",
    "\n",
    "# Copy the script file to the destination folder\n",
    "source_script = \"C:/Users/Manip2/SCRIPTS/CodePythonAudrey/CodePythonAurelie/HayLabAnalysis/python/_MINI&OE_9_osc_coupling_probability.ipynb\"\n",
    "destination_file_path = f\"{destination_folder}/_MINI&OE_9_osc_coupling_probability.txt\"\n",
    "shutil.copy(source_script, destination_file_path)\n",
    "     \n",
    "\n",
    "# Specify the directory containing the Excel files\n",
    "InitialDirectory1 =f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_baseline_analysis/\" \n",
    "directory1= f'{InitialDirectory1}/{choosed_folder1}'\n",
    "InitialDirectory2 = \"//10.69.168.1/crnldata/forgetting/Aurelie/GaelleData/CGP/AB_Analysis\" \n",
    "directory2= f'{InitialDirectory2}/{choosed_folder2}'\n",
    "\n",
    "Drugs= ['Baseline', 'CGP'] if DrugExperiment else ['Baseline']\n",
    "\n",
    "bins = int((5000 - -5000) / 100) \n",
    "bins = 50\n",
    "\n",
    "GrandPSTH_PFC_S1spdl=[]\n",
    "GrandPSTH_S1_PFCspdl=[]\n",
    "GrandPSTH_SWR_S1spdl=[]\n",
    "GrandPSTH_SWR_PFCspdl=[]\n",
    "\n",
    "###########################################################################\n",
    "                            ##### GLOBAL #####\n",
    "###########################################################################\n",
    "dfs = []\n",
    "\n",
    "nametofind=f'SpdlS1_'\n",
    "\n",
    "# Recursively traverse the directory structure\n",
    "#for directory in [directory1, directory2]: #both Baseline & CGP experiments \n",
    "for directory in [directory1]: #both Baseline & CGP experiments \n",
    "    for root, _, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            # Check if the file is an Excel file and contains the specified name\n",
    "            if filename.endswith('.pkl') and nametofind in filename:\n",
    "                # Construct the full path to the file\n",
    "                filepath = os.path.join(root, filename)\n",
    "                # Read the file and append it to the list\n",
    "                with open(filepath, 'rb') as pickle_file:\n",
    "                    df = pickle.load(pickle_file)\n",
    "                dfs+=df\n",
    "                PSTH,binedges=np.histogram(df, bins=bins)\n",
    "                #PSTH = (PSTH / len(df)) * 100\n",
    "                GrandPSTH_PFC_S1spdl.append(PSTH)\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "                            ##### GLOBAL #####\n",
    "###########################################################################\n",
    "dfs = []\n",
    "\n",
    "nametofind=f'SpdlPFC_'\n",
    "\n",
    "# Recursively traverse the directory structure\n",
    "#for directory in [directory1, directory2]: #both Baseline & CGP experiments \n",
    "for directory in [directory1]: #both Baseline & CGP experiments \n",
    "    for root, _, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            # Check if the file is an Excel file and contains the specified name\n",
    "            if filename.endswith('.pkl') and nametofind in filename:\n",
    "                # Construct the full path to the file\n",
    "                filepath = os.path.join(root, filename)\n",
    "                # Read the file and append it to the list\n",
    "                with open(filepath, 'rb') as pickle_file:\n",
    "                    df = pickle.load(pickle_file)\n",
    "                dfs+=df\n",
    "                PSTH,binedges=np.histogram(df, bins=bins)\n",
    "                #PSTH = (PSTH / len(df)) * 100\n",
    "                GrandPSTH_S1_PFCspdl.append(PSTH/sum(PSTH))\n",
    "\n",
    "###########################################################################\n",
    "                            ##### GLOBAL #####\n",
    "###########################################################################\n",
    "\n",
    "nametofind=f'SWR_S1'\n",
    "dfs = []\n",
    "\n",
    "# Recursively traverse the directory structure\n",
    "for directory in [directory1]: #both Baseline & CGP experiments \n",
    "    for root, _, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            # Check if the file is an Excel file and contains the specified name\n",
    "            if filename.endswith('.pkl') and nametofind in filename:\n",
    "                # Construct the full path to the file\n",
    "                filepath = os.path.join(root, filename)\n",
    "                # Read the file and append it to the list\n",
    "                with open(filepath, 'rb') as pickle_file:\n",
    "                    df = pickle.load(pickle_file)\n",
    "                dfs+=df\n",
    "                PSTH,binedges=np.histogram(df, bins=bins)\n",
    "                #PSTH = (PSTH / len(df)) * 100\n",
    "                GrandPSTH_SWR_S1spdl.append(PSTH/sum(PSTH))\n",
    "\n",
    "\n",
    "nametofind=f'SWR_PFC'\n",
    "dfs = []\n",
    "\n",
    "# Recursively traverse the directory structure\n",
    "for directory in [directory1]: #both Baseline & CGP experiments \n",
    "    for root, _, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            # Check if the file is an Excel file and contains the specified name\n",
    "            if filename.endswith('.pkl') and nametofind in filename:\n",
    "                # Construct the full path to the file\n",
    "                filepath = os.path.join(root, filename)\n",
    "                # Read the file and append it to the list\n",
    "                with open(filepath, 'rb') as pickle_file:\n",
    "                    df = pickle.load(pickle_file)\n",
    "                dfs+=df\n",
    "                PSTH,binedges=np.histogram(df, bins=bins)\n",
    "                #PSTH = (PSTH / len(df)) * 100\n",
    "                GrandPSTH_SWR_PFCspdl.append(PSTH/sum(PSTH))\n",
    "                print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb0686",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(GrandPSTH_SWR_PFCspdl[0], color='black') #BlackLines\n",
    "plt.plot(GrandPSTH_SWR_PFCspdl[1], color='blue') #BlueLines\n",
    "plt.plot(GrandPSTH_SWR_PFCspdl[2], color='Green') #GreenDots\n",
    "plt.plot(GrandPSTH_SWR_PFCspdl[3], color='Cyan') #GreenLines\n",
    "plt.plot(GrandPSTH_SWR_PFCspdl[4], color='Purple') #PurpleSquare\n",
    "plt.plot(GrandPSTH_SWR_PFCspdl[5], color='Red') #RedLines\n",
    "plt.plot(GrandPSTH_SWR_PFCspdl[6], color='Yellow') #ThreeBlueCrosses\n",
    "plt.plot(GrandPSTH_SWR_PFCspdl[7], color='Orange') #ThreeColDots\n",
    "plt.title('GrandPSTH_SWR_PFCspdl')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fb870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(GrandPSTH_S1_PFCspdl[0], color='black')\n",
    "plt.plot(GrandPSTH_S1_PFCspdl[1], color='blue')\n",
    "plt.plot(GrandPSTH_S1_PFCspdl[2], color='Green')\n",
    "plt.plot(GrandPSTH_S1_PFCspdl[3], color='Cyan')\n",
    "plt.plot(GrandPSTH_S1_PFCspdl[4], color='Purple')\n",
    "plt.plot(GrandPSTH_S1_PFCspdl[5], color='Red')\n",
    "plt.plot(GrandPSTH_S1_PFCspdl[6], color='Yellow')\n",
    "plt.plot(GrandPSTH_S1_PFCspdl[7], color='Orange')\n",
    "plt.title('GrandPSTH_S1_PFCspdl')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a0ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.close()\n",
    "plt.figure(figsize=(5, 3))\n",
    "\n",
    "# Simulate spike data\n",
    "n_bins = bins\n",
    "spike_counts=GrandPSTH_SWR_PFCspdl\n",
    "\n",
    "# Compute the observed PSTH\n",
    "observed_psth = np.mean(spike_counts, axis=0)\n",
    "\n",
    "# Monte Carlo parameters\n",
    "n_permutations = 5000\n",
    "shuffled_psths = []\n",
    "\n",
    "# Shuffle data and compute shuffled PSTHs\n",
    "for _ in range(n_permutations):\n",
    "    shuffled_counts = np.apply_along_axis(np.random.permutation, 1, spike_counts)\n",
    "    shuffled_psth = shuffled_counts.mean(axis=0)\n",
    "    shuffled_psths.append(shuffled_psth)\n",
    "\n",
    "shuffled_psths = np.array(shuffled_psths)\n",
    "\n",
    "# Compute significance (e.g., p < 0.05)\n",
    "alpha = 0.05\n",
    "lower_bound = np.percentile(shuffled_psths, alpha / 2 * 100, axis=0)\n",
    "upper_bound = np.percentile(shuffled_psths, (1 - alpha / 2) * 100, axis=0)\n",
    "significant_bins05 = (observed_psth < lower_bound) | (observed_psth > upper_bound)\n",
    "\n",
    "alpha = 0.01\n",
    "lower_bound = np.percentile(shuffled_psths, alpha / 2 * 100, axis=0)\n",
    "upper_bound = np.percentile(shuffled_psths, (1 - alpha / 2) * 100, axis=0)\n",
    "significant_bins01 = (observed_psth < lower_bound) | (observed_psth > upper_bound)\n",
    "\n",
    "alpha = 0.001\n",
    "lower_bound = np.percentile(shuffled_psths, alpha / 2 * 100, axis=0)\n",
    "upper_bound = np.percentile(shuffled_psths, (1 - alpha / 2) * 100, axis=0)\n",
    "significant_bins001 = (observed_psth < lower_bound) | (observed_psth > upper_bound)\n",
    "\n",
    "\n",
    "# Plot results\n",
    "time_bins = np.linspace(-10, 10, n_bins)\n",
    "plt.bar(time_bins, observed_psth, label='Observed PSTH', color='blue', width=0.4, alpha=0.5)\n",
    "plt.bar(time_bins, shuffled_psths[0], color='gray', label='Shuffle CI', width=0.4, alpha=0.5)\n",
    "\n",
    "plt.scatter(\n",
    "    time_bins[significant_bins05],\n",
    "    observed_psth[significant_bins05],\n",
    "    color='green',\n",
    "    label='p<0.05',\n",
    ")\n",
    "plt.scatter(\n",
    "    time_bins[significant_bins01],\n",
    "    observed_psth[significant_bins01],\n",
    "    color='blue',\n",
    "    label='p<0.01',\n",
    ")\n",
    "plt.scatter(\n",
    "    time_bins[significant_bins001],\n",
    "    observed_psth[significant_bins001],\n",
    "    color='red',\n",
    "    label='p<0.001',\n",
    ")\n",
    "\n",
    "plt.xlabel('Time from PFC spindles (s)')\n",
    "plt.ylabel('SWR probability')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'C:/Users/Manip2/Documents/Manuscripts/Figures_PNASreviews/Figure4_revised/ProbaSWRPFCSpdl.svg', format='svg', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09abe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.close()\n",
    "plt.figure(figsize=(5, 3))\n",
    "\n",
    "# Simulate spike data\n",
    "n_bins = bins\n",
    "spike_counts=GrandPSTH_SWR_S1spdl\n",
    "\n",
    "# Compute the observed PSTH\n",
    "observed_psth = np.mean(spike_counts, axis=0)\n",
    "\n",
    "# Monte Carlo parameters\n",
    "n_permutations = 5000\n",
    "shuffled_psths = []\n",
    "\n",
    "# Shuffle data and compute shuffled PSTHs\n",
    "for _ in range(n_permutations):\n",
    "    shuffled_counts = np.apply_along_axis(np.random.permutation, 1, spike_counts)\n",
    "    shuffled_psth = shuffled_counts.mean(axis=0)\n",
    "    shuffled_psths.append(shuffled_psth)\n",
    "\n",
    "shuffled_psths = np.array(shuffled_psths)\n",
    "\n",
    "# Compute significance (e.g., p < 0.05)\n",
    "alpha = 0.05\n",
    "lower_bound = np.percentile(shuffled_psths, alpha / 2 * 100, axis=0)\n",
    "upper_bound = np.percentile(shuffled_psths, (1 - alpha / 2) * 100, axis=0)\n",
    "significant_bins05 = (observed_psth < lower_bound) | (observed_psth > upper_bound)\n",
    "\n",
    "alpha = 0.01\n",
    "lower_bound = np.percentile(shuffled_psths, alpha / 2 * 100, axis=0)\n",
    "upper_bound = np.percentile(shuffled_psths, (1 - alpha / 2) * 100, axis=0)\n",
    "significant_bins01 = (observed_psth < lower_bound) | (observed_psth > upper_bound)\n",
    "\n",
    "alpha = 0.001\n",
    "lower_bound = np.percentile(shuffled_psths, alpha / 2 * 100, axis=0)\n",
    "upper_bound = np.percentile(shuffled_psths, (1 - alpha / 2) * 100, axis=0)\n",
    "significant_bins001 = (observed_psth < lower_bound) | (observed_psth > upper_bound)\n",
    "\n",
    "\n",
    "# Plot results\n",
    "time_bins = np.linspace(-10, 10, n_bins)\n",
    "plt.bar(time_bins, observed_psth, label='Observed PSTH', color='blue', width=0.4, alpha=0.5)\n",
    "plt.bar(time_bins, shuffled_psths[0], color='gray', label='Shuffle CI', width=0.4, alpha=0.5)\n",
    "\n",
    "plt.scatter(\n",
    "    time_bins[significant_bins05],\n",
    "    observed_psth[significant_bins05],\n",
    "    color='green',\n",
    "    label='p<0.05',\n",
    ")\n",
    "plt.scatter(\n",
    "    time_bins[significant_bins01],\n",
    "    observed_psth[significant_bins01],\n",
    "    color='blue',\n",
    "    label='p<0.01',\n",
    ")\n",
    "plt.scatter(\n",
    "    time_bins[significant_bins001],\n",
    "    observed_psth[significant_bins001],\n",
    "    color='red',\n",
    "    label='p<0.001',\n",
    ")\n",
    "\n",
    "plt.xlabel('Time from S1 spindles (s)')\n",
    "plt.ylabel('SWR probability')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'C:/Users/Manip2/Documents/Manuscripts/Figures_PNASreviews/Figure4_revised/ProbaSWRS1Spdl.svg', format='svg', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4dcd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "# Simulate spike data\n",
    "n_bins = bins\n",
    "spike_counts=GrandPSTH_S1_PFCspdl\n",
    "\n",
    "# Compute the observed PSTH\n",
    "observed_psth = np.mean(spike_counts, axis=0)\n",
    "\n",
    "# Monte Carlo parameters\n",
    "n_permutations = 5000\n",
    "shuffled_psths = []\n",
    "\n",
    "# Shuffle data and compute shuffled PSTHs\n",
    "for _ in range(n_permutations):\n",
    "    shuffled_counts = np.apply_along_axis(np.random.permutation, 1, spike_counts)\n",
    "    shuffled_psth = shuffled_counts.mean(axis=0)\n",
    "    shuffled_psths.append(shuffled_psth)\n",
    "\n",
    "shuffled_psths = np.array(shuffled_psths)\n",
    "\n",
    "# Compute significance (e.g., p < 0.05)\n",
    "alpha = 0.05\n",
    "lower_bound = np.percentile(shuffled_psths, alpha / 2 * 100, axis=0)\n",
    "upper_bound = np.percentile(shuffled_psths, (1 - alpha / 2) * 100, axis=0)\n",
    "significant_bins05 = (observed_psth < lower_bound) | (observed_psth > upper_bound)\n",
    "\n",
    "alpha = 0.01\n",
    "lower_bound = np.percentile(shuffled_psths, alpha / 2 * 100, axis=0)\n",
    "upper_bound = np.percentile(shuffled_psths, (1 - alpha / 2) * 100, axis=0)\n",
    "significant_bins01 = (observed_psth < lower_bound) | (observed_psth > upper_bound)\n",
    "\n",
    "alpha = 0.001\n",
    "lower_bound = np.percentile(shuffled_psths, alpha / 2 * 100, axis=0)\n",
    "upper_bound = np.percentile(shuffled_psths, (1 - alpha / 2) * 100, axis=0)\n",
    "significant_bins001 = (observed_psth < lower_bound) | (observed_psth > upper_bound)\n",
    "\n",
    "\n",
    "# Plot results\n",
    "time_bins = np.linspace(-10, 10, n_bins)\n",
    "plt.bar(time_bins, observed_psth, label='Observed PSTH', color='blue', width=0.4, alpha=0.5)\n",
    "plt.bar(time_bins, shuffled_psths[0], color='gray', label='Shuffle CI', width=0.4, alpha=0.5)\n",
    "\n",
    "plt.scatter(\n",
    "    time_bins[significant_bins05],\n",
    "    observed_psth[significant_bins05],\n",
    "    color='green',\n",
    "    label='p<0.05',\n",
    ")\n",
    "plt.scatter(\n",
    "    time_bins[significant_bins01],\n",
    "    observed_psth[significant_bins01],\n",
    "    color='blue',\n",
    "    label='p<0.01',\n",
    ")\n",
    "plt.scatter(\n",
    "    time_bins[significant_bins001],\n",
    "    observed_psth[significant_bins001],\n",
    "    color='red',\n",
    "    label='p<0.001',\n",
    ")\n",
    "plt.xlabel('Time from PFC spindles (s)')\n",
    "plt.ylabel('S1 spindles probability')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'C:/Users/Manip2/Documents/Manuscripts/Figures_PNASreviews/Figure4_revised/ProbaS1SpdlPFCSpdl.svg', format='svg', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e339851",
   "metadata": {},
   "source": [
    "### Compare vigilance states with and without miniscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51f1386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ListSleepScor_noMini= {\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_baseline_analysis/Sleep_Scoring_6Stages_5sEpoch_GreenLines.csv\",\n",
    "\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_baseline_analysis/Sleep_Scoring_6Stages_5sEpoch_BlueLines1.csv\",\n",
    "\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_baseline_analysis/Sleep_Scoring_6Stages_5sEpoch_BlackLines.csv\",\n",
    "\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_baseline_analysis/Sleep_Scoring_6Stages_5sEpoch_BlueLines.csv\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9ada7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "mapp = {1: 'AW',  2: 'QW', 3: 'NREM',  4: 'IS', 5: 'REM',  6: 'undefined'}\n",
    "\n",
    "SUBSTATES=pd.DataFrame()\n",
    "\n",
    "# Determine each substate identity and duration\n",
    "for SleepScoring_filename in ListSleepScor_noMini:\n",
    "\n",
    "    last_underscore = SleepScoring_filename.rfind('_')\n",
    "    last_dot = SleepScoring_filename.rfind('.')\n",
    "    mouse = SleepScoring_filename[last_underscore + 1:last_dot]\n",
    "\n",
    "    SleepScored  = pd.read_csv(SleepScoring_filename)\n",
    "    SleepScored['label']= SleepScored['label'].str.extract(r'(\\d+)', expand=False)    \n",
    "    SleepScoredTS=np.array(SleepScored['label'])\n",
    "    SleepScoredTS=SleepScoredTS.astype(int)\n",
    "    substates_duration = [len(list(group)) for key, group in groupby(SleepScoredTS)]\n",
    "    substates_identity = [key for key, _ in groupby(SleepScoredTS)]\n",
    "    substates_end = np.array(substates_duration).cumsum()        \n",
    "    substates_start =np.append([0],substates_end[:-1]) #substates_start =np.append([1],substates_end+1) create 1 second gap\n",
    "    substates_identity = [mapp[num] for num in substates_identity]\n",
    "    substates = pd.DataFrame(list(zip(substates_identity, substates_duration, substates_start, substates_end)), columns=['Substate', 'Duration', 'Start','End'])\n",
    "    substates['Mice']=mouse\n",
    "    SUBSTATES = pd.concat([SUBSTATES, substates], ignore_index=True)\n",
    "    \n",
    "DurationVigStates = SUBSTATES.pivot_table(index='Mice', columns=[SUBSTATES['Substate']], values='Duration', aggfunc='mean', fill_value=None)\n",
    "TotDurationVigStates = SUBSTATES.pivot_table(index='Mice', columns=[SUBSTATES['Substate']], values='Duration', aggfunc='sum', fill_value=None)\n",
    "TotDurationVigStates['Tot']=TotDurationVigStates.sum(axis=1)\n",
    "ProportionVigStates= TotDurationVigStates[['AW', 'QW', 'NREM', 'IS', 'REM']].div(TotDurationVigStates['Tot'], axis=0)*100\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
