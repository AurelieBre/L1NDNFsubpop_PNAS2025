{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats on Ca2+ imaging with miniscope and Vigilance States\n",
    "\n",
    "#######################################################################################\n",
    "                            # Define Experiment type #\n",
    "#######################################################################################\n",
    "\n",
    "AnalysisID='_CGP' #to identify this analysis from another\n",
    "DrugExperiment=1 # 0 if Baseline, 1 if CGP, 2 if Baseline & CGP\n",
    "\n",
    "saveexcel=0\n",
    "Local=1\n",
    "\n",
    "desired_order = ['AW','QW', 'NREM', 'IS', 'REM', 'undefined']   \n",
    "\n",
    "#choosed_folder='VigSt_2024-07-22_18_21_32_AB_FINAL' if DrugExperiment else 'VigSt_2024-07-22_17_16_28_AB_FINAL'\n",
    "choosed_folder1='VigSt_2025-05-03_10_01_32' # for Baseline Expe\n",
    "choosed_folder2='VigSt_2025-05-03_12_01_21' # for CGP Expe\n",
    "choosed_folder3='Corr_VigSt_2025-05-03_14_47_15' # for Correlations\n",
    "\n",
    "#######################################################################################\n",
    "                                # Load packages #\n",
    "#######################################################################################\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import quantities as pq\n",
    "import numpy as np\n",
    "import math \n",
    "import neo\n",
    "import json\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "import pickle\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from scipy.stats import ttest_ind\n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def extract_micename(index_value):\n",
    "    match = re.match(r\"([a-zA-Z]+)\", index_value)\n",
    "    return match.group(1) if match else index_value\n",
    "\n",
    "def max_column_name(row):\n",
    "    return row.idxmax()\n",
    "    \n",
    "\n",
    "#######################################################################################\n",
    "                            # Define Directories #\n",
    "#######################################################################################\n",
    "\n",
    "# Specify the directory containing the Excel files\n",
    "InitialDirectory1 = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_baseline_analysis\" if Local else \"/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_baseline_analysis\" \n",
    "directory1= f'{InitialDirectory1}/{choosed_folder1}'\n",
    "InitialDirectory2 =\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_CGP_analysis\" if Local else \"/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_CGP_analysis\"\n",
    "directory2= f'{InitialDirectory2}/{choosed_folder2}'\n",
    "\n",
    "InitialDirectory3 =\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_global_analysis\" if Local else \"/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_global_analysis\"\n",
    "directory3= f'{InitialDirectory3}/{choosed_folder3}'\n",
    "\n",
    "# Get the current date and time\n",
    "FolderNameSave=str(datetime.now())[:19]\n",
    "FolderNameSave = FolderNameSave.replace(\" \", \"_\").replace(\".\", \"_\").replace(\":\", \"_\")\n",
    "destination_folder= f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_global_analysis/AVG_VigSt_{FolderNameSave}{AnalysisID}\" if Local else f\"/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_global_analysis/AVG_VigSt_{FolderNameSave}{AnalysisID}\"\n",
    "os.makedirs(destination_folder)\n",
    "folder_to_save=Path(destination_folder)\n",
    "\n",
    "# Copy the script file to the destination folder\n",
    "source_script = \"C:/Users/Manip2/SCRIPTS/CodePythonAudrey/CodePythonAurelie/HayLabAnalysis/python/_MINI&OE_4_average_per_cluster.py\" if Local else \"/python/_MINI&OE_4_average_per_cluster.py\" \n",
    "destination_file_path = f\"{destination_folder}/_MINI&OE_4_average_per_cluster.txt\"\n",
    "shutil.copy(source_script, destination_file_path)\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "                            # Do the average per cluster #\n",
    "#######################################################################################\n",
    "\n",
    "# Load Global Table \n",
    "directorY=directory2 if DrugExperiment else directory1\n",
    "with open(f'{directorY}/VigStates_Global_cluster.pkl', 'rb') as pickle_file:\n",
    "    combined_dfO = pickle.load(pickle_file)\n",
    "\n",
    "AllProportionVigStates=pd.DataFrame()\n",
    "AllDurationVigStates=pd.DataFrame()\n",
    "AllTotDurationVigStates=pd.DataFrame()\n",
    "\n",
    "NrSubtypeList=['L1NDNF_mice','L2_3_mice']\n",
    "\n",
    "for NrSubtype in NrSubtypeList:\n",
    "\n",
    "    analysisfileCa='VigSt_CaCorr'\n",
    "    with open(f'{directory3}/{NrSubtype}_{analysisfileCa}.pkl', 'rb') as pickle_file:\n",
    "        combined_dfCa = pickle.load(pickle_file)\n",
    "        del combined_dfCa['baseline_IS']\n",
    "        del combined_dfCa['baseline_undefined']        \n",
    "        del combined_dfCa['Z_baseline_IS']\n",
    "        del combined_dfCa['Z_baseline_undefined']\n",
    "\n",
    "    analysisfileSp='VigSt_SpCorr'\n",
    "    with open(f'{directory3}/{NrSubtype}_{analysisfileSp}.pkl', 'rb') as pickle_file:\n",
    "        combined_dfSp = pickle.load(pickle_file)   \n",
    "        del combined_dfSp['baseline_IS']\n",
    "        del combined_dfSp['baseline_undefined']        \n",
    "        del combined_dfSp['Z_baseline_IS']\n",
    "        del combined_dfSp['Z_baseline_undefined']\n",
    "\n",
    "    analysisfileCa='Tot_CaCorr'\n",
    "    with open(f'{directory3}/{NrSubtype}_{analysisfileCa}.pkl', 'rb') as pickle_file:\n",
    "        combined_dfCaTot = pickle.load(pickle_file)\n",
    "\n",
    "    analysisfileSp='Tot_SpCorr'\n",
    "    with open(f'{directory3}/{NrSubtype}_{analysisfileSp}.pkl', 'rb') as pickle_file:\n",
    "        combined_dfSpTot = pickle.load(pickle_file)\n",
    "    \n",
    "    analysisfileCa='SubSt_CaCorr'\n",
    "    with open(f'{directory3}/{NrSubtype}_{analysisfileCa}.pkl', 'rb') as pickle_file:\n",
    "        combined_dfCaSub = pickle.load(pickle_file)\n",
    "        del combined_dfCaSub['baseline_IS']\n",
    "        del combined_dfCaSub['baseline_undefined']\n",
    "        del combined_dfCaSub['CGP_IS']\n",
    "        del combined_dfCaSub['CGP_undefined']\n",
    "\n",
    "    ######################\n",
    "    # CHOOSE OPTIONS\n",
    "    ######################\n",
    "\n",
    "    # MINIMUM VIG STATES DURATION #\n",
    "    #combined_df = combined_dfO[combined_dfO['DurationSubstate'] >= 0] #10\n",
    "    \n",
    "    Drugs= ['baseline', 'CGP'] if DrugExperiment else ['baseline']\n",
    "\n",
    "    # NO LOW FIRING RATE #\n",
    "    #combined_df = combined_df[combined_df['Avg_SpikeActivityHz'] >= 0.05] \n",
    "    \n",
    "    #####################\n",
    "    # LOAD CLUSTERS #\n",
    "    #####################\n",
    "\n",
    "    # /!/ The ones from Baseline (not CGP)\n",
    "\n",
    "    combined_df = combined_dfO.copy()\n",
    "    combined_df = combined_df[combined_df['NeuronType'] == NrSubtype]\n",
    "    combined_df_Drug = combined_df.copy()\n",
    "    combined_df_Drug = combined_df[combined_df['Drug'] == 'baseline']\n",
    "\n",
    "    AllBaselineUnits = combined_df_Drug['Unit_ID'].unique()\n",
    "    Cluster0units = combined_df_Drug[combined_df_Drug['ClusterHDBSCAN'] == 0]['Unit_ID'].unique()\n",
    "    Cluster1units = combined_df_Drug[combined_df_Drug['ClusterHDBSCAN'] == 1]['Unit_ID'].unique()\n",
    "    Cluster2units = combined_df_Drug[combined_df_Drug['ClusterHDBSCAN'] == 2]['Unit_ID'].unique()\n",
    "    \n",
    "    # Only keep units that appears in CGP & Baseline    \n",
    "    if DrugExperiment>=1 :\n",
    "        combined_df_CGP=combined_df.copy()\n",
    "        combined_df_CGP = combined_df_CGP[combined_df_CGP['Drug'] == 'CGP'] \n",
    "        AllCGPUnits = combined_df_CGP['Unit_ID'].unique()\n",
    "\n",
    "        AllBaselineUnits= np.intersect1d(AllBaselineUnits,AllCGPUnits)\n",
    "        Cluster0units= np.intersect1d(Cluster0units,AllBaselineUnits)\n",
    "        Cluster1units= np.intersect1d(Cluster1units,AllBaselineUnits)\n",
    "        Cluster2units= np.intersect1d(Cluster2units,AllBaselineUnits)\n",
    "        \n",
    "    # Save the List of significant Unit more active in one vigilance state\n",
    "    if NrSubtype=='L1NDNF_mice':\n",
    "        os.makedirs(f'{folder_to_save}/baseline/')\n",
    "\n",
    "    for Drug in Drugs:\n",
    "\n",
    "        combined_df_DrugO=combined_df.copy() # no min vig states durations == for vig states stats\n",
    "        combined_df_DrugO = combined_df_DrugO[combined_df_DrugO['Drug'] == Drug] \n",
    "\n",
    "        combined_df_Drug=combined_df.copy()\n",
    "        combined_df_Drug = combined_df_Drug[combined_df_Drug['Drug'] == Drug] \n",
    "        AllUnits= combined_df_Drug['Unit_ID'].unique()\n",
    "\n",
    "        folder_to_save2= f'{folder_to_save}/{Drug}/'\n",
    "        if NrSubtype=='L1NDNF_mice' and Drug=='CGP':\n",
    "            os.makedirs(folder_to_save2)\n",
    "\n",
    "        List_SignFiringPreference=[Cluster0units, Cluster1units, Cluster2units, AllBaselineUnits, AllUnits] if DrugExperiment else [Cluster0units, Cluster1units, Cluster2units, AllUnits]\n",
    "        SecondaryList=[Cluster1units, Cluster2units, Cluster0units, AllBaselineUnits, AllUnits] if DrugExperiment else [Cluster1units, Cluster2units, Cluster0units, AllUnits]\n",
    "        List_Names=['Cluster0units', 'Cluster1units', 'Cluster2units', 'AllBaselineUnits', 'All']if DrugExperiment else ['Cluster0units', 'Cluster1units','Cluster2units', 'All']\n",
    "        SecondaryList_Names=['Cluster1units', 'Cluster2units', 'Cluster0units', 'AllBaselineUnits', 'All' ] if DrugExperiment else ['Cluster1units', 'Cluster2units', 'Cluster0units', 'All']\n",
    "        \n",
    "        for listnb, listI  in enumerate(List_SignFiringPreference):\n",
    "\n",
    "            if len(listI)>0:\n",
    "            \n",
    "                filtered_df = combined_df_Drug[combined_df_Drug['Unit_ID'].isin(listI)]\n",
    "                List_name=List_Names[listnb]\n",
    "                SecondaryList_name=SecondaryList_Names[listnb]\n",
    "                listII=SecondaryList[listnb]\n",
    "\n",
    "                filtered_df_AllDrug = combined_df[combined_df['Unit_ID'].isin(listI)]\n",
    "                filenameOut = f'{folder_to_save}/GLM_{NrSubtype}_{List_name}_VigSt_Global.xlsx'\n",
    "                writer = pd.ExcelWriter(filenameOut)\n",
    "                filtered_df_AllDrug.to_excel(writer)\n",
    "                writer.close()\n",
    "\n",
    "                if NrSubtype=='L1NDNF_mice':\n",
    "                    new_folder= f\"{folder_to_save2}/{List_name}/\"\n",
    "                    os.makedirs(new_folder)\n",
    "\n",
    "                if Drug==Drug: #'baseline':\n",
    "                    \n",
    "                    #####################################################\n",
    "                    ## TOTAL Ca correlation with neuron from same population ##\n",
    "                    #####################################################\n",
    "\n",
    "                    # Keep only neurons from the list \n",
    "                    dfCaTot_filtered={}\n",
    "                    for sheet_name, dfCa in combined_dfCaTot.items():\n",
    "                        dfCa=pd.DataFrame(dfCa)\n",
    "                        indices_to_keep_existing = [idx for idx in listI if idx in dfCa.index] #from first list\n",
    "                        columns_to_keep_existing = [col for col in listI if col in dfCa.columns] #from second list\n",
    "                        dfCaTot_filtered[sheet_name] = dfCa.loc[indices_to_keep_existing, columns_to_keep_existing]\n",
    "                    \n",
    "                    if DrugExperiment>=1:\n",
    "                        # Keep only correlation pairs that occurs for each Drug condition\n",
    "                        for sheet_name, df in dfCaTot_filtered.items(): #remove inactive/non recorded neurons\n",
    "                            df = df[~(df.fillna(0) == 0).all(axis=1)]\n",
    "                            df = df.loc[:, ~(df.fillna(0) == 0).all(axis=0)]\n",
    "                            dfCaTot_filtered[sheet_name] = df    \n",
    "                        first_key = list(dfCaTot_filtered.keys())[0]\n",
    "                        common_columns = dfCaTot_filtered[first_key].columns\n",
    "                        common_indices = dfCaTot_filtered[first_key].index\n",
    "                        for df in dfCaTot_filtered.values():\n",
    "                            common_columns = common_columns.intersection(df.columns)\n",
    "                            common_indices = common_indices.intersection(df.index)\n",
    "                        dfCaTot_Doublefiltered = {name: df.loc[common_indices, common_columns] for name, df in dfCaTot_filtered.items()}\n",
    "                    else:\n",
    "                        dfCaTot_Doublefiltered=dfCaTot_filtered\n",
    "\n",
    "                    # Save Corr Pairs\n",
    "                    file_path = f'{folder_to_save2}/{List_name}/{NrSubtype}_Tot_PairCorrCa_{List_name}.xlsx'\n",
    "                    with pd.ExcelWriter(file_path) as writer:\n",
    "                        for sheet_name, dfCa in dfCaTot_Doublefiltered.items():\n",
    "                            if 'Z_' not in sheet_name:                            \n",
    "                                dfCa = dfCa.sort_index(axis=1)\n",
    "                                dfCa = dfCa.sort_index(axis=0)\n",
    "                                dfCa.to_excel(writer, sheet_name=sheet_name, index=True, header=True)\n",
    "\n",
    "                    # Flat correlations\n",
    "                    SummaryMatrixCa= pd.DataFrame()\n",
    "                    for sheet_name, df in dfCaTot_Doublefiltered.items():    \n",
    "                        series_flattened = df.stack().reset_index()\n",
    "                        series_flattened['index'] = series_flattened['level_0'] + '_' + series_flattened['level_1']\n",
    "                        series_flattened = series_flattened.set_index('index')[0]\n",
    "                        series_flattened_cleaned = series_flattened[series_flattened.index.str.split('_').str[0] != series_flattened.index.str.split('_').str[1]] #remove Neuron1 vs Neuron1\n",
    "                        series_flattened_cleaned.name = sheet_name\n",
    "                        SummaryMatrixCa = pd.concat([SummaryMatrixCa,series_flattened_cleaned], axis=1)\n",
    "                    \n",
    "                    SummaryMatrixCa_cleaned = SummaryMatrixCa.round(5) # to better detect duplicate                   \n",
    "                    SummaryMatrixCa_cleaned = SummaryMatrixCa.drop_duplicates(subset=SummaryMatrixCa.columns[1:]) \n",
    "                    #SummaryMatrixCa_cleaned = SummaryMatrixCa_cleaned.drop(columns=[SummaryMatrixCa_cleaned.columns[0], SummaryMatrixCa_cleaned.columns[2], SummaryMatrixCa_cleaned.columns[4], SummaryMatrixCa_cleaned.columns[6], SummaryMatrixCa_cleaned.columns[8], SummaryMatrixCa_cleaned.columns[10]]) if DrugExperiment else SummaryMatrixCa_cleaned.drop(columns=[SummaryMatrixCa_cleaned.columns[0], SummaryMatrixCa_cleaned.columns[2], SummaryMatrixCa_cleaned.columns[4]])\n",
    "\n",
    "                    filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_Tot_FlatPairCaCorr_{List_name}.xlsx'\n",
    "                    SummaryMatrixCa_cleaned.to_excel(filenameOut, index=True, header=True)  \n",
    "                \n",
    "                    #####################################################\n",
    "                    ## TOTAL Ca correlation with neuron from different population ##\n",
    "                    #####################################################\n",
    "\n",
    "                    # Keep only neurons from the list \n",
    "                    dfCaTot_filtered={}\n",
    "                    for sheet_name, dfCa in combined_dfCaTot.items():\n",
    "                        dfCa=pd.DataFrame(dfCa)\n",
    "                        indices_to_keep_existing = [idx for idx in listI if idx in dfCa.index] #from first list\n",
    "                        columns_to_keep_existing = [col for col in listII if col in dfCa.columns] #from second list\n",
    "                        dfCaTot_filtered[sheet_name] = dfCa.loc[indices_to_keep_existing, columns_to_keep_existing]\n",
    "                    \n",
    "                    if DrugExperiment>=1:\n",
    "                        # Keep only correlation pairs that occurs for each Drug condition\n",
    "                        for sheet_name, df in dfCaTot_filtered.items(): #remove inactive/non recorded neurons\n",
    "                            df = df[~(df.fillna(0) == 0).all(axis=1)]\n",
    "                            df = df.loc[:, ~(df.fillna(0) == 0).all(axis=0)]\n",
    "                            dfCaTot_filtered[sheet_name] = df    \n",
    "                        first_key = list(dfCaTot_filtered.keys())[0]\n",
    "                        common_columns = dfCaTot_filtered[first_key].columns\n",
    "                        common_indices = dfCaTot_filtered[first_key].index\n",
    "                        for df in dfCaTot_filtered.values():\n",
    "                            common_columns = common_columns.intersection(df.columns)\n",
    "                            common_indices = common_indices.intersection(df.index)\n",
    "                        dfCaTot_Doublefiltered = {name: df.loc[common_indices, common_columns] for name, df in dfCaTot_filtered.items()}\n",
    "                    else:\n",
    "                        dfCaTot_Doublefiltered=dfCaTot_filtered\n",
    "\n",
    "                    # Save Corr Pairs\n",
    "                    file_path = f'{folder_to_save2}/{List_name}/{NrSubtype}_Tot_PairCorrCa_{SecondaryList_name}.xlsx'\n",
    "                    with pd.ExcelWriter(file_path) as writer:\n",
    "                        for sheet_name, dfCa in dfCaTot_Doublefiltered.items():\n",
    "                            if 'Z_' not in sheet_name:\n",
    "                                dfCa = dfCa.sort_index(axis=1)\n",
    "                                dfCa = dfCa.sort_index(axis=0)\n",
    "                                dfCa.to_excel(writer, sheet_name=sheet_name, index=True, header=True)\n",
    "\n",
    "                    # Flat correlations\n",
    "                    SummaryMatrixCa= pd.DataFrame()\n",
    "                    for sheet_name, df in dfCaTot_Doublefiltered.items():    \n",
    "                        series_flattened = df.stack().reset_index()\n",
    "                        series_flattened['index'] = series_flattened['level_0'] + '_' + series_flattened['level_1']\n",
    "                        series_flattened = series_flattened.set_index('index')[0]\n",
    "                        series_flattened_cleaned = series_flattened[series_flattened.index.str.split('_').str[0] != series_flattened.index.str.split('_').str[1]] #remove Neuron1 vs Neuron1\n",
    "                        series_flattened_cleaned.name = sheet_name\n",
    "                        SummaryMatrixCa = pd.concat([SummaryMatrixCa,series_flattened_cleaned], axis=1)\n",
    "                    \n",
    "                    SummaryMatrixCa_cleaned = SummaryMatrixCa.round(5) # to better detect duplicate                   \n",
    "                    SummaryMatrixCa_cleaned = SummaryMatrixCa.drop_duplicates(subset=SummaryMatrixCa.columns[1:]) \n",
    "                    #SummaryMatrixCa_cleaned = SummaryMatrixCa_cleaned.drop(columns=[SummaryMatrixCa_cleaned.columns[0], SummaryMatrixCa_cleaned.columns[2], SummaryMatrixCa_cleaned.columns[4], SummaryMatrixCa_cleaned.columns[6], SummaryMatrixCa_cleaned.columns[8], SummaryMatrixCa_cleaned.columns[10]]) if DrugExperiment else SummaryMatrixCa_cleaned.drop(columns=[SummaryMatrixCa_cleaned.columns[0], SummaryMatrixCa_cleaned.columns[2], SummaryMatrixCa_cleaned.columns[4]])\n",
    "\n",
    "                    filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_Tot_FlatPairCaCorr_{SecondaryList_name}.xlsx'\n",
    "                    SummaryMatrixCa_cleaned.to_excel(filenameOut, index=True, header=True)  \n",
    "                \n",
    "\n",
    "                    #####################################################\n",
    "                    ## Vig St Ca correlation with neuron from same population ##\n",
    "                    #####################################################\n",
    "\n",
    "                    # Keep only neurons from the list \n",
    "                    dfCa_filtered={}\n",
    "                    for sheet_name, dfCa in combined_dfCa.items():\n",
    "                        dfCa=pd.DataFrame(dfCa)\n",
    "                        indices_to_keep_existing = [idx for idx in listI if idx in dfCa.index] #from first list\n",
    "                        columns_to_keep_existing = [col for col in listI if col in dfCa.columns] #from second list\n",
    "                        dfCa_filtered[sheet_name] = dfCa.loc[indices_to_keep_existing, columns_to_keep_existing]\n",
    "\n",
    "                    if DrugExperiment==1: \n",
    "                        # Keep only correlation pairs that occurs for each Drug condition                \n",
    "                        dfCa_filtered2 = copy.deepcopy(dfCa_filtered)\n",
    "                        keys_to_keep =['baseline_AW', 'Z_baseline_AW', 'CGP_AW', 'Z_CGP_AW']\n",
    "                        dfCa_filtered2 = {k: dfCa_filtered2[k] for k in keys_to_keep if k in dfCa_filtered2}\n",
    "                        for sheet_name, df in dfCa_filtered2.items(): #remove inactive/non recorded neurons\n",
    "                            df = df[~(df.fillna(0) == 0).all(axis=1)]\n",
    "                            df = df.loc[:, ~(df.fillna(0) == 0).all(axis=0)]\n",
    "                            dfCa_filtered2[sheet_name] = df    \n",
    "                        first_key = list(dfCa_filtered2.keys())[0]\n",
    "                        common_columns = dfCa_filtered2[first_key].columns\n",
    "                        common_indices = dfCa_filtered2[first_key].index\n",
    "                        for df in dfCa_filtered2.values():\n",
    "                            common_columns = common_columns.intersection(df.columns)\n",
    "                            common_indices = common_indices.intersection(df.index)\n",
    "                        dfCa_DoubleFiltered = {name: df.loc[common_indices, common_columns] for name, df in dfCa_filtered2.items()}\n",
    "\n",
    "                        dfCa_filtered2 = copy.deepcopy(dfCa_filtered)\n",
    "                        keys_to_keep =['baseline_QW', 'Z_baseline_QW', 'CGP_QW', 'Z_CGP_QW']\n",
    "                        dfCa_filtered2 = {k: dfCa_filtered2[k] for k in keys_to_keep if k in dfCa_filtered2}\n",
    "                        for sheet_name, df in dfCa_filtered2.items(): #remove inactive/non recorded neurons\n",
    "                            df = df[~(df.fillna(0) == 0).all(axis=1)]\n",
    "                            df = df.loc[:, ~(df.fillna(0) == 0).all(axis=0)]\n",
    "                            dfCa_filtered2[sheet_name] = df    \n",
    "                        first_key = list(dfCa_filtered2.keys())[0]\n",
    "                        common_columns = dfCa_filtered2[first_key].columns\n",
    "                        common_indices = dfCa_filtered2[first_key].index\n",
    "                        for df in dfCa_filtered2.values():\n",
    "                            common_columns = common_columns.intersection(df.columns)\n",
    "                            common_indices = common_indices.intersection(df.index)\n",
    "                        dfCa_DoubleFiltered2 = {name: df.loc[common_indices, common_columns] for name, df in dfCa_filtered2.items()}\n",
    "                        \n",
    "                        dfCa_filtered2 = copy.deepcopy(dfCa_filtered)\n",
    "                        keys_to_keep =['baseline_NREM', 'Z_baseline_NREM', 'CGP_NREM', 'Z_CGP_NREM']\n",
    "                        dfCa_filtered2 = {k: dfCa_filtered2[k] for k in keys_to_keep if k in dfCa_filtered2}\n",
    "                        for sheet_name, df in dfCa_filtered2.items(): #remove inactive/non recorded neurons\n",
    "                            df = df[~(df.fillna(0) == 0).all(axis=1)]\n",
    "                            df = df.loc[:, ~(df.fillna(0) == 0).all(axis=0)]\n",
    "                            dfCa_filtered2[sheet_name] = df    \n",
    "                        first_key = list(dfCa_filtered2.keys())[0]\n",
    "                        common_columns = dfCa_filtered2[first_key].columns\n",
    "                        common_indices = dfCa_filtered2[first_key].index\n",
    "                        for df in dfCa_filtered2.values():\n",
    "                            common_columns = common_columns.intersection(df.columns)\n",
    "                            common_indices = common_indices.intersection(df.index)\n",
    "                        dfCa_DoubleFiltered2 = {name: df.loc[common_indices, common_columns] for name, df in dfCa_filtered2.items()}\n",
    "\n",
    "                        dfCa_filtered2 = copy.deepcopy(dfCa_filtered)\n",
    "                        keys_to_keep =['baseline_REM', 'Z_baseline_REM', 'CGP_REM', 'Z_CGP_REM']\n",
    "                        dfCa_filtered2 = {k: dfCa_filtered2[k] for k in keys_to_keep if k in dfCa_filtered2}\n",
    "                        for sheet_name, df in dfCa_filtered2.items(): #remove inactive/non recorded neurons\n",
    "                            df = df[~(df.fillna(0) == 0).all(axis=1)]\n",
    "                            df = df.loc[:, ~(df.fillna(0) == 0).all(axis=0)]\n",
    "                            dfCa_filtered2[sheet_name] = df    \n",
    "                        first_key = list(dfCa_filtered2.keys())[0]\n",
    "                        common_columns = dfCa_filtered2[first_key].columns\n",
    "                        common_indices = dfCa_filtered2[first_key].index\n",
    "                        for df in dfCa_filtered2.values():\n",
    "                            common_columns = common_columns.intersection(df.columns)\n",
    "                            common_indices = common_indices.intersection(df.index)\n",
    "                        dfCa_DoubleFiltered3 = {name: df.loc[common_indices, common_columns] for name, df in dfCa_filtered2.items()}\n",
    "            \n",
    "                        dfCa_DoubleFiltered.update(dfCa_DoubleFiltered2)    # modifies z with keys and values of y\n",
    "                        dfCa_DoubleFiltered.update(dfCa_DoubleFiltered3)    # modifies z with keys and values of y\n",
    "\n",
    "                    elif DrugExperiment==0:\n",
    "                        # Keep only correlation pairs that occurs for each Vig States  \n",
    "                        dfCa_filtered2 = copy.deepcopy(dfCa_filtered)\n",
    "                        keys_to_keep =['baseline_AW', 'Z_baseline_AW','baseline_QW', 'Z_baseline_QW', 'baseline_NREM', 'Z_baseline_NREM', 'baseline_REM', 'Z_baseline_REM']\n",
    "                        dfCa_filtered2 = {k: dfCa_filtered2[k] for k in keys_to_keep if k in dfCa_filtered2}\n",
    "                        for sheet_name, df in dfCa_filtered2.items(): #remove inactive/non recorded neurons\n",
    "                            df = df[~(df.fillna(0) == 0).all(axis=1)]\n",
    "                            df = df.loc[:, ~(df.fillna(0) == 0).all(axis=0)]\n",
    "                            dfCa_filtered2[sheet_name] = df    \n",
    "                        first_key = list(dfCa_filtered2.keys())[0]\n",
    "                        common_columns = dfCa_filtered2[first_key].columns\n",
    "                        common_indices = dfCa_filtered2[first_key].index\n",
    "                        for df in dfCa_filtered2.values():\n",
    "                            common_columns = common_columns.intersection(df.columns)\n",
    "                            common_indices = common_indices.intersection(df.index)\n",
    "                        dfCa_DoubleFiltered = {name: df.loc[common_indices, common_columns] for name, df in dfCa_filtered2.items()}\n",
    "                                            \n",
    "                    elif DrugExperiment ==2: \n",
    "                        # Keep only correlation pairs that occurs for each Vig States  \n",
    "                        dfCa_filtered2 = copy.deepcopy(dfCa_filtered)\n",
    "                        keys_to_keep =['CGP_AW', 'Z_CGP_AW','CGP_QW', 'Z_CGP_QW', 'CGP_NREM', 'Z_CGP_NREM', 'CGP_REM', 'Z_CGP_REM']\n",
    "                        dfCa_filtered2 = {k: dfCa_filtered2[k] for k in keys_to_keep if k in dfCa_filtered2}\n",
    "                        for sheet_name, df in dfCa_filtered2.items(): #remove inactive/non recorded neurons\n",
    "                            df = df[~(df.fillna(0) == 0).all(axis=1)]\n",
    "                            df = df.loc[:, ~(df.fillna(0) == 0).all(axis=0)]\n",
    "                            dfCa_filtered2[sheet_name] = df    \n",
    "                        first_key = list(dfCa_filtered2.keys())[0]\n",
    "                        common_columns = dfCa_filtered2[first_key].columns\n",
    "                        common_indices = dfCa_filtered2[first_key].index\n",
    "                        for df in dfCa_filtered2.values():\n",
    "                            common_columns = common_columns.intersection(df.columns)\n",
    "                            common_indices = common_indices.intersection(df.index)\n",
    "                        dfCa_DoubleFiltered = {name: df.loc[common_indices, common_columns] for name, df in dfCa_filtered2.items()}\n",
    "                        \n",
    "                        dfCa_filtered2 = copy.deepcopy(dfCa_filtered)\n",
    "                        keys_to_keep =['baseline_AW', 'Z_baseline_AW','baseline_QW', 'Z_baseline_QW', 'baseline_NREM', 'Z_baseline_NREM', 'baseline_REM', 'Z_baseline_REM']\n",
    "                        dfCa_filtered2 = {k: dfCa_filtered2[k] for k in keys_to_keep if k in dfCa_filtered2}       \n",
    "                        for sheet_name, df in dfCa_filtered2.items(): #remove inactive/non recorded neurons\n",
    "                            df = df[~(df.fillna(0) == 0).all(axis=1)]\n",
    "                            df = df.loc[:, ~(df.fillna(0) == 0).all(axis=0)]\n",
    "                            dfCa_filtered2[sheet_name] = df    \n",
    "                        first_key = list(dfCa_filtered2.keys())[0]\n",
    "                        common_columns = dfCa_filtered2[first_key].columns\n",
    "                        common_indices = dfCa_filtered2[first_key].index\n",
    "                        for df in dfCa_filtered2.values():\n",
    "                            common_columns = common_columns.intersection(df.columns)\n",
    "                            common_indices = common_indices.intersection(df.index)\n",
    "                        dfCa_DoubleFiltered2 = {name: df.loc[common_indices, common_columns] for name, df in dfCa_filtered2.items()}\n",
    "\n",
    "                        dfCa_DoubleFiltered.update(dfCa_DoubleFiltered2)    # modifies z with keys and values of y\n",
    "                    \n",
    "                    # Save Corr Pairs\n",
    "                    file_path = f'{folder_to_save2}/{List_name}/{NrSubtype}_VigSt_PairCorrCa_{List_name}.xlsx'\n",
    "                    with pd.ExcelWriter(file_path) as writer:\n",
    "                        for sheet_name, dfCa in dfCa_DoubleFiltered.items():\n",
    "                            if 'Z_' not in sheet_name:                            \n",
    "                                dfCa = dfCa.sort_index(axis=1)\n",
    "                                dfCa = dfCa.sort_index(axis=0)\n",
    "                                dfCa.to_excel(writer, sheet_name=sheet_name, index=True, header=True)\n",
    "\n",
    "                    # Flat correlations\n",
    "                    SummaryMatrixCa= pd.DataFrame()\n",
    "                    for sheet_name, df in dfCa_DoubleFiltered.items():    \n",
    "                        series_flattened = df.stack().reset_index()\n",
    "                        series_flattened['index'] = series_flattened['level_0'] + '_' + series_flattened['level_1']\n",
    "                        series_flattened = series_flattened.set_index('index')[0]\n",
    "                        series_flattened_cleaned = series_flattened[series_flattened.index.str.split('_').str[0] != series_flattened.index.str.split('_').str[1]] #remove Neuron1 vs Neuron1\n",
    "                        series_flattened_cleaned.name = sheet_name\n",
    "                        SummaryMatrixCa = pd.concat([SummaryMatrixCa,series_flattened_cleaned], axis=1)\n",
    "                    \n",
    "                    SummaryMatrixCa_cleaned = SummaryMatrixCa.round(5) # to better detect duplicate                   \n",
    "                    SummaryMatrixCa_cleaned = SummaryMatrixCa.drop_duplicates(subset=SummaryMatrixCa.columns[1:]) \n",
    "                    #SummaryMatrixCa_cleaned = SummaryMatrixCa_cleaned.drop(columns=[SummaryMatrixCa_cleaned.columns[0], SummaryMatrixCa_cleaned.columns[2], SummaryMatrixCa_cleaned.columns[4], SummaryMatrixCa_cleaned.columns[6], SummaryMatrixCa_cleaned.columns[8], SummaryMatrixCa_cleaned.columns[10]]) if DrugExperiment else SummaryMatrixCa_cleaned.drop(columns=[SummaryMatrixCa_cleaned.columns[0], SummaryMatrixCa_cleaned.columns[2], SummaryMatrixCa_cleaned.columns[4]])\n",
    "                    \"\"\"\n",
    "                    df_reset = SummaryMatrixCa_cleaned.reset_index()       \n",
    "                    if len(df_reset)>0:\n",
    "                        melted_df = pd.melt(df_reset, id_vars=['index'], var_name='VigilanceSt', value_name='CorrCoeff')\n",
    "                        split_columns = melted_df['VigilanceSt'].str.split('_', expand=True)\n",
    "                        split_columns.columns = ['Transformation','Drug','Substate']\n",
    "                        melted_df = pd.concat([melted_df, split_columns], axis=1)\n",
    "                        extracted_micename = [extract_micename(idx) for idx in melted_df['index']]\n",
    "                        melted_df['Mice']=extracted_micename            \n",
    "                    else: \n",
    "                        melted_df = pd.DataFrame() \n",
    "\n",
    "                    filenameOut = f'{folder_to_save2}/{List_name}/GLM_{NrSubtype}_FlatPairCaCorr_{List_name}.xlsx'\n",
    "                    melted_df.to_excel(filenameOut, index=True, header=True)\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_VigSt_FlatPairCaCorr_{List_name}.xlsx'\n",
    "                    SummaryMatrixCa_cleaned.to_excel(filenameOut, index=True, header=True) \n",
    "\n",
    "                    ###########################################################\n",
    "                    ## Vig St Ca correlation with neurons from different population ##\n",
    "                    ###########################################################\n",
    "\n",
    "                    # Keep only neurons from the list \n",
    "                    dfCa_filtered={}\n",
    "                    for sheet_name, dfCa in combined_dfCa.items():\n",
    "                        dfCa=pd.DataFrame(dfCa)\n",
    "                        indices_to_keep_existing = [idx for idx in listI if idx in dfCa.index] #from first list\n",
    "                        columns_to_keep_existing = [col for col in listII if col in dfCa.columns] #from second list\n",
    "                        dfCa_filtered[sheet_name] = dfCa.loc[indices_to_keep_existing, columns_to_keep_existing]\n",
    "                        \n",
    "                    if DrugExperiment==1: \n",
    "                        # Keep only correlation pairs that occurs for each Drug condition                     \n",
    "                        dfCa_filtered2 = copy.deepcopy(dfCa_filtered)\n",
    "                        keys_to_keep =['baseline_AW', 'Z_baseline_AW', 'CGP_AW', 'Z_CGP_AW']\n",
    "                        dfCa_filtered2 = {k: dfCa_filtered2[k] for k in keys_to_keep if k in dfCa_filtered2}\n",
    "                        for sheet_name, df in dfCa_filtered2.items(): #remove inactive/non recorded neurons\n",
    "                            df = df[~(df.fillna(0) == 0).all(axis=1)]\n",
    "                            df = df.loc[:, ~(df.fillna(0) == 0).all(axis=0)]\n",
    "                            dfCa_filtered2[sheet_name] = df    \n",
    "                        first_key = list(dfCa_filtered2.keys())[0]\n",
    "                        common_columns = dfCa_filtered2[first_key].columns\n",
    "                        common_indices = dfCa_filtered2[first_key].index\n",
    "                        for df in dfCa_filtered2.values():\n",
    "                            common_columns = common_columns.intersection(df.columns)\n",
    "                            common_indices = common_indices.intersection(df.index)\n",
    "                        dfCa_DoubleFiltered = {name: df.loc[common_indices, common_columns] for name, df in dfCa_filtered2.items()}\n",
    "\n",
    "                        dfCa_filtered2 = copy.deepcopy(dfCa_filtered)\n",
    "                        keys_to_keep =['baseline_QW', 'Z_baseline_QW', 'CGP_QW', 'Z_CGP_QW']\n",
    "                        dfCa_filtered2 = {k: dfCa_filtered2[k] for k in keys_to_keep if k in dfCa_filtered2}\n",
    "                        for sheet_name, df in dfCa_filtered2.items(): #remove inactive/non recorded neurons\n",
    "                            df = df[~(df.fillna(0) == 0).all(axis=1)]\n",
    "                            df = df.loc[:, ~(df.fillna(0) == 0).all(axis=0)]\n",
    "                            dfCa_filtered2[sheet_name] = df    \n",
    "                        first_key = list(dfCa_filtered2.keys())[0]\n",
    "                        common_columns = dfCa_filtered2[first_key].columns\n",
    "                        common_indices = dfCa_filtered2[first_key].index\n",
    "                        for df in dfCa_filtered2.values():\n",
    "                            common_columns = common_columns.intersection(df.columns)\n",
    "                            common_indices = common_indices.intersection(df.index)\n",
    "                        dfCa_DoubleFiltered2 = {name: df.loc[common_indices, common_columns] for name, df in dfCa_filtered2.items()}\n",
    "\n",
    "                        dfCa_filtered2 = copy.deepcopy(dfCa_filtered)\n",
    "                        keys_to_keep =['baseline_NREM', 'Z_baseline_NREM', 'CGP_NREM', 'Z_CGP_NREM']\n",
    "                        dfCa_filtered2 = {k: dfCa_filtered2[k] for k in keys_to_keep if k in dfCa_filtered2}\n",
    "                        for sheet_name, df in dfCa_filtered2.items(): #remove inactive/non recorded neurons\n",
    "                            df = df[~(df.fillna(0) == 0).all(axis=1)]\n",
    "                            df = df.loc[:, ~(df.fillna(0) == 0).all(axis=0)]\n",
    "                            dfCa_filtered2[sheet_name] = df    \n",
    "                        first_key = list(dfCa_filtered2.keys())[0]\n",
    "                        common_columns = dfCa_filtered2[first_key].columns\n",
    "                        common_indices = dfCa_filtered2[first_key].index\n",
    "                        for df in dfCa_filtered2.values():\n",
    "                            common_columns = common_columns.intersection(df.columns)\n",
    "                            common_indices = common_indices.intersection(df.index)\n",
    "                        dfCa_DoubleFiltered2 = {name: df.loc[common_indices, common_columns] for name, df in dfCa_filtered2.items()}\n",
    "                        \n",
    "                        dfCa_filtered2 = copy.deepcopy(dfCa_filtered)\n",
    "                        keys_to_keep =['baseline_REM', 'Z_baseline_REM', 'CGP_REM', 'Z_CGP_REM']\n",
    "                        dfCa_filtered2 = {k: dfCa_filtered2[k] for k in keys_to_keep if k in dfCa_filtered2}\n",
    "                        for sheet_name, df in dfCa_filtered2.items(): #remove inactive/non recorded neurons\n",
    "                            df = df[~(df.fillna(0) == 0).all(axis=1)]\n",
    "                            df = df.loc[:, ~(df.fillna(0) == 0).all(axis=0)]\n",
    "                            dfCa_filtered2[sheet_name] = df    \n",
    "                        first_key = list(dfCa_filtered2.keys())[0]\n",
    "                        common_columns = dfCa_filtered2[first_key].columns\n",
    "                        common_indices = dfCa_filtered2[first_key].index\n",
    "                        for df in dfCa_filtered2.values():\n",
    "                            common_columns = common_columns.intersection(df.columns)\n",
    "                            common_indices = common_indices.intersection(df.index)\n",
    "                        dfCa_DoubleFiltered3 = {name: df.loc[common_indices, common_columns] for name, df in dfCa_filtered2.items()}\n",
    "            \n",
    "                        dfCa_DoubleFiltered.update(dfCa_DoubleFiltered2)    # modifies z with keys and values of y\n",
    "                        dfCa_DoubleFiltered.update(dfCa_DoubleFiltered3)    # modifies z with keys and values of y\n",
    "\n",
    "                    elif DrugExperiment==0:\n",
    "                        # Keep only correlation pairs that occurs for each Vig States  \n",
    "                        dfCa_filtered2 = copy.deepcopy(dfCa_filtered)\n",
    "                        for key in ['CGP_AW', 'Z_CGP_AW','CGP_QW', 'Z_CGP_QW', 'CGP_NREM', 'Z_CGP_NREM', 'CGP_REM', 'Z_CGP_REM']:\n",
    "                            if key in dfCa_filtered2:\n",
    "                                del dfCa_filtered2[key]\n",
    "                        for sheet_name, df in dfCa_filtered2.items(): #remove inactive/non recorded neurons\n",
    "                            df = df[~(df.fillna(0) == 0).all(axis=1)]\n",
    "                            df = df.loc[:, ~(df.fillna(0) == 0).all(axis=0)]\n",
    "                            dfCa_filtered2[sheet_name] = df    \n",
    "                        first_key = list(dfCa_filtered2.keys())[0]\n",
    "                        common_columns = dfCa_filtered2[first_key].columns\n",
    "                        common_indices = dfCa_filtered2[first_key].index\n",
    "                        for df in dfCa_filtered2.values():\n",
    "                            common_columns = common_columns.intersection(df.columns)\n",
    "                            common_indices = common_indices.intersection(df.index)\n",
    "                        dfCa_DoubleFiltered = {name: df.loc[common_indices, common_columns] for name, df in dfCa_filtered2.items()}\n",
    "                    \n",
    "                    elif DrugExperiment ==2: \n",
    "                        # Keep only correlation pairs that occurs for each Vig States  \n",
    "                        dfCa_filtered2 = copy.deepcopy(dfCa_filtered)\n",
    "                        keys_to_keep =['CGP_AW', 'Z_CGP_AW','CGP_QW', 'Z_CGP_QW', 'CGP_NREM', 'Z_CGP_NREM', 'CGP_REM', 'Z_CGP_REM']\n",
    "                        dfCa_filtered2 = {k: dfCa_filtered2[k] for k in keys_to_keep if k in dfCa_filtered2}\n",
    "                        for sheet_name, df in dfCa_filtered2.items(): #remove inactive/non recorded neurons\n",
    "                            df = df[~(df.fillna(0) == 0).all(axis=1)]\n",
    "                            df = df.loc[:, ~(df.fillna(0) == 0).all(axis=0)]\n",
    "                            dfCa_filtered2[sheet_name] = df    \n",
    "                        first_key = list(dfCa_filtered2.keys())[0]\n",
    "                        common_columns = dfCa_filtered2[first_key].columns\n",
    "                        common_indices = dfCa_filtered2[first_key].index\n",
    "                        for df in dfCa_filtered2.values():\n",
    "                            common_columns = common_columns.intersection(df.columns)\n",
    "                            common_indices = common_indices.intersection(df.index)\n",
    "                        dfCa_DoubleFiltered = {name: df.loc[common_indices, common_columns] for name, df in dfCa_filtered2.items()}\n",
    "                        \n",
    "                        dfCa_filtered2 = copy.deepcopy(dfCa_filtered)\n",
    "                        keys_to_keep =['baseline_AW', 'Z_baseline_AW','baseline_QW', 'Z_baseline_QW', 'baseline_NREM', 'Z_baseline_NREM', 'baseline_REM', 'Z_baseline_REM']\n",
    "                        dfCa_filtered2 = {k: dfCa_filtered2[k] for k in keys_to_keep if k in dfCa_filtered2}              \n",
    "                        for sheet_name, df in dfCa_filtered2.items(): #remove inactive/non recorded neurons\n",
    "                            df = df[~(df.fillna(0) == 0).all(axis=1)]\n",
    "                            df = df.loc[:, ~(df.fillna(0) == 0).all(axis=0)]\n",
    "                            dfCa_filtered2[sheet_name] = df    \n",
    "                        first_key = list(dfCa_filtered2.keys())[0]\n",
    "                        common_columns = dfCa_filtered2[first_key].columns\n",
    "                        common_indices = dfCa_filtered2[first_key].index\n",
    "                        for df in dfCa_filtered2.values():\n",
    "                            common_columns = common_columns.intersection(df.columns)\n",
    "                            common_indices = common_indices.intersection(df.index)\n",
    "                        dfCa_DoubleFiltered2 = {name: df.loc[common_indices, common_columns] for name, df in dfCa_filtered2.items()}\n",
    "\n",
    "                        dfCa_DoubleFiltered.update(dfCa_DoubleFiltered2)    # modifies z with keys and values of y\n",
    "                    \n",
    "                    # Save Corr Pairs\n",
    "                    file_path = f'{folder_to_save2}/{List_name}/{NrSubtype}_VigSt_PairCorrCa_{SecondaryList_name}.xlsx'\n",
    "                    with pd.ExcelWriter(file_path) as writer:\n",
    "                        for sheet_name, dfCa in dfCa_DoubleFiltered.items():\n",
    "                            if 'Z_' not in sheet_name:\n",
    "                                dfCa = dfCa.sort_index(axis=1)\n",
    "                                dfCa = dfCa.sort_index(axis=0)\n",
    "                                dfCa.to_excel(writer, sheet_name=sheet_name, index=True, header=True)\n",
    "                    \n",
    "                    # Flat correlations\n",
    "                    SummaryMatrixCa= pd.DataFrame()\n",
    "                    for sheet_name, df in dfCa_DoubleFiltered.items():    \n",
    "                        series_flattened = df.stack().reset_index()\n",
    "                        series_flattened['index'] = series_flattened['level_0'] + '_' + series_flattened['level_1']\n",
    "                        series_flattened = series_flattened.set_index('index')[0]\n",
    "                        series_flattened_cleaned = series_flattened[series_flattened.index.str.split('_').str[0] != series_flattened.index.str.split('_').str[1]] #remove Neuron1 vs Neuron1\n",
    "                        series_flattened_cleaned.name = sheet_name\n",
    "                        SummaryMatrixCa = pd.concat([SummaryMatrixCa,series_flattened_cleaned], axis=1)\n",
    "                    \n",
    "                    SummaryMatrixCa_cleaned = SummaryMatrixCa.round(5) # to better detect duplicate                   \n",
    "                    SummaryMatrixCa_cleaned = SummaryMatrixCa.drop_duplicates(subset=SummaryMatrixCa.columns[1:]) \n",
    "                    #SummaryMatrixCa_cleaned = SummaryMatrixCa_cleaned.drop(columns=[SummaryMatrixCa_cleaned.columns[0], SummaryMatrixCa_cleaned.columns[2], SummaryMatrixCa_cleaned.columns[4], SummaryMatrixCa_cleaned.columns[6], SummaryMatrixCa_cleaned.columns[8], SummaryMatrixCa_cleaned.columns[10]]) if DrugExperiment else SummaryMatrixCa_cleaned.drop(columns=[SummaryMatrixCa_cleaned.columns[0], SummaryMatrixCa_cleaned.columns[2], SummaryMatrixCa_cleaned.columns[4]])\n",
    "\n",
    "                    \"\"\"\n",
    "                    df_reset = SummaryMatrixCa_cleaned.reset_index()       \n",
    "                    if len(df_reset)>0:\n",
    "                        melted_df = pd.melt(df_reset, id_vars=['index'], var_name='VigilanceSt', value_name='CorrCoeff')\n",
    "                        split_columns = melted_df['VigilanceSt'].str.split('_', expand=True)\n",
    "                        split_columns.columns = ['Transformation','Drug','Substate']\n",
    "                        melted_df = pd.concat([melted_df, split_columns], axis=1)\n",
    "                        extracted_micename = [extract_micename(idx) for idx in melted_df['index']]\n",
    "                        melted_df['Mice']=extracted_micename            \n",
    "                    else: \n",
    "                        melted_df = pd.DataFrame()\n",
    "\n",
    "                    filenameOut = f'{folder_to_save2}/{List_name}/GLM_{NrSubtype}_FlatPairCaCorr_{SecondaryList_name}.xlsx'\n",
    "                    melted_df.to_excel(filenameOut, index=True, header=True)  \n",
    "                    \"\"\"\n",
    "                    filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_VigSt_FlatPairCaCorr_{SecondaryList_name}.xlsx'\n",
    "                    SummaryMatrixCa_cleaned.to_excel(filenameOut, index=True, header=True)   \n",
    "                    \n",
    "\n",
    "                filenameOut = f'{folder_to_save2}/{List_name}/GLM_{NrSubtype}_VigSt_Global.xlsx'\n",
    "                filtered_df.to_excel(filenameOut)\n",
    "                \n",
    "                #####################    \n",
    "                # POPULATION COUPLING #\n",
    "                #####################\n",
    "\n",
    "                CaPopCoupling_perUnit = filtered_df.pivot_table(index='Unit_ID', columns='Session_ID', values='TotZ_CaPopCoupling', aggfunc='mean')\n",
    "                CaPopCoupling_perUnit['AllSession']=CaPopCoupling_perUnit.mean(axis=1)  \n",
    "                # Save CaPopCoupling_perUnit\n",
    "                filenameOutCaPopCoupling = f'{folder_to_save2}/{List_name}/{NrSubtype}_Tot_ZCaPopCoupling.xlsx'\n",
    "                writerCaPopCoupling = pd.ExcelWriter(filenameOutCaPopCoupling)\n",
    "                CaPopCoupling_perUnit.to_excel(writerCaPopCoupling)\n",
    "                writerCaPopCoupling.close()\n",
    "\n",
    "                #####################\n",
    "                # AUC CALCIUM #\n",
    "                #####################\n",
    "\n",
    "                resultNormalizedAUC_calcium_perUnit = filtered_df.pivot_table(index='Unit_ID', columns='Substate', values='NormalizedAUC_calcium', aggfunc='mean')   \n",
    "                try : resultNormalizedAUC_calcium_perUnit = resultNormalizedAUC_calcium_perUnit[desired_order]\n",
    "                except: pass\n",
    "                resultNormalizedAUC_calcium_perUnit['Activated_by'] = resultNormalizedAUC_calcium_perUnit.apply(max_column_name, axis=1)\n",
    "                proportions = resultNormalizedAUC_calcium_perUnit['Activated_by'].value_counts(normalize=True)*100\n",
    "                \n",
    "                filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_VigStAct_nAUC_proportions.xlsx'\n",
    "                proportions.to_excel(filenameOut)\n",
    "\n",
    "                filenameOutAUC = f'{folder_to_save2}/{List_name}/{NrSubtype}_VigSt_nAUC.xlsx'\n",
    "                resultNormalizedAUC_calcium_perUnit.to_excel(filenameOutAUC)\n",
    "\n",
    "                if Drug == 'baseline':\n",
    "                    BaselineResultNormalizedAUC=resultNormalizedAUC_calcium_perUnit\n",
    "                    \n",
    "                resultNormalizedAUC_calcium_perMouse = filtered_df.pivot_table(index='Mice', columns='Substate', values='NormalizedAUC_calcium', aggfunc='mean')\n",
    "                try: resultNormalizedAUC_calcium_perMouse = resultNormalizedAUC_calcium_perMouse[desired_order]\n",
    "                except: pass\n",
    "                filenameOutAUCM = f'{folder_to_save2}/{List_name}/{NrSubtype}_VigSt_AUC_perMouse.xlsx'\n",
    "                resultNormalizedAUC_calcium_perMouse.to_excel(filenameOutAUCM)\n",
    "\n",
    "                #####################\n",
    "                # DECONV ACTIVITY #\n",
    "                #####################\n",
    "                \n",
    "                resultSpikeActivity_perUnit = filtered_df.pivot_table(index='Unit_ID', columns='Substate', values='DeconvSpikeMeanActivity', aggfunc='mean')    \n",
    "                try: resultSpikeActivity_perUnit = resultSpikeActivity_perUnit[desired_order]\n",
    "                except: pass\n",
    "                resultSpikeActivity_perUnit['Activated_by'] = resultSpikeActivity_perUnit.apply(max_column_name, axis=1)\n",
    "                proportions = resultSpikeActivity_perUnit['Activated_by'].value_counts(normalize=True)*100\n",
    "                filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_VigStAct_Deconv_proportions.xlsx'\n",
    "                proportions.to_excel(filenameOut)\n",
    "\n",
    "                # Save  df\n",
    "                filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_VigSt_DeconvSpike.xlsx'\n",
    "                resultSpikeActivity_perUnit.to_excel(filenameOut)\n",
    "\n",
    "                resultSpikeActivity_perMouse = filtered_df.pivot_table(index='Mice', columns='Substate', values='DeconvSpikeMeanActivity', aggfunc='mean')\n",
    "                try: resultSpikeActivity_perMouse = resultSpikeActivity_perMouse[desired_order]\n",
    "                except: pass\n",
    "                filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_VigSt_DeconvSpike_perMouse.xlsx'\n",
    "                writer = pd.ExcelWriter(filenameOut)\n",
    "                resultSpikeActivity_perMouse.to_excel(writer)\n",
    "                writer.close()\n",
    "            \n",
    "                \n",
    "                #####################\n",
    "                # Spike ACTIVITY #\n",
    "                #####################\n",
    "                \n",
    "                resultSpikeActivity_perUnit = filtered_df.pivot_table(index='Unit_ID', columns='Substate', values='SpikeActivityHz', aggfunc='mean')    \n",
    "                try: resultSpikeActivity_perUnit = resultSpikeActivity_perUnit[desired_order]\n",
    "                except: pass\n",
    "                resultSpikeActivity_perUnit['Activated_by'] = resultSpikeActivity_perUnit.apply(max_column_name, axis=1)\n",
    "                proportions = resultSpikeActivity_perUnit['Activated_by'].value_counts(normalize=True)*100\n",
    "                filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_VigStAct_SpikeHz_proportions.xlsx'\n",
    "                proportions.to_excel(filenameOut)\n",
    "\n",
    "                # Save  df\n",
    "                filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_VigSt_SpikeActivityHz.xlsx'\n",
    "                resultSpikeActivity_perUnit.to_excel(filenameOut)\n",
    "\n",
    "                resultSpikeActivity_perMouse = filtered_df.pivot_table(index='Mice', columns='Substate', values='SpikeActivityHz', aggfunc='mean')\n",
    "                try: resultSpikeActivity_perMouse = resultSpikeActivity_perMouse[desired_order]\n",
    "                except: pass\n",
    "                filenameOut = f'{folder_to_save2}/{List_name}/{NrSubtype}_VigSt_SpikeActivityHz_perMouse.xlsx'\n",
    "                writer = pd.ExcelWriter(filenameOut)\n",
    "                resultSpikeActivity_perMouse.to_excel(writer)\n",
    "                writer.close()\n",
    "\n",
    "            \n",
    "                #####################    \n",
    "                # POPULATION COUPLING #\n",
    "                #####################\n",
    "\n",
    "                CaPopCoupling_perUnit = filtered_df.pivot_table(index='Unit_ID', columns='Substate', values='Z_CaPopCoupling', aggfunc='mean')\n",
    "                try: CaPopCoupling_perUnit = CaPopCoupling_perUnit[desired_order]\n",
    "                except: pass\n",
    "                # Save CaPopCoupling_perUnit\n",
    "                filenameOutCaPopCoupling = f'{folder_to_save2}/{List_name}/{NrSubtype}_VigSt_Z_CaPopCoupling.xlsx'\n",
    "                writerCaPopCoupling = pd.ExcelWriter(filenameOutCaPopCoupling)\n",
    "                CaPopCoupling_perUnit.to_excel(writerCaPopCoupling)\n",
    "                writerCaPopCoupling.close()\n",
    "                \n",
    "                CaPopCoupling_perUnit = filtered_df.pivot_table(index='Unit_ID', columns=[filtered_df['Substate'], filtered_df['Session_ID']], values='Z_CaPopCoupling', aggfunc='mean')   \n",
    "                try : CaPopCoupling_perUnit = CaPopCoupling_perUnit[desired_order]\n",
    "                except: pass\n",
    "\n",
    "                filenameOutAUC = f'{folder_to_save2}/{List_name}/{NrSubtype}_VarAcrossVigSt_CaPopCoup.xlsx'\n",
    "                CaPopCoupling_perUnit.to_excel(filenameOutAUC)\n",
    "\n",
    "        if DrugExperiment:\n",
    "            resultNormalizedAUC_calcium_perUnit = resultNormalizedAUC_calcium_perUnit.rename(columns={'Wake': 'CGP Wake', 'NREM': 'CGP NREM', 'REM': 'CGP REM', 'Activated_by':'CGP Activated_by', 'RatioNREM_REM':'CGP RatioNREM_REM'})\n",
    "            mergeRes=pd.concat([BaselineResultNormalizedAUC,resultNormalizedAUC_calcium_perUnit], axis=1)\n",
    "            filenameOut = f'{folder_to_save}/{NrSubtype}_SelectivityIndex.xlsx'\n",
    "            mergeRes.to_excel(filenameOut)\n",
    "\n",
    "#######################\n",
    "# Propreties VigStates\n",
    "#######################\n",
    "\n",
    "filenameOut = f'{folder_to_save}/VigStPropreties.xlsx'\n",
    "writer = pd.ExcelWriter(filenameOut)\n",
    "\n",
    "combined_df2 = combined_dfO.drop_duplicates(subset='Substate_ID', keep='first')\n",
    "\n",
    "DurationVigStates = combined_df2.pivot_table(index='Mice', columns=[combined_df2['Drug'], combined_df2['Substate']], values='DurationSubstate', aggfunc='mean', fill_value=None)\n",
    "try: DurationVigStates = DurationVigStates[desired_order]\n",
    "except: pass        \n",
    "AllDurationVigStates=pd.concat([AllDurationVigStates, DurationVigStates], axis=0)\n",
    "\n",
    "TotDurationVigStates = combined_df2.pivot_table(index='Mice', columns=[combined_df2['Drug'], combined_df2['Substate']], values='DurationSubstate', aggfunc='sum', fill_value=None)\n",
    "try: TotDurationVigStates = TotDurationVigStates[desired_order]\n",
    "except: pass\n",
    "AllTotDurationVigStates=pd.concat([AllTotDurationVigStates, TotDurationVigStates], axis=0)\n",
    "\n",
    "AllDurationVigStates.to_excel(writer, sheet_name=f'MeanEpisodeDurations')\n",
    "AllTotDurationVigStates.to_excel(writer, sheet_name=f'TotalEpisodeDurations')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aff4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "directorY=\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_CGP_analysis/VigSt_2025-05-03_12_01_21/TotCaCorr_BlueLines.pkl\"\n",
    "with open(directorY, 'rb') as pickle_file:\n",
    "    combined_dfO = pickle.load(pickle_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
