{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca608c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynapple as nap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(style=\"ticks\", palette=\"colorblind\", font_scale=1.0, rc=custom_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the frequency of the wavelets in our filter bank\n",
    "freqs = np.linspace(1, 25, num=25)\n",
    "Fs=1000\n",
    "# Get the filter bank\n",
    "filter_bank = nap.generate_morlet_filterbank(\n",
    "    freqs, Fs, gaussian_width=1.5, window_length=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c4c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_lengths = [1, 2, 4]\n",
    "gaussian_widths = [1.0, 4.0, 8]\n",
    "colors = np.array([[\"r\", \"g\", 'k', 'y'], [\"b\", \"y\", 'c', 'p']])\n",
    "fig = plt.figure()\n",
    "fig, ax = plt.subplots(\n",
    "    len(window_lengths) + 1,\n",
    "    len(gaussian_widths) + 1,\n",
    "    constrained_layout=True,\n",
    "    figsize=(10, 8),\n",
    ")\n",
    "for row_i, wl in enumerate(window_lengths):\n",
    "    for col_i, gw in enumerate(gaussian_widths):\n",
    "        wavelet = nap.generate_morlet_filterbank(\n",
    "            np.array([15.0]), Fs, gaussian_width=gw, window_length=wl, precision=12\n",
    "        )[:, 0].real()\n",
    "        ax[row_i, col_i].plot(wavelet, c='k')\n",
    "        fft = nap.compute_power_spectral_density(wavelet)\n",
    "        for i, j in [(row_i, -1), (-1, col_i)]:\n",
    "            ax[i, j].plot(fft.abs(), c='k')\n",
    "        ax[row_i, col_i].set(xlim=(-2, 2))\n",
    "for i in range(len(window_lengths)):\n",
    "    for j in range(len(gaussian_widths)):\n",
    "        ax[i, j].set(xlabel=\"Time (s)\", yticks=[])\n",
    "for ci, gw in enumerate(gaussian_widths):\n",
    "    ax[0, ci].set_title(f\"gaussian_width={gw}\", fontsize=10)\n",
    "for ri, wl in enumerate(window_lengths):\n",
    "    ax[ri, 0].set_ylabel(f\"window_length={wl}\", fontsize=10)\n",
    "fig.suptitle(\"Parametrization Visualization (15 Hz Wavelet)\")\n",
    "ax[-1, -1].set_visible(False)\n",
    "for i in range(len(window_lengths)):\n",
    "    ax[-1, i].set(\n",
    "        xlim=(0, 20), yticks=[], ylabel=\"Frequency Response\", xlabel=\"Frequency (Hz)\"\n",
    "    )\n",
    "for i in range(len(gaussian_widths)):\n",
    "    ax[i, -1].set(\n",
    "        xlim=(0, 20), yticks=[], ylabel=\"Frequency Response\", xlabel=\"Frequency (Hz)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "                            # Define Directory #\n",
    "#######################################################################################\n",
    "\n",
    "dir = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/L2_3_mice/ThreeColDots/preCGP/\"\n",
    "\n",
    "#######################################################################################\n",
    "                                # Load Packages #\n",
    "#######################################################################################\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pynapple as nap\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import IPython\n",
    "import os\n",
    "import warnings\n",
    "from scipy.stats import zscore\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#######################################################################################\n",
    "                                # Define functions #\n",
    "#######################################################################################\n",
    "def restriction_parameter(All_Spindle):\n",
    "    nb_spindle = All_Spindle.shape[0]\n",
    "    listtodrop = []\n",
    "    for tt in range(nb_spindle-1):\n",
    "        # merge spdl that starts within a spdl\n",
    "        if(All_Spindle['end time'][tt]>All_Spindle['start time'][tt + 1]):\n",
    "            if(All_Spindle['Duration'][tt]<All_Spindle['Duration'][tt + 1]):\n",
    "                if(All_Spindle['start time'][tt]<All_Spindle['start time'][tt + 1]):\n",
    "                    All_Spindle['start time'][tt+1] = All_Spindle['start time'][tt]\n",
    "                    listtodrop.append(tt)\n",
    "                else:\n",
    "                    listtodrop.append(tt)\n",
    "            if(All_Spindle['Duration'][tt]>All_Spindle['Duration'][tt + 1]):\n",
    "                if(All_Spindle['end time'][tt]<All_Spindle['end time'][tt + 1]):\n",
    "                    All_Spindle['end time'][tt] = All_Spindle['end time'][tt + 1]\n",
    "                    listtodrop.append(tt+1)\n",
    "                else:\n",
    "                    listtodrop.append(tt+1)\n",
    "    \"\"\"\n",
    "    for tt in range(nb_spindle-1):\n",
    "        # merge spdls that are 200ms apart\n",
    "        if((All_Spindle['start time'][tt + 1] - All_Spindle['end time'][tt])<200):\n",
    "            if((All_Spindle['Duration'][tt])<All_Spindle['Duration'][tt + 1]): #first spdl longer so remove/merge the second one\n",
    "                All_Spindle['start time'][tt + 1] = min(All_Spindle['start time'][tt], All_Spindle['start time'][tt+1])\n",
    "                All_Spindle['end time'][tt+ 1] = max(All_Spindle['end time'][tt + 1], All_Spindle['end time'][tt])\n",
    "                listtodrop.append(tt)\n",
    "            if((All_Spindle['Duration'][tt+1])<All_Spindle['Duration'][tt]): #second spdl longer so remove/merge the first one\n",
    "                All_Spindle['start time'][tt] = min(All_Spindle['start time'][tt], All_Spindle['start time'][tt+1])\n",
    "                All_Spindle['end time'][tt] = max(All_Spindle['end time'][tt + 1], All_Spindle['end time'][tt])\n",
    "                listtodrop.append(tt+1)\n",
    "    \"\"\"\n",
    "    for tt in range(nb_spindle):\n",
    "        #Update duration because of the merging\n",
    "        All_Spindle['Duration'][tt]=All_Spindle['end time'][tt]-All_Spindle['start time'][tt]\n",
    "\n",
    "    for tt in range(nb_spindle): #All_Spindle.index:\n",
    "        #Remove Spdl that last less than 500ms\n",
    "        if (All_Spindle['Duration'][tt]<400):\n",
    "            listtodrop.append(tt)        \n",
    "    \n",
    "    All_Spindle = All_Spindle.drop(listtodrop) \n",
    "    All_Spindle = All_Spindle.reset_index(drop=True)\n",
    "    return All_Spindle\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "                                # Load Signals #\n",
    "#######################################################################################\n",
    "\n",
    "#Load LFP coordinates \n",
    "notebook_path = Path(\"/\".join(IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\")[-5:]))\n",
    "Channels = f'{notebook_path.parent}/_LFP_coordinates_of_all_mice.csv'\n",
    "all_LFPcoordinates = pd.read_csv(Channels, index_col=0)\n",
    "\n",
    "\n",
    "for dpath in Path(dir).glob('**/DataFrame_rawdataDS.pkl'):\n",
    "    #Load signals\n",
    "    folder_base = Path(dpath).parent\n",
    "    print(folder_base)\n",
    "    LFPfile = Path(f'{folder_base}\\DataFrame_rawdataDS.pkl')\n",
    "    LFPs_df = pd.read_pickle(LFPfile)\n",
    "    samplerate = 1000 \n",
    "    numchannel = LFPs_df.shape[1]\n",
    "    rec_ch_list = LFPs_df.columns.values\n",
    "    # Load LFPs timestamps \n",
    "    for file_pathTS in folder_base.parent.parent.glob('**/continuous/*/timeStampsDS.npy'):\n",
    "        print('LFPs timestamps file found')\n",
    "        LFPtimestamps = np.load(file_pathTS)  \n",
    "    print(round(LFPs_df.shape[0]/samplerate/60), 'min of recording')\n",
    "\n",
    "    # Identify mouse & choose threshold for detection\n",
    "    mouse = []\n",
    "    pos_mice = []\n",
    "    for mouse_name in all_LFPcoordinates.index:\n",
    "        if mouse_name in LFPfile.__str__():\n",
    "            mouse.append(mouse_name)\n",
    "            pos_mice.append(LFPfile.__str__().find(mouse_name)) \n",
    "    mouse = [x for _, x in sorted(zip(pos_mice, mouse))] # sort mouse in the same order as they appear in the path\n",
    "    mouse=mouse[0]   \n",
    "\n",
    "    # Identify electrodes & create differential LFPs\n",
    "    all_LFPcoordinates = all_LFPcoordinates.astype(str)\n",
    "    for region in all_LFPcoordinates.loc[mouse].index:\n",
    "        locals()[region] = []\n",
    "        locals()[f'{region}_ch'] = []\n",
    "    ID=0\n",
    "    rec_ch_list_mouse = [value for value in rec_ch_list if 0+(ID*32) <= value <= 31+(ID*32)]\n",
    "    for rec_ch in rec_ch_list_mouse:\n",
    "        for idx, LFPcoord_str in enumerate(all_LFPcoordinates.loc[mouse]):\n",
    "            region = all_LFPcoordinates.loc[mouse].index[idx]\n",
    "            if LFPcoord_str != 'nan':\n",
    "                LFPcoord = LFPcoord_str.split('_')[:2] # only take into account the 2 first of electrode of that region \n",
    "                num_ch = np.where(str(rec_ch-(ID*32)) == np.array(LFPcoord))[0]\n",
    "                if len(num_ch) > 0:\n",
    "                    region = all_LFPcoordinates.loc[mouse].index[idx]\n",
    "                    LFP = locals()[region]\n",
    "                    LFP = LFP-np.array(LFPs_df[(rec_ch)]) if len(LFP) > 0 else np.array(LFPs_df[(rec_ch)])\n",
    "                    locals()[region] = LFP\n",
    "                    locals()[f'{region}_ch'].append(rec_ch)\n",
    "                    break\n",
    "                continue    \n",
    "    for region in all_LFPcoordinates.loc[mouse].index:\n",
    "        LFP = locals()[region]\n",
    "        LFP_ch = locals()[f'{region}_ch']\n",
    "\n",
    "\n",
    "    \n",
    "    # Load Sleep Scoring    \n",
    "    ScoringFile= folder_base / f'Sleep_Scoring_6Stages_5sEpoch.csv'\n",
    "    SleepScored = pd.read_csv(ScoringFile)\n",
    "    SleepScored['label']= SleepScored['label'].str.extract(r'(\\d+)', expand=False)\n",
    "    SleepScoredTS=np.array(SleepScored['label'])\n",
    "    scale_factor=samplerate/0.2  #cause scoring was done in 5 seconds bin, ie 0.2 Hz              \n",
    "    SleepScoredTS_upscaled0 = np.repeat(SleepScoredTS, scale_factor, axis=0)\n",
    "    SleepScoredTS_upscaled0=SleepScoredTS_upscaled0.astype(int)\n",
    "    SleepScoredTS_upscaled=SleepScoredTS_upscaled0.copy()\n",
    "\n",
    "    SleepScoredTS_upscaled[SleepScoredTS_upscaled==2]=1 # Transform QW in AW\n",
    "    SleepScoredTS_upscaled[SleepScoredTS_upscaled==4]=1 # Transform REM in AW\n",
    "    SleepScoredTS_upscaled[SleepScoredTS_upscaled==5]=1 # Transform IS in AW\n",
    "    SleepScoredTS_upscaled[SleepScoredTS_upscaled==6]=1 # Transform undefined in AW\n",
    "\n",
    "    if len(CA1) > len(SleepScoredTS_upscaled):\n",
    "        SleepScoredTS_upscaled = np.pad(SleepScoredTS_upscaled, (0, (len(CA1) - len(SleepScoredTS_upscaled))), constant_values=SleepScoredTS_upscaled[-1])\n",
    "    elif len(CA1) < len(SleepScoredTS_upscaled):\n",
    "        SleepScoredTS_upscaled=SleepScoredTS_upscaled[:len(CA1)]\n",
    "    notNREMBool = SleepScoredTS_upscaled==1 \n",
    "\n",
    "    CA1=zscore(np.array(CA1))#-np.mean(np.array(CA1)))#/np.mean(np.array(CA1))\n",
    "    S1=zscore(np.array(S1))#-np.mean(np.array(S1)))#/np.mean(np.array(S1))\n",
    "    PFC=zscore(np.array(PFC))#-np.mean(np.array(PFC)))#/np.mean(np.array(PFC))\n",
    "\n",
    "    CA1[notNREMBool] = 0\n",
    "    S1[notNREMBool] = 0\n",
    "    PFC[notNREMBool] = 0\n",
    "    \n",
    "    ###########################################\n",
    "            # SWR in CA1: 120-200 Hz #\n",
    "    ###########################################\n",
    "\n",
    "    lfp = nap.Tsd(t=np.arange(len(CA1))/samplerate, d=CA1)\n",
    "    freqs = np.geomspace(3, 200, 100)\n",
    "    mwt_RUN = nap.compute_wavelet_transform(lfp, fs=samplerate, freqs=freqs, gaussian_width=4, window_length=1)\n",
    "    ripple_freq_index = np.logical_and(freqs > 120, freqs < 200)\n",
    "    ripple_power = np.mean(np.abs(mwt_RUN[:, ripple_freq_index]), 1)\n",
    "    smoothed_ripple_power = ripple_power.smooth(0.010) #in seconds 0.005 \n",
    "    threshold_ripple_power = smoothed_ripple_power.threshold(.1)\n",
    "    rip_ep = threshold_ripple_power.time_support\n",
    "    rip_ep['dur_ms']=np.round((rip_ep['end']-rip_ep['start'])*1000)\n",
    "    #rip_ep=rip_ep[rip_ep['dur_ms']>50]\n",
    "\n",
    "    emp=[]\n",
    "    All_SWR = pd.DataFrame(emp, columns = ['start time', 'end time', 'Duration'])\n",
    "    All_SWR['start time']=rip_ep['start']*1000\n",
    "    All_SWR['end time']=rip_ep['end']*1000\n",
    "    All_SWR['Duration']=rip_ep['dur_ms']\n",
    "    All_SWR['toKeep']= 'True'\n",
    "\n",
    "    # Store the results in All_SWR_prop pd dataframe and save as pkl/csv for post processing.\n",
    "    filename = folder_base / f'SWR_detection.csv'\n",
    "    All_SWR.to_csv(filename)\n",
    "\n",
    "    print(len(All_SWR), 'SWR detected in CA1')\n",
    "\n",
    "    ########################################\n",
    "                # Spdl: 9-18 Hz #\n",
    "    ########################################\n",
    "    \n",
    "    #####################################\n",
    "        ##         PFC         ##\n",
    "\n",
    "    lfp = nap.Tsd(t=np.arange(len(PFC))/samplerate, d=PFC)\n",
    "    freqs = np.geomspace(3, 200, 100)\n",
    "    mwt_RUN = nap.compute_wavelet_transform(lfp, fs=samplerate, freqs=freqs, gaussian_width=3, window_length=1.5)\n",
    "    spdl_freq_index = np.logical_and(freqs > 11, freqs < 17)\n",
    "    spdl_power = np.mean(np.abs(mwt_RUN[:, spdl_freq_index]), 1)\n",
    "    smoothed_spdl_power = spdl_power.smooth(0.1) #in seconds 0.005 \n",
    "    threshold_spdl_power = smoothed_spdl_power.threshold(.4)\n",
    "    spdl_ep = threshold_spdl_power.time_support\n",
    "    spdl_ep['dur_ms']=np.round((spdl_ep['end']-spdl_ep['start'])*1000)\n",
    "    #spdl_ep=spdl_ep[spdl_ep['dur_ms']>500]\n",
    "\n",
    "    emp=[]\n",
    "    All_SpindlePFC = pd.DataFrame(emp, columns = ['start time', 'end time', 'Duration'])\n",
    "    All_SpindlePFC['start time']=spdl_ep['start']*1000\n",
    "    All_SpindlePFC['end time']=spdl_ep['end']*1000\n",
    "    All_SpindlePFC['Duration']=spdl_ep['dur_ms']\n",
    "    All_SpindlePFC['toKeep']= 'True'\n",
    "\n",
    "    filename = folder_base / f'SpindlesPFC_detection.csv'\n",
    "    All_SpindlePFC.to_csv(filename)\n",
    "\n",
    "    print(len(All_SpindlePFC), 'Spdl detected in PFC')\n",
    "\n",
    "    #####################################\n",
    "            ##         S1         ##\n",
    "\n",
    "    lfp = nap.Tsd(t=np.arange(len(S1))/samplerate, d=S1)\n",
    "    freqs = np.geomspace(3, 200, 100)\n",
    "    mwt_RUN = nap.compute_wavelet_transform(lfp, fs=samplerate, freqs=freqs, gaussian_width=3, window_length=1.5)\n",
    "    spdl_freq_index1 = np.logical_and(freqs > 11, freqs < 17)\n",
    "    spdl_power1 = np.mean(np.abs(mwt_RUN[:, spdl_freq_index1]), 1)\n",
    "    smoothed_spdl_power1 = spdl_power1.smooth(0.1) #in seconds 0.005 \n",
    "    threshold_spdl_power1 = smoothed_spdl_power1.threshold(.4)\n",
    "    spdl_ep1 = threshold_spdl_power1.time_support\n",
    "    spdl_ep1['dur_ms']=np.round((spdl_ep1['end']-spdl_ep1['start'])*1000)\n",
    "    #spdl_ep=spdl_ep[spdl_ep['dur_ms']>500]\n",
    "\n",
    "    emp=[]\n",
    "    All_SpindleS1 = pd.DataFrame(emp, columns = ['start time', 'end time', 'Duration'])\n",
    "    All_SpindleS1['start time']=spdl_ep1['start']*1000\n",
    "    All_SpindleS1['end time']=spdl_ep1['end']*1000\n",
    "    All_SpindleS1['Duration']=spdl_ep1['dur_ms']\n",
    "    All_SpindleS1['toKeep']= 'True'\n",
    "\n",
    "    filename = folder_base / f'SpindlesS1_detection.csv'\n",
    "    All_SpindleS1.to_csv(filename)\n",
    "    \n",
    "    print(len(All_SpindleS1), 'Spdl detected in S1')\n",
    "\n",
    "\n",
    "    ########################################\n",
    "                # Merge Spdl #\n",
    "    ########################################\n",
    "    \n",
    "    All_SpindlePFC['CTX']='PFC'\n",
    "    All_SpindlePFC['StartingLoc']='PFC'\n",
    "    All_SpindlePFC = All_SpindlePFC.reset_index(drop=True)\n",
    "    NewPFClist=restriction_parameter(All_SpindlePFC)\n",
    "\n",
    "    All_SpindleS1['CTX']='S1'\n",
    "    All_SpindleS1['StartingLoc']='S1'\n",
    "    All_SpindleS1 = All_SpindleS1.reset_index(drop=True)\n",
    "    NewS1list=restriction_parameter(All_SpindleS1)\n",
    "\n",
    "    #Spdllist=pd.concat([All_SpindlePFC,All_SpindleS1],ignore_index=False)  \n",
    "    Spdllist=pd.concat([NewPFClist,NewS1list],ignore_index=False)  \n",
    "\n",
    "    Spdllist['LocalGlobal']='Local'\n",
    "    Spdllist['DistanceClosestSpdl']=np.inf\n",
    "\n",
    "    Spdllist = Spdllist.sort_values(by='start time')\n",
    "    Spdllist = Spdllist.reset_index(drop=True)\n",
    "\n",
    "    liststarts=Spdllist[\"start time\"]\n",
    "    listends=Spdllist[\"end time\"]\n",
    "    NewSpdllist=Spdllist.copy()\n",
    "\n",
    "    for spdl1 in NewSpdllist.index : # range(len(Spdllist)) :\n",
    "        start1=liststarts[spdl1]\n",
    "        end1=listends[spdl1]\n",
    "        otherunit_range = [x for x in NewSpdllist.index  if x != spdl1]\n",
    "        #print(f'spdl1 n°{spdl1}')\n",
    "        if NewSpdllist.loc[spdl1,'toKeep'] != 'False':\n",
    "            for spdl2 in otherunit_range:\n",
    "                if NewSpdllist.loc[spdl2,'toKeep'] != 'False':\n",
    "                    start2=liststarts[spdl2]\n",
    "                    end2=listends[spdl2]\n",
    "                    if NewSpdllist.loc[spdl1,'CTX']!= NewSpdllist.loc[spdl2,'CTX']: # Needs to be from 2 differents brain areas\n",
    "\n",
    "                        if start2>start1:\n",
    "                            NewSpdllist.loc[spdl1, 'DistanceClosestSpdl'] = start1-start2 if start2-start1<NewSpdllist.loc[spdl1, 'DistanceClosestSpdl'] else NewSpdllist.loc[spdl1, 'DistanceClosestSpdl']\n",
    "                            NewSpdllist.loc[spdl2, 'DistanceClosestSpdl'] = start2-start1 if start2-start1<NewSpdllist.loc[spdl2, 'DistanceClosestSpdl'] else NewSpdllist.loc[spdl2, 'DistanceClosestSpdl']\n",
    "                        else:\n",
    "                            NewSpdllist.loc[spdl1, 'DistanceClosestSpdl'] = start1-start2 if start1-start2<NewSpdllist.loc[spdl1, 'DistanceClosestSpdl'] else NewSpdllist.loc[spdl1, 'DistanceClosestSpdl']\n",
    "                            NewSpdllist.loc[spdl2, 'DistanceClosestSpdl'] = start2-start1 if start1-start2<NewSpdllist.loc[spdl2, 'DistanceClosestSpdl'] else NewSpdllist.loc[spdl2, 'DistanceClosestSpdl']\n",
    "\n",
    "                        if start1<=start2 and start2<=end1: # event n°2 begins after the start n°1               \n",
    "                            if (end1-start2)>=int(0.5*(end1-start1)): # overlapp > to 50% of the duration of the event n°1                                \n",
    "                                NewSpdllist.loc[spdl1, 'LocalGlobal']='Global'\n",
    "                                NewSpdllist.loc[spdl1, 'StartingLoc']=NewSpdllist.loc[spdl1,'CTX']\n",
    "                                NewSpdllist.loc[spdl1, 'CTX']='S1PFC'\n",
    "                                NewSpdllist.loc[spdl1, 'start time']=int((start1 + start2)/2)\n",
    "                                NewSpdllist.loc[spdl1, 'end time']=max(end1, end2)\n",
    "                                NewSpdllist.loc[spdl1, 'Duration']=max(end1, end2)-int((start1 + start2)/2)\n",
    "                                NewSpdllist.loc[spdl2, 'toKeep']='False'\n",
    "                                #print(f'Cdt n°1: Global, keep spdl n°{spdl1} {start1} instead of spdl n°{spdl2} {start2}')\n",
    "                                break\n",
    "                        elif start1<=end2 and end2<=end1: # event n°2 ends before the end n°1 \n",
    "                            if (end2-start1)>=int(0.5*(end1-start1)): # overlapp > to 50% of the duration of the event n°1\n",
    "                                NewSpdllist.loc[spdl2, 'LocalGlobal']='Global'\n",
    "                                NewSpdllist.loc[spdl2, 'StartingLoc']=NewSpdllist.loc[spdl2,'CTX']\n",
    "                                NewSpdllist.loc[spdl2, 'CTX']='S1PFC'\n",
    "                                NewSpdllist.loc[spdl2, 'start time']=int((start1 + start2)/2)\n",
    "                                NewSpdllist.loc[spdl2, 'end time']=max(end1, end2)\n",
    "                                NewSpdllist.loc[spdl2, 'Duration']=max(end1, end2)-int((start1 + start2)/2)\n",
    "                                NewSpdllist.loc[spdl1, 'toKeep']='False'\n",
    "                                #print(f'Cdt n°2: Global, keep spdl n°{spdl2} {start2}, instead of spdl n°{spdl1} {start1}')\n",
    "                                break\n",
    "    NewSpdllist = NewSpdllist[NewSpdllist['toKeep'].isin(['True', 'VRAI'])]\n",
    "    NewSpdllist = NewSpdllist.sort_values(by='start time')\n",
    "    NewSpdllist = NewSpdllist.reset_index(drop=True)\n",
    "    NewSpdllist['DistanceClosestSpdl'] = NewSpdllist['DistanceClosestSpdl'] *-1 # to have in positive the spdl that arrives after the onset and vice versa\n",
    "    NewSpdllist=restriction_parameter(NewSpdllist)\n",
    "\n",
    "    filenameOutput = folder_base / f'SpindlesS1&PFC_detection.csv' \n",
    "    NewSpdllist.to_csv(filenameOutput, sep= ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092da31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rip_ep=rip_ep[rip_ep['dur_ms']>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923f9620",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(15, 5))\n",
    "gs = plt.GridSpec(2, 1, figure=fig, height_ratios=[1.0, 0.5])\n",
    "ax0 = plt.subplot(gs[0, 0])\n",
    "ax0.plot(CA1, label=\"CA1\")\n",
    "for i, (s, e) in enumerate(rip_ep.values):\n",
    "    ax0.axvspan(s, e, color='k', alpha=0.2, ec=None)\n",
    "ax0.set_ylabel(\"LFP (a.u.)\")\n",
    "ax1 = plt.subplot(gs[1, 0])\n",
    "ax1.legend()\n",
    "ax1.plot(ripple_power, label=\"150-250 Hz\")\n",
    "ax1.plot(smoothed_ripple_power)\n",
    "for i, (s, e) in enumerate(rip_ep.values):\n",
    "    ax1.axvspan(s, e, color='k', alpha=0.2, ec=None)\n",
    "ax1.legend()\n",
    "ax1.set_ylabel(\"Mean Amplitude\")\n",
    "ax1.set_xlabel(\"Time (s)\")\n",
    "\n",
    "t1=421.4\n",
    "t2=t1+.1\n",
    "ax0.set_xlim([t1*samplerate,t2*samplerate])\n",
    "ax1.set_xlim([t1,t2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebef7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(15, 5))\n",
    "gs = plt.GridSpec(2, 1, figure=fig, height_ratios=[1.0, 0.5])\n",
    "ax0 = plt.subplot(gs[0, 0])\n",
    "ax0.plot(S1, label=\"S1\")\n",
    "for i, (s, e) in enumerate(spdl_ep1.values):\n",
    "    ax0.axvspan(s, e, color='k', alpha=0.2, ec=None)\n",
    "ax0.set_ylabel(\"LFP (a.u.)\")\n",
    "ax1 = plt.subplot(gs[1, 0])\n",
    "ax1.legend()\n",
    "ax1.plot(spdl_power1-np.mean(spdl_power1), label=\"11-17 Hz\")\n",
    "ax1.plot(threshold_spdl_power1)\n",
    "for i, (s, e) in enumerate(spdl_ep1.values):\n",
    "    ax1.axvspan(s, e, color='k', alpha=0.2, ec=None)\n",
    "ax1.legend()\n",
    "ax1.set_ylabel(\"Mean Amplitude\")\n",
    "ax1.set_xlabel(\"Time (s)\")\n",
    "\n",
    "t1=1140\n",
    "t2=t1+15\n",
    "ax0.set_xlim([t1*samplerate,t2*samplerate])\n",
    "ax1.set_xlim([t1,t2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28ab76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(15, 5))\n",
    "gs = plt.GridSpec(2, 1, figure=fig, height_ratios=[1.0, 0.5])\n",
    "ax0 = plt.subplot(gs[0, 0])\n",
    "ax0.plot(PFC, label=\"PFC\")\n",
    "for i, (s, e) in enumerate(spdl_ep.values):\n",
    "    ax0.axvspan(s, e, color='k', alpha=0.2, ec=None)\n",
    "ax0.set_ylabel(\"LFP (a.u.)\")\n",
    "ax1 = plt.subplot(gs[1, 0])\n",
    "ax1.legend()\n",
    "ax1.plot(spdl_power, label=\"11-17 Hz\")\n",
    "ax1.plot(threshold_spdl_power)\n",
    "for i, (s, e) in enumerate(spdl_ep.values):\n",
    "    ax1.axvspan(s, e, color='k', alpha=0.2, ec=None)\n",
    "ax1.legend()\n",
    "ax1.set_ylabel(\"Mean Amplitude\")\n",
    "ax1.set_xlabel(\"Time (s)\")\n",
    "\n",
    "t1=80\n",
    "t2=t1+20\n",
    "ax0.set_xlim([t1*samplerate,t2*samplerate])\n",
    "ax1.set_xlim([t1,t2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pynapple",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
