{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc13b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder used for minian procedures is : c:\\Users\\Manip2\\SCRIPTS\\CodePythonAudrey\\CodePythonAurelie\\HayLabAnalysis\\minian\n",
      "####################################################################################\n",
      "################################### BlueLines ####################################\n",
      "####################################################################################\n",
      "session2_1 : starts at 13.1 s & ends at 772.2 s ( 759.1 s duration,  0 dropped frames, minian frequency = 20 Hz, experiment type =  baseline )...\n",
      "... kept values = ['[88]', '[8]', '[91]', '[9]', '[10]', '[12]', '[6]', '[94]', '[99]', '[0]']\n",
      "... Loading time = 1.45 seconds\n",
      "... 0 Spdl processed in 0.00 & PSTH done in 0.00 seconds for one cell\n",
      "... 491 SWR processed in 0.43 seconds & PSTH done in 0.02 seconds for one cell\n",
      "... The 10 units of session2_1 analyzed in 4.52 seconds\n",
      "... 0 spindles (0 Coupled & 0 Uncoupled Spdl // 0 Global, 0 LocalS1 & 0 LocalPFC) and 491 SWR detected (0 Coupled & 127 Uncoupled SWR)\n",
      "session2_2 : starts at 772.2 s & ends at 1092.2 s ( 320.0 s duration,  0 dropped frames, minian frequency = 20 Hz, experiment type =  baseline )...\n",
      "... kept values = ['[26]', '[33]', '[111]', '[112]', '[113]', '[8]', '[108]', '[9]', '[109]', '[110]', '[10]', '[12]', '[6]', '[103]', '[2]', '[0]']\n",
      "... Loading time = 1.76 seconds\n"
     ]
    }
   ],
   "source": [
    "# # Associate Ca2+ signal with spindles for each session & subsessions using crossregistration\n",
    "\n",
    "#######################################################################################\n",
    "                            # Define Experiment type #\n",
    "#######################################################################################\n",
    "\n",
    "DrugExperiment=0 # 0 if Baseline Experiment / 1 if CGP Experiment\n",
    "\n",
    "saveexcel=1\n",
    "\n",
    "AHmethod=0 # 0 if using the method of Aurelie Hay (2025) / 1 if using the method of Audrey Hay (2025)\n",
    "\n",
    "AnalysisID='_likeAH' if AHmethod else '_pynapple' # '_pynapple' if using the method of Aurelie Hay (2025) / '_minian' if using the method of Audrey Hay (2025)\n",
    "suffix=''\n",
    "\n",
    "CTX=['S1', 'PFC', 'S1PFC']\n",
    "Coupling=['', 'UnCoupled', 'Coupled']\n",
    "\n",
    "dir = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/L1NDNF_mice/BlueLines/\"\n",
    "\n",
    "before = 500 # Max distance in ms between a SWR and a spindle to be considered as Precoupled\n",
    "after = 1000 # Max distance in ms between a spindle and a SWR to be considered as Postcoupled\n",
    "durationSpdl = 1 # number of sec before and after the Spdl onset taken into acount\n",
    "durationSWR = 1 # number of sec before and after the SWR onset taken into acount\n",
    "\n",
    "drugs=['baseline', 'CGP'] if DrugExperiment else ['baseline']\n",
    "\n",
    "#######################################################################################\n",
    "                                # Load packages #\n",
    "#######################################################################################\n",
    "\n",
    "import os\n",
    "import quantities as pq\n",
    "import numpy as np\n",
    "import math \n",
    "import neo\n",
    "import json\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "from scipy.interpolate import interp2d\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import zscore\n",
    "import pickle\n",
    "import os\n",
    "from scipy.interpolate import griddata\n",
    "import logging\n",
    "import sys \n",
    "import shutil\n",
    "from bisect import bisect_left\n",
    "from ast import literal_eval\n",
    "from scipy import interpolate\n",
    "import time\n",
    "\n",
    "from itertools import groupby\n",
    "from ephyviewer import mkQApp, MainViewer, TraceViewer\n",
    "from IPython.display import display\n",
    "from ipyfilechooser import FileChooser\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "minian_path = os.path.join(os.path.abspath('.'),'minian')\n",
    "print(\"The folder used for minian procedures is : {}\".format(minian_path))\n",
    "sys.path.append(minian_path)\n",
    "\n",
    "\n",
    "from minian.utilities import (\n",
    "    TaskAnnotation,\n",
    "    get_optimal_chk,\n",
    "    load_videos,\n",
    "    open_minian,\n",
    "    save_minian,\n",
    ")\n",
    "\n",
    "#######################################################################################\n",
    "                                # Define functions #\n",
    "#######################################################################################\n",
    "\n",
    "def is_between(myList, starttime, endtime):\n",
    "    IsTrue=False\n",
    "    for ind in range(len(myList)):\n",
    "        if starttime <= myList[ind] <= endtime:\n",
    "            IsTrue=True\n",
    "    return IsTrue\n",
    "\n",
    "def is_overlapping(starttime, endtime, starttimeList, endtimeList):\n",
    "    IsTrue='False'\n",
    "    for ind in starttimeList.index: #range(len(starttimeList)):\n",
    "        if starttime<=starttimeList[ind] and starttimeList[ind]<=endtime: # event n°2 begins after the start n°1               \n",
    "            if (endtime-starttimeList[ind])>=int(0.5*(endtime-starttime)): # overlapp > to 50% of the duration of the event n°1\n",
    "                IsTrue='True'\n",
    "                break                \n",
    "        elif starttime<=endtimeList[ind] and endtimeList[ind]<=endtime: # event n°2 ends before the end n°1 \n",
    "            if (endtimeList[ind]-starttime)>=int(0.5*(endtime-starttime)): # overlapp > to 50% of the duration of the event n°1\n",
    "                IsTrue='True'\n",
    "                break\n",
    "    return IsTrue, ind\n",
    "\n",
    "def find_session_folders(root_path):\n",
    "    sessions = []\n",
    "    sessions_path=[]\n",
    "    # Iterate through items in the root_path\n",
    "    for item in os.listdir(root_path):\n",
    "        item_path = os.path.join(root_path, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            # Check if the directory name contains \"session\"\n",
    "            if \"session\" in item:\n",
    "                sessions.append(item)\n",
    "                sessions_path.append(item_path)\n",
    "            else:\n",
    "                # Check the subdirectories of the current directory\n",
    "                for sub_item in os.listdir(item_path):\n",
    "                    sub_item_path = os.path.join(item_path, sub_item)\n",
    "                    if os.path.isdir(sub_item_path) and \"session\" in sub_item:\n",
    "                        sessions.append(sub_item)\n",
    "                        sessions_path.append(sub_item_path)\n",
    "                        \n",
    "    return sessions, sessions_path\n",
    "\n",
    "#######################################################################################\n",
    "                # Load sleep score and Ca2+ time series numpy arrays #\n",
    "#######################################################################################\n",
    "\n",
    "all_expe_types=['baseline', 'preCGP', 'postCGP'] if DrugExperiment else ['baseline', 'preCGP']\n",
    "\n",
    "# Get the current date and time\n",
    "FolderNameSave=str(datetime.now())[:19]\n",
    "FolderNameSave = FolderNameSave.replace(\" \", \"_\").replace(\".\", \"_\").replace(\":\", \"_\")\n",
    "\n",
    "destination_folder= f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_CGP_analysis/Osc_{FolderNameSave}{suffix}{AnalysisID}\" if DrugExperiment else f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/Analysed2025_AB/_baseline_analysis/Osc_{FolderNameSave}{suffix}{AnalysisID}\"\n",
    "os.makedirs(destination_folder)\n",
    "folder_to_save=Path(destination_folder)\n",
    "\n",
    "# Copy the script file to the destination folder\n",
    "source_script = \"C:/Users/Manip2/SCRIPTS/CodePythonAudrey/CodePythonAurelie/HayLabAnalysis/python/_MINI&OE_6_compute_osc_activity.py\"\n",
    "destination_file_path = f\"{destination_folder}/_MINI&OE_6_compute_osc_activity.txt\"\n",
    "shutil.copy(source_script, destination_file_path)\n",
    "\n",
    "data = {}        \n",
    "counter=0\n",
    "counter2=0\n",
    "\n",
    "norm_freq=20 # final miniscope frequency used for all recordings\n",
    "\n",
    "Spindles_GlobalResults= pd.DataFrame(data, columns=['Mice', 'NeuronType','Session','Session_Date', 'Session_Time','Unique_Unit','UnitNumber','UnitValue','ExpeType','Drug', 'SpdlStatut','SpdlStartLocation',\n",
    "                                                        'GlobalSpindle', 'SpdlNumber','SpdlDuration','SWR_inside_Spdl','DistanceSWR_Spdl','DistanceClosestSpdl','CalciumActivityPreference', 'CalciumActivityBefore',\n",
    "                                                        'CalciumActivityDuring','CalciumActivityAfter', 'AUC_calciumBaseline','AUC_calciumBefore','AUC_calciumDuring','AUC_calciumAfter',\n",
    "                                                        'SpikeActivityPreference','SpikeActivityBefore','SpikeActivityDuring','SpikeActivityAfter'])\n",
    "SWR_GlobalResults= pd.DataFrame(data, columns=['Mice', 'NeuronType','Session','Session_Date','Session_Time','Unique_Unit','UnitNumber','UnitValue','ExpeType','Drug','SWRStatut','SpdlLoc', 'SWRNumber','SWRDuration',\n",
    "                                                'SWR_inside_Spdl','DistanceSWR_Spdl','CalciumActivityPreference', 'CalciumActivityBefore','CalciumActivityDuring','CalciumActivityAfter',\n",
    "                                                'AUC_calciumBaseline','AUC_calciumBefore','AUC_calciumDuring','AUC_calciumAfter','SpikeActivityPreference','SpikeActivityBefore','SpikeActivityDuring','SpikeActivityAfter'])\n",
    "\n",
    "for dpath in Path(dir).glob('**/mappingsAB.pkl'):\n",
    "    \n",
    "    mappfile = open(dpath.parents[0]/ f'mappingsAB.pkl', 'rb')\n",
    "    mapping = pickle.load(mappfile)\n",
    "    mapping_sess = mapping['session']   \n",
    "        \n",
    "    centfile = open(dpath.parents[0]/ f'centsAB.pkl', 'rb')\n",
    "    centroids = pickle.load(centfile) \n",
    "\n",
    "    mice = dpath.parents[0].parts[-1]\n",
    "    NeuronType = dpath.parents[1].parts[-1]\n",
    "    \n",
    "    print(f\"####################################################################################\")\n",
    "    print(f\"################################### {mice} ####################################\")\n",
    "    print(f\"####################################################################################\")\n",
    "\n",
    "    nb_minian_total=0\n",
    "\n",
    "    subsessions = []\n",
    "    dict_Calcium = {}\n",
    "    dict_Deconv = {}\n",
    "    dict_SWRprop = {}\n",
    "    dict_DSprop={}\n",
    "    dict_Spindleprop = {}\n",
    "    dict_Stamps = {}\n",
    "    dict_StampsMiniscope = {}\n",
    "    dict_TodropFile = {}\n",
    "    dict_Path={}\n",
    "    dict_Scoring = {}\n",
    "\n",
    "    for drug in drugs: \n",
    "        for coup in Coupling:\n",
    "            for ctx in CTX:            \n",
    "                locals()[f'dict_All_ActivityCa_{coup}SPDL{ctx}_{drug}']={}\n",
    "                locals()[f'dict_All_ActivitySp_{coup}SPDL{ctx}_{drug}']={}\n",
    "                if coup=='Coupled':\n",
    "                    locals()[f'dict_All_ActivityCa_{coup}SWR{ctx}_{drug}']={}\n",
    "                    locals()[f'dict_All_ActivitySp_{coup}SWR{ctx}_{drug}']={}\n",
    "                else: \n",
    "                    locals()[f'dict_All_ActivityCa_{coup}SWR_{drug}']={}\n",
    "                    locals()[f'dict_All_ActivitySp_{coup}SWR_{drug}']={}\n",
    "    \n",
    "\n",
    "    previousEndTime=0\n",
    "    InitialStartTime=0\n",
    "\n",
    "\n",
    "    minian_folders = [f for f in dpath.parents[0].rglob('minian') if f.is_dir()]\n",
    "\n",
    "    for minianpath in minian_folders: # for each minian folders found in this mouse\n",
    "\n",
    "        if any(p in all_expe_types for p in minianpath.parts): # have to be to the expe_types\n",
    "\n",
    "            start = time.time()\n",
    "\n",
    "            cCoupled=0\n",
    "            cUnCoupled=0\n",
    "            cGlobal=0\n",
    "            cLocalS1=0\n",
    "            cLocalPFC=0\n",
    "\n",
    "            cCoupledSWR=0\n",
    "            cUnCoupledSWR=0   \n",
    "            \n",
    "            session=minianpath.parents[0].name if len(minianpath.parts)==12 else minianpath.parents[1].name.split(\"_\")[-1]\n",
    "            session_path=minianpath.parents[2] if len(minianpath.parts)==12 else minianpath.parents[1]\n",
    "            expe_type=minianpath.parents[3].name if len(minianpath.parts)==12 else minianpath.parents[2].name\n",
    "\n",
    "            session_date= minianpath.parents[2].name.split(\"_\")[0] if len(minianpath.parts)==12 else minianpath.parents[1].name.split(\"_\")[0]\n",
    "            session_time= minianpath.parents[2].name.split(\"_\")[1] if len(minianpath.parts)==12 else minianpath.parents[1].name.split(\"_\")[1]\n",
    "\n",
    "            drug='CGP' if expe_type == 'postCGP' else 'baseline'\n",
    "            dict_Path[session] = session_path\n",
    "        \n",
    "            minian_ds = open_minian(minianpath)\n",
    "            dict_Calcium[session] = minian_ds['C'] # calcium traces \n",
    "            dict_Deconv[session] = minian_ds['S'] # estimated spikes deconvolved activity\n",
    "\n",
    "            dict_Scoring[session]  = pd.read_csv(session_path/ f'OpenEphys/Sleep_Scoring_6Stages_5sEpoch.csv')\n",
    "            dict_Stamps[session]  = pd.read_excel(session_path/ f'SynchroFileCorrect.xlsx')\n",
    "            dict_StampsMiniscope[session]  = pd.read_csv(list(session_path.glob('*V4_Miniscope/timeStamps.csv'))[0])\n",
    "\n",
    "            with open(minianpath / f'TodropFileAB.json', 'r') as f:\n",
    "                unit_to_drop = json.load(f)\n",
    "                dict_TodropFile[session]  = unit_to_drop\n",
    "\n",
    "\n",
    "            SWRlist= pd.read_csv(session_path / f'OpenEphys/SWRproperties.csv' ) if AHmethod else pd.read_csv(session_path / f'OpenEphys/SWR_detection.csv' ) \n",
    "            SWRlist['toKeep'] = 'True' # SWRlist['toKeep'].astype(str)\n",
    "            dict_SWRprop[session]  =SWRlist[SWRlist['toKeep'].isin(['VRAI', 'True'])]\n",
    "\n",
    "            Spdllist = pd.read_csv(session_path / f'OpenEphys/Spindleproperties_S1&PFC.csv') if AHmethod else pd.read_csv(session_path / f'OpenEphys/SpindlesS1&PFC_detection.csv' ) \n",
    "            Spdllist['toKeep'] = 'True' # Spdllist['toKeep'].astype(str)\n",
    "            dict_Spindleprop[session]  = Spdllist[Spdllist['toKeep'].isin(['VRAI', 'True'])]\n",
    "\n",
    "            nb_minian_total+=1\n",
    "\n",
    "            #######################################################################################\n",
    "            # Distribute Ca2+ intensity & spikes to oscillations for each sessions/subsessions #\n",
    "            #######################################################################################\n",
    "\n",
    "            # Start time & freq miniscope\n",
    "\n",
    "            StartTime = list(dict_Stamps[session][0])[0] # in seconds\n",
    "            StartTimeO = StartTime\n",
    "            minian_freq=list(dict_Stamps[session][0])[2] # in Hz\n",
    "            TimeStamps_miniscope=dict_StampsMiniscope[session]\n",
    "            TimeStamps_miniscope[\"Time Stamp (ms)\"]=TimeStamps_miniscope[\"Time Stamp (ms)\"] + (StartTimeO*1000)\n",
    "\n",
    "            minian_freq=round(1/np.mean(np.diff(np.array(TimeStamps_miniscope[\"Time Stamp (ms)\"])/1000)))\n",
    "\n",
    "            freqLFP=1000\n",
    "\n",
    "            if minian_freq>=20: # should only remove 1 session                \n",
    "\n",
    "                # Adjust the StartTime if subsessions\n",
    "\n",
    "                if InitialStartTime==0:\n",
    "                    InitialStartTime=StartTime    \n",
    "                    firstframe=0\n",
    "                    StartTimeMiniscope=0 # start time of miniscope rec of that subsesssions relative to the start of the mniscope recording\n",
    "                else:\n",
    "                    if StartTime == InitialStartTime: # just a subsession\n",
    "                        StartTime = previousEndTime + 1/minian_freq #  +1 frame in seconds\n",
    "                        StartTimeMiniscope= StartTime-InitialStartTime\n",
    "                    else:  \n",
    "                        InitialStartTime=StartTime # this is a new session\n",
    "                        firstframe=0\n",
    "                        StartTimeMiniscope=0   \n",
    "\n",
    "\n",
    "                # Remove bad units from recordings\n",
    "\n",
    "                C=dict_Calcium[session]\n",
    "                D=dict_Deconv[session] \n",
    "                unit_to_drop=dict_TodropFile[session]    \n",
    "\n",
    "                C_sel=C.drop_sel(unit_id=unit_to_drop)\n",
    "                D_sel=D.drop_sel(unit_id=unit_to_drop)\n",
    "\n",
    "                Calcium = pd.DataFrame(C_sel, index=C_sel['unit_id'])\n",
    "                Deconv = pd.DataFrame(D_sel, index=D_sel['unit_id'])\n",
    "\n",
    "                indexMappList=mapping_sess[session]\n",
    "                kept_uniq_unit_List=[]\n",
    "                for unit in Calcium.index:\n",
    "                    indexMapp = np.where(indexMappList == unit)[0]\n",
    "                    kept_uniq_unit_List.append(str(indexMapp))\n",
    "\n",
    "                nb_unit=len(Calcium)\n",
    "                if nb_unit==0:\n",
    "                    continue  # next iteration\n",
    "                \n",
    "                \n",
    "                Carray=Calcium.values.T.astype(float)\n",
    "                Darray=Deconv.values.T.astype(float)\n",
    "\n",
    "                StartFrame_msec=TimeStamps_miniscope['Time Stamp (ms)'][TimeStamps_miniscope['Frame Number'][firstframe]]\n",
    "                LastFrame_msec=TimeStamps_miniscope['Time Stamp (ms)'][TimeStamps_miniscope['Frame Number'][firstframe+len(Calcium.T)-1]]\n",
    "                TS_miniscope_sub=TimeStamps_miniscope['Time Stamp (ms)'].iloc[firstframe:firstframe+len(Calcium.T)]\n",
    "                rec_dur=len(Calcium.T)\n",
    "\n",
    "                rec_dur_sec= (LastFrame_msec - StartFrame_msec)/1000\n",
    "                \n",
    "                nb_of_previousframe=firstframe\n",
    "\n",
    "\n",
    "                # Deal with dropped frames (failure to acquire miniscope images)\n",
    "\n",
    "                list_droppedframes = literal_eval(dict_Stamps[session][0][3])    \n",
    "                numbdropfr= 0   \n",
    "                droppedframes_inrec=[]\n",
    "                for item in list_droppedframes: \n",
    "                    if item < (round(StartTimeMiniscope*minian_freq) + rec_dur_sec) and item > round(StartTimeMiniscope*minian_freq):\n",
    "                        numbdropfr+=1                        \n",
    "\n",
    "                EndTime = StartTime + rec_dur_sec # (upd_rec_dur/minian_freq) # in seconds\n",
    "                previousEndTime=EndTime \n",
    "\n",
    "                print(session, ': starts at', round(StartTime,1), 's & ends at', round(EndTime,1), 's (', round(rec_dur_sec,1), 's duration, ', numbdropfr, 'dropped frames, minian frequency =', minian_freq, 'Hz, experiment type = ', expe_type, ')...') \n",
    "                sentence1= f\"... kept values = {kept_uniq_unit_List}\"\n",
    "                print(sentence1)\n",
    "\n",
    "                # Align Oscillations to miniscope start \n",
    "\n",
    "                SpipropO=dict_Spindleprop[session]\n",
    "                SpipropM=SpipropO.copy()\n",
    "                SWRpropO=dict_SWRprop[session]\n",
    "                SWRpropM=SWRpropO.copy()\n",
    "\n",
    "                SpipropM=SpipropM[SpipropM['start time']> StartFrame_msec]\n",
    "                SpipropTrunc=SpipropM[SpipropM['end time']< LastFrame_msec]\n",
    "                SWRpropM=SWRpropM[SWRpropM['start time']> StartFrame_msec]\n",
    "                SWRpropTrunc=SWRpropM[SWRpropM['end time']< LastFrame_msec]\n",
    "\n",
    "                HalfSpdl = round(durationSpdl*minian_freq)\n",
    "                HalfSWR = round(durationSWR*minian_freq)\n",
    "\n",
    "                nb_spindle = SpipropTrunc.shape[0]\n",
    "                nb_swr = SWRpropTrunc.shape[0]\n",
    "\n",
    "                print(f\"... Loading time = {time.time() - start:.2f} seconds\")\n",
    "\n",
    "                start2 = time.time()\n",
    "\n",
    "                unit_count=0\n",
    "                for unit in range(nb_unit): # for each kept units (cause Cseries/Sseries only have kept units)\n",
    "                    \n",
    "                    indexMapp = np.where(mapping_sess[session] == Calcium.index[unit])[0]\n",
    "                    \n",
    "                    if len(indexMapp)>0 : # The neuron needs to be in the cross-registration\n",
    "\n",
    "                        unit_count+=1\n",
    "                        \n",
    "                        Carray_unit =Carray[:,unit]\n",
    "                        Darray_unit =Darray[:,unit]\n",
    "                        peaks, _ = find_peaks(Darray_unit)#, height=np.std(SpTrace))\n",
    "                        Sarray_unit=np.zeros(len(Darray_unit))\n",
    "                        Sarray_unit[peaks]=1\n",
    "\n",
    "                        #######################################################################################\n",
    "                                                            # for SPDLs #\n",
    "                        #######################################################################################\n",
    "                        for coup in Coupling:\n",
    "                            for ctx in CTX:            \n",
    "                                locals()[f'ActivityCa_{coup}Spin{ctx}']=[] #For each unit \n",
    "                                locals()[f'ActivitySp_{coup}Spin{ctx}']=[] #For each unit  \n",
    "\n",
    "                        start3 = time.time()\n",
    "                        prevspin=[]\n",
    "\n",
    "                        for Pspin in SpipropTrunc.index: \n",
    "                            \n",
    "                            # Get the calcium and spike trace associated with the spdl\n",
    "            \n",
    "                            startSpi=SpipropTrunc.loc[Pspin, \"start time\"]                \n",
    "                            endSpi=SpipropTrunc.loc[Pspin, \"end time\"]    \n",
    "                            ctxSpi=SpipropTrunc.loc[Pspin, \"CTX\"]                \n",
    "                            diffSpi=SpipropTrunc.loc[Pspin, \"LocalGlobal\"]                \n",
    "                            StartLocSpi=SpipropTrunc.loc[Pspin, \"StartingLoc\"]   \n",
    "                            closestSpdl=SpipropTrunc.loc[Pspin, \"DistanceClosestSpdl\"]    \n",
    "\n",
    "                            endPreviousSpi=SpipropTrunc.loc[prevspin, \"end time\"] if prevspin else startSpi-durationSpdl*1000 #line and not index cause sometimes, index are not ordered    \n",
    "                            prevspin=Pspin\n",
    "\n",
    "                            if startSpi - endPreviousSpi >= durationSpdl*1000 : # if the spindle is not too close from the end of previous one \n",
    "\n",
    "                                TooEarlySpdl=startSpi-durationSpdl*1000<StartFrame_msec # too close to the begining of the recording\n",
    "                                TooLateSpdl=startSpi+durationSpdl*1000>LastFrame_msec # too close to the end of the recording\n",
    "                                \n",
    "                                if TooEarlySpdl or TooLateSpdl:\n",
    "                                    print(\"... /!\\ Spindle too close to the begining/end of the recording,\", session, \", Spdl n°\", Pspin, \", Start Spdl =\", round(startSpi/1000,1), \"s\") if unit_count==1 else None            \n",
    "                                else:\n",
    "\n",
    "                                    if ctxSpi=='S1':\n",
    "                                        cLocalS1+=1 if unit_count==1 else 0\n",
    "                                    elif ctxSpi=='PFC': \n",
    "                                        cLocalPFC+=1 if unit_count==1 else 0\n",
    "                                    elif ctxSpi=='S1PFC': \n",
    "                                        cGlobal+=1 if unit_count==1 else 0    \n",
    "\n",
    "                                    # Find the index of the closest value in the column\n",
    "                                    Frame_Spindle_start_all = (TS_miniscope_sub - startSpi).abs().idxmin()\n",
    "                                    Frame_Spindle_start=Frame_Spindle_start_all-nb_of_previousframe\n",
    "\n",
    "                                    CaTrace = list(Carray_unit[Frame_Spindle_start-HalfSpdl:Frame_Spindle_start+HalfSpdl])\n",
    "                                    SpTrace = list(Sarray_unit[Frame_Spindle_start-HalfSpdl:Frame_Spindle_start+HalfSpdl]) \n",
    "\n",
    "                                    ActivityCa_Spin=locals()[f'ActivityCa_Spin{ctxSpi}']\n",
    "                                    ActivitySp_Spin=locals()[f'ActivitySp_Spin{ctxSpi}']\n",
    "                                    ActivityCa_Spin.append(CaTrace)\n",
    "                                    ActivitySp_Spin.append(SpTrace)               \n",
    "\n",
    "                                    # Define if that spindle is coupled with a SWR or not\n",
    "\n",
    "                                    Spdl_statut=[]\n",
    "                                    startSWRList = list(pd.Series(SWRpropTrunc[\"start time\"]))\n",
    "                                    delaiSWRSpdl=None\n",
    "                                    if len(startSWRList)>0:\n",
    "                                        startClosest_SWR_idx = (np.abs(startSWRList - startSpi)).argmin()\n",
    "                                        startClosest_SWR = startSWRList[startClosest_SWR_idx]\n",
    "                                        distance = abs(startClosest_SWR - startSpi)\n",
    "                                        IsTrue=is_between(startSWRList,startSpi, endSpi)\n",
    "                                        if (distance < before) or IsTrue:\n",
    "                                            Spdl_statut = 'Coupled'\n",
    "                                            cCoupled+=1 if unit_count==1 else 0   \n",
    "                                            delaiSWRSpdl=startClosest_SWR - startSpi                           \n",
    "                                        else:\n",
    "                                            Spdl_statut= 'UnCoupled'\n",
    "                                            cUnCoupled+=1 if unit_count==1 else 0\n",
    "                                    else:\n",
    "                                        Spdl_statut= 'UnCoupled'\n",
    "                                        cUnCoupled+=1 if unit_count==1 else 0\n",
    "\n",
    "                                    ActivityCa_SpinCp=locals()[f'ActivityCa_{Spdl_statut}Spin{ctxSpi}']\n",
    "                                    ActivitySp_SpinCp=locals()[f'ActivitySp_{Spdl_statut}Spin{ctxSpi}']\n",
    "                                    ActivityCa_SpinCp.append(CaTrace)\n",
    "                                    ActivitySp_SpinCp.append(SpTrace)\n",
    "                                    \n",
    "                                    # Fill the big summary table Spindles_GlobalResults\n",
    "\n",
    "                                    Spindles_GlobalResults.loc[counter, 'Mice'] = mice\n",
    "                                    Spindles_GlobalResults.loc[counter, 'NeuronType'] = NeuronType\n",
    "\n",
    "                                    Spindles_GlobalResults.loc[counter, 'Session'] = session\n",
    "                                    Spindles_GlobalResults.loc[counter, 'Session_Date'] = session_date \n",
    "                                    Spindles_GlobalResults.loc[counter, 'Session_Time'] = session_time                    \n",
    "\n",
    "                                    Spindles_GlobalResults.loc[counter, 'Unique_Unit'] = indexMapp \n",
    "                                    Spindles_GlobalResults.loc[counter, 'UnitNumber'] = unit \n",
    "                                    Spindles_GlobalResults.loc[counter, 'UnitValue'] = Calcium.index[unit] \n",
    "                                    \n",
    "                                    Spindles_GlobalResults.loc[counter, 'ExpeType'] =  expe_type\n",
    "                                    Spindles_GlobalResults.loc[counter, 'Drug'] =  drug\n",
    "\n",
    "                                    Spindles_GlobalResults.loc[counter, 'SpdlStatut'] = Spdl_statut\n",
    "                                    Spindles_GlobalResults.loc[counter, 'SpdlStartLocation'] = StartLocSpi\n",
    "                                    Spindles_GlobalResults.loc[counter, 'GlobalSpindle'] = diffSpi\n",
    "                                    Spindles_GlobalResults.loc[counter, 'SpdlNumber'] = Pspin\n",
    "                                    Spindles_GlobalResults.loc[counter, 'SpdlDuration'] = endSpi- startSpi                        \n",
    "                                    Spindles_GlobalResults.loc[counter, 'SWR_inside_Spdl'] = IsTrue\n",
    "                                    Spindles_GlobalResults.loc[counter, 'DistanceSWR_Spdl'] = delaiSWRSpdl \n",
    "                                    Spindles_GlobalResults.loc[counter, 'DistanceClosestSpdl'] = closestSpdl \n",
    "                \n",
    "                                    counter+=1    \n",
    "                            #else: \n",
    "                                #print(\"/!\\ Spindle too close to the end of the previous one,\", session, \", Spdl n°\", Pspin, \", Start Spdl =\", round(startSpi/1000,1), \"s\") if unit_count==1 else None\n",
    "                        \n",
    "                        ## Peristimulus Time Histogram \n",
    "                        start4 = time.time()\n",
    "                        for ctx in CTX: \n",
    "                            for coup in Coupling: \n",
    "                                # All Ca traces for each spindles per Unique unit (according to cross-registration)\n",
    "                                ActivityCa = locals()[f'ActivityCa_{coup}Spin{ctx}']\n",
    "                                dict_All_ActivityCa = locals()[f'dict_All_ActivityCa_{coup}SPDL{ctx}_{drug}']\n",
    "                                ActivitySp = locals()[f'ActivitySp_{coup}Spin{ctx}']\n",
    "                                dict_All_ActivitySp = locals()[f'dict_All_ActivitySp_{coup}SPDL{ctx}_{drug}']\n",
    "                                if len(indexMapp) > 0: #not empty --> cause some units are not in the cross registration..! Need to know why    \n",
    "                                    if len(ActivityCa)>0 :                                \n",
    "                                        if np.shape(np.array(ActivityCa))[1] == int(norm_freq*durationSpdl*2):  #normalize traces to the same frequency rate         \n",
    "                                            ActivityCa= np.reshape(np.array(ActivityCa), (-1, len(np.array(ActivityCa)))) if np.ndim(ActivityCa) == 1 else np.array(ActivityCa)    \n",
    "                                            ActivitySp= np.reshape(np.array(ActivitySp), (-1, len(np.array(ActivitySp)))) if np.ndim(ActivitySp) == 1 else np.array(ActivitySp)    \n",
    "                                            key=mice + str(indexMapp).replace('[','').replace(']','')\n",
    "                                            dict_All_ActivityCa[key] = np.append(dict_All_ActivityCa[key], np.array(ActivityCa), axis=0) if key in dict_All_ActivityCa else np.array(ActivityCa)\n",
    "                                            dict_All_ActivitySp[key] = np.append(dict_All_ActivitySp[key], np.array(ActivitySp), axis=0) if key in dict_All_ActivitySp else np.array(ActivitySp)\n",
    "                                        else:\n",
    "                                            dataO = np.array(ActivityCa)\n",
    "                                            data= np.repeat(dataO, 2, axis=0) if dataO.shape[0] == 1 else dataO\n",
    "                                            x_mesh, y_mesh = np.meshgrid(np.arange(data.shape[1]), np.arange(data.shape[0]))\n",
    "                                            x_new_mesh, y_new_mesh = np.meshgrid(np.linspace(0, data.shape[1] - 1, int(norm_freq*durationSpdl*2)), np.linspace(0, data.shape[0] - 1, np.shape(data)[0]))\n",
    "                                            resampled_dataO = griddata((x_mesh.flatten(), y_mesh.flatten()), data.flatten(), (x_new_mesh, y_new_mesh), method='linear')\n",
    "                                            resampled_data= resampled_dataO[0,:] if dataO.shape[0] == 1 else resampled_dataO\n",
    "                                            resampled_data= np.reshape(resampled_data, (-1, len(resampled_data))) if np.ndim(resampled_data) == 1 else resampled_data\n",
    "                                            key=mice + str(indexMapp).replace('[','').replace(']','')\n",
    "                                            dict_All_ActivityCa[key] = np.append(dict_All_ActivityCa[key], np.array(resampled_data), axis=0) if key in dict_All_ActivityCa else np.array(resampled_data)\n",
    "\n",
    "                                            dataO = np.array(ActivitySp)\n",
    "                                            data= np.repeat(dataO, 2, axis=0) if dataO.shape[0] == 1 else dataO\n",
    "                                            x_mesh, y_mesh = np.meshgrid(np.arange(data.shape[1]), np.arange(data.shape[0]))\n",
    "                                            x_new_mesh, y_new_mesh = np.meshgrid(np.linspace(0, data.shape[1] - 1, int(norm_freq*durationSpdl*2)), np.linspace(0, data.shape[0] - 1, np.shape(data)[0]))\n",
    "                                            resampled_dataO = griddata((x_mesh.flatten(), y_mesh.flatten()), data.flatten(), (x_new_mesh, y_new_mesh), method='nearest')\n",
    "                                            resampled_data= resampled_dataO[0,:] if dataO.shape[0] == 1 else resampled_dataO\n",
    "                                            resampled_data= np.reshape(resampled_data, (-1, len(resampled_data))) if np.ndim(resampled_data) == 1 else resampled_data\n",
    "                                            key=mice + str(indexMapp).replace('[','').replace(']','')\n",
    "                                            dict_All_ActivitySp[key] = np.append(dict_All_ActivitySp[key], np.array(resampled_data), axis=0) if key in dict_All_ActivitySp else np.array(resampled_data)\n",
    "\n",
    "                        print(f'... {len(SpipropTrunc)} Spdl processed in {time.time() - start3:.2f} & PSTH done in {time.time() - start4:.2f} seconds for one cell') if unit_count==1 else None\n",
    "\n",
    "                        #######################################################################################\n",
    "                                                            # for SWRs #\n",
    "                        #######################################################################################\n",
    "                        \n",
    "                        for coup in Coupling:\n",
    "                            for ctx in CTX:   \n",
    "                                if coup =='Coupled':     \n",
    "                                    locals()[f'ActivityCa_{coup}swr{ctx}']=[] #For each unit \n",
    "                                    locals()[f'ActivitySp_{coup}swr{ctx}']=[] #For each unit  \n",
    "                                else:\n",
    "                                    locals()[f'ActivityCa_{coup}swr']=[] #For each unit \n",
    "                                    locals()[f'ActivitySp_{coup}swr']=[] #For each unit  \n",
    "\n",
    "                        start5 = time.time()\n",
    "\n",
    "                        prevSWR=[]\n",
    "                        for Pswr in SWRpropTrunc.index: \n",
    "\n",
    "                            # Get the calcium and spike trace associated with the SWR\n",
    "                            startSwr=SWRpropTrunc.loc[Pswr, \"start time\"]\n",
    "                            endSwr=SWRpropTrunc.loc[Pswr, \"end time\"]\n",
    "\n",
    "                            endPreviousSwr=SWRpropTrunc.loc[prevSWR, \"end time\"] if prevSWR else startSwr-durationSWR*1000                             \n",
    "                            prevSWR=Pswr\n",
    "\n",
    "                            if startSwr - endPreviousSwr >= durationSWR*1000 : # if the spindle is not too close from the end of previous one \n",
    "                                \n",
    "                                TooEarlySWR=startSwr-durationSWR*1000<StartFrame_msec # too close to the begining of the recording\n",
    "                                TooLateSWR=startSwr+durationSWR*1000>LastFrame_msec # too close to the end of the recording\n",
    "                                \n",
    "                                if TooEarlySWR or TooLateSWR:\n",
    "                                    print(\"/!\\ SWR too close to the begining/end of the recording,\", session, \", SWR n°\", Pswr, \", Start SWR =\",  round(startSwr/1000,1), \"s\") if unit_count==1 else None \n",
    "                                else:\n",
    "\n",
    "                                    Frame_SWR_start_all = (TS_miniscope_sub - startSwr).abs().idxmin()\n",
    "                                    Frame_SWR_start=Frame_SWR_start_all-nb_of_previousframe\n",
    "\n",
    "                                    CaTrace = list(Carray_unit[Frame_SWR_start-HalfSWR:Frame_SWR_start+HalfSWR])\n",
    "                                    SpTrace = list(Sarray_unit[Frame_SWR_start-HalfSWR:Frame_SWR_start+HalfSWR]) \n",
    "\n",
    "                                    ActivityCa_swr=locals()[f'ActivityCa_swr']\n",
    "                                    ActivitySp_swr=locals()[f'ActivitySp_swr']\n",
    "\n",
    "                                    ActivityCa_swr.append(CaTrace)\n",
    "                                    ActivitySp_swr.append(SpTrace)\n",
    "\n",
    "                                    # Define if that SWR is coupled with a SPDL or not\n",
    "\n",
    "                                    SWR_statut=[]\n",
    "                                    startSpiList = list(pd.Series(SpipropTrunc[\"start time\"]))\n",
    "                                    endSpiList = list(pd.Series(SpipropTrunc[\"end time\"]))\n",
    "                                    ctxSpiList = list(pd.Series(SpipropTrunc[\"CTX\"]))\n",
    "                                    delaiSWRSpdl=None\n",
    "                                    IsTrue=None\n",
    "                                    if len(startSpiList)>0:\n",
    "                                        startClosest_Spdl_idx = (np.abs(startSpiList - startSwr)).argmin()\n",
    "                                        startClosest_Spi = startSpiList[startClosest_Spdl_idx]\n",
    "                                        endClosest_Spi=endSpiList[startClosest_Spdl_idx]\n",
    "                                        ctxSpi=ctxSpiList[startClosest_Spdl_idx]\n",
    "                                        distance = abs(startClosest_Spi - startSwr) #  + StartTimeIndexSpi]  \n",
    "                                        IsTrue = startSwr>startClosest_Spi and startSwr<endClosest_Spi #SWR inside the Spindle\n",
    "                                        if distance<before or IsTrue:\n",
    "                                            SWR_statut = 'Coupled'\n",
    "                                            cCoupledSWR+=1 if unit_count==1 else 0\n",
    "                                            delaiSWRSpdl=startClosest_Spi - startSwr                           \n",
    "                                        else:\n",
    "                                            SWR_statut= 'UnCoupled'\n",
    "                                            cUnCoupledSWR+=1 if unit_count==1 else 0\n",
    "                                            ctxSpi=''\n",
    "                                    else: \n",
    "                                        SWR_statut= 'UnCoupled'\n",
    "                                        cUnCoupledSWR+=1 if unit_count==1 else 0\n",
    "                                        ctxSpi=''\n",
    "\n",
    "                                    ActivityCa_swrCp=locals()[f'ActivityCa_{SWR_statut}swr{ctxSpi}']\n",
    "                                    ActivitySp_swrCp=locals()[f'ActivitySp_{SWR_statut}swr{ctxSpi}']\n",
    "                                    ActivityCa_swrCp.append(CaTrace)\n",
    "                                    ActivitySp_swrCp.append(SpTrace)\n",
    "                                    \n",
    "                                    # Fill the big summary table SWR_GlobalResults\n",
    "\n",
    "                                    SWR_GlobalResults.loc[counter2, 'Mice'] = mice\n",
    "                                    SWR_GlobalResults.loc[counter2, 'NeuronType'] = NeuronType\n",
    "\n",
    "                                    SWR_GlobalResults.loc[counter2, 'Session'] = session\n",
    "                                    SWR_GlobalResults.loc[counter2, 'Session_Date'] = session_date \n",
    "                                    SWR_GlobalResults.loc[counter2, 'Session_Time'] = session_time                    \n",
    "\n",
    "                                    SWR_GlobalResults.loc[counter2, 'Unique_Unit'] = indexMapp \n",
    "                                    SWR_GlobalResults.loc[counter2, 'UnitNumber'] = unit \n",
    "                                    SWR_GlobalResults.loc[counter2, 'UnitValue'] = Calcium.index[unit] \n",
    "                                    \n",
    "                                    SWR_GlobalResults.loc[counter2, 'ExpeType'] =  expe_type\n",
    "                                    SWR_GlobalResults.loc[counter2, 'Drug'] = drug\n",
    "\n",
    "                                    SWR_GlobalResults.loc[counter2, 'SWRStatut'] = SWR_statut\n",
    "                                    SWR_GlobalResults.loc[counter2, 'SpdlLoc'] = ctxSpi\n",
    "                                    SWR_GlobalResults.loc[counter2, 'SWRNumber'] = Pswr\n",
    "                                    SWR_GlobalResults.loc[counter2, 'SWRDuration'] = endSwr- startSwr\n",
    "                                    SWR_GlobalResults.loc[counter2, 'SWR_inside_Spdl'] = IsTrue\n",
    "                                    SWR_GlobalResults.loc[counter2, 'DistanceSWR_Spdl'] = delaiSWRSpdl \n",
    "                                    counter2+=1  \n",
    "                            #else: \n",
    "                            #    print(\"/!\\ SWR too close to the end of the previous one,\", session, \", SWR n°\", Pswr, \", Start SWR =\",  round(startSwr/1000,1), \"s\") if unit==0 else None\n",
    "\n",
    "                        ## Peristimulus Time Histogram \n",
    "                        start6 = time.time()\n",
    "                        for ctx in CTX: \n",
    "                            for coup in Coupling: \n",
    "                                if coup=='Coupled':\n",
    "                                    # All Ca traces for each spindles per Unique unit (according to cross-registration)\n",
    "                                    ActivityCa = locals()[f'ActivityCa_{coup}swr{ctx}']\n",
    "                                    dict_All_ActivityCa = locals()[f'dict_All_ActivityCa_{coup}SWR{ctx}_{drug}']\n",
    "                                    ActivitySp = locals()[f'ActivitySp_{coup}swr{ctx}']\n",
    "                                    dict_All_ActivitySp = locals()[f'dict_All_ActivitySp_{coup}SWR{ctx}_{drug}']\n",
    "                                else:    \n",
    "                                    # All Ca traces for each spindles per Unique unit (according to cross-registration)\n",
    "                                    ActivityCa = locals()[f'ActivityCa_{coup}swr']\n",
    "                                    dict_All_ActivityCa = locals()[f'dict_All_ActivityCa_{coup}SWR_{drug}']\n",
    "                                    ActivitySp = locals()[f'ActivitySp_{coup}swr']\n",
    "                                    dict_All_ActivitySp = locals()[f'dict_All_ActivitySp_{coup}SWR_{drug}']\n",
    "                                if len(indexMapp) > 0: #not empty --> cause some units are not in the cross registration..! Need to know why \n",
    "                                    if len(ActivityCa)>0 :                                  \n",
    "                                        if np.shape(np.array(ActivityCa))[1] == int(norm_freq*durationSWR*2):   #normalize traces to the same frequency rate    \n",
    "                                            ActivityCa= np.reshape(np.array(ActivityCa), (-1, len(np.array(ActivityCa)))) if np.ndim(ActivityCa) == 1 else np.array(ActivityCa)    \n",
    "                                            ActivitySp= np.reshape(np.array(ActivitySp), (-1, len(np.array(ActivitySp)))) if np.ndim(ActivitySp) == 1 else np.array(ActivitySp)    \n",
    "                                            key=mice + str(indexMapp).replace('[','').replace(']','')\n",
    "                                            dict_All_ActivityCa[key] = np.append(dict_All_ActivityCa[key], np.array(ActivityCa), axis=0) if key in dict_All_ActivityCa else np.array(ActivityCa)\n",
    "                                            dict_All_ActivitySp[key] = np.append(dict_All_ActivitySp[key], np.array(ActivitySp), axis=0) if key in dict_All_ActivitySp else np.array(ActivitySp)\n",
    "                                        else:\n",
    "                                            dataO = np.array(ActivityCa)\n",
    "                                            data= np.repeat(dataO, 2, axis=0) if dataO.shape[0] == 1 else dataO\n",
    "                                            x_mesh, y_mesh = np.meshgrid(np.arange(data.shape[1]), np.arange(data.shape[0]))\n",
    "                                            x_new_mesh, y_new_mesh = np.meshgrid(np.linspace(0, data.shape[1] - 1, int(norm_freq*durationSWR*2)), np.linspace(0, data.shape[0] - 1, np.shape(data)[0]))\n",
    "                                            resampled_dataO = griddata((x_mesh.flatten(), y_mesh.flatten()), data.flatten(), (x_new_mesh, y_new_mesh), method='linear')\n",
    "                                            resampled_data= resampled_dataO[0,:] if dataO.shape[0] == 1 else resampled_dataO\n",
    "                                            resampled_data= np.reshape(resampled_data, (-1, len(resampled_data))) if np.ndim(resampled_data) == 1 else resampled_data\n",
    "                                            key=mice + str(indexMapp).replace('[','').replace(']','')\n",
    "                                            dict_All_ActivityCa[key] = np.append(dict_All_ActivityCa[key], np.array(resampled_data), axis=0) if key in dict_All_ActivityCa else np.array(resampled_data)\n",
    "                                            \n",
    "                                            dataO = np.array(ActivitySp)\n",
    "                                            data= np.repeat(dataO, 2, axis=0) if dataO.shape[0] == 1 else dataO\n",
    "                                            x_mesh, y_mesh = np.meshgrid(np.arange(data.shape[1]), np.arange(data.shape[0]))\n",
    "                                            x_new_mesh, y_new_mesh = np.meshgrid(np.linspace(0, data.shape[1] - 1, int(norm_freq*durationSWR*2)), np.linspace(0, data.shape[0] - 1, np.shape(data)[0]))\n",
    "                                            resampled_dataO = griddata((x_mesh.flatten(), y_mesh.flatten()), data.flatten(), (x_new_mesh, y_new_mesh), method='nearest')\n",
    "                                            resampled_data= resampled_dataO[0,:] if dataO.shape[0] == 1 else resampled_dataO\n",
    "                                            resampled_data= np.reshape(resampled_data, (-1, len(resampled_data))) if np.ndim(resampled_data) == 1 else resampled_data\n",
    "                                            key=mice + str(indexMapp).replace('[','').replace(']','')\n",
    "                                            dict_All_ActivitySp[key] = np.append(dict_All_ActivitySp[key], np.array(resampled_data), axis=0) if key in dict_All_ActivitySp else np.array(resampled_data)\n",
    "                        \n",
    "                        print(f'... {len(SWRpropTrunc)} SWR processed in {time.time() - start5:.2f} seconds & PSTH done in {time.time() - start6:.2f} seconds for one cell') if unit_count==1 else None\n",
    "\n",
    "                print(f\"... The {unit_count} units of {session} analyzed in {time.time() - start2:.2f} seconds\")\n",
    "\n",
    "                sentence2=f\"... {nb_spindle} spindles ({cCoupled} Coupled & {cUnCoupled} Uncoupled Spdl // {cGlobal} Global, {cLocalS1} LocalS1 & {cLocalPFC} LocalPFC) and {nb_swr} SWR detected ({cCoupledSWR} Coupled & {cUnCoupledSWR} Uncoupled SWR)\"\n",
    "                print(sentence2) \n",
    "            else:\n",
    "                print(f'/!\\ {session} not taken into account cause minian frequency = {minian_freq}')\n",
    "                        \n",
    "    #######################################################################################\n",
    "                            # Save Spindles & SWR analysis #\n",
    "    #######################################################################################\n",
    "    # Do average Calcium & Spike results for Spindles & SWR Peristimulus Time Histogram \n",
    "    start7 = time.time()\n",
    "\n",
    "    Data=['Ca', 'Sp']\n",
    "    for data in Data:   \n",
    "        for ctx in CTX: \n",
    "            for coup in Coupling:\n",
    "                for drug in drugs:      \n",
    "                    dict_All_Activity=locals()[f'dict_All_Activity{data}_{coup}SPDL{ctx}_{drug}']\n",
    "                    filenameOut = folder_to_save / f'Spdl_{data}PSTH_{coup}{ctx}{drug}_{mice}.pkl' #keep each responses of each cells for all rec Spdl\n",
    "                    with open(filenameOut, 'wb') as pickle_file:\n",
    "                        pickle.dump(dict_All_Activity, pickle_file)\n",
    "                    if coup=='Coupled' : \n",
    "                        dict_All_Activity=locals()[f'dict_All_Activity{data}_{coup}SWR{ctx}_{drug}']\n",
    "                        filenameOut = folder_to_save / f'SWR_{data}PSTH_{coup}{ctx}{drug}_{mice}.pkl' #keep each responses of each cells for all rec SWR\n",
    "                        with open(filenameOut, 'wb') as pickle_file:\n",
    "                            pickle.dump(dict_All_Activity, pickle_file)\n",
    "                    else:\n",
    "                        dict_All_Activity=locals()[f'dict_All_Activity{data}_{coup}SWR_{drug}']\n",
    "                        filenameOut = folder_to_save / f'SWR_{data}PSTH_{coup}{drug}_{mice}.pkl' #keep each responses of each cells for all rec SWR\n",
    "                        with open(filenameOut, 'wb') as pickle_file:\n",
    "                            pickle.dump(dict_All_Activity, pickle_file)\n",
    "\n",
    "    sentence3=f\"Nb of unique units for {mice} = {len(mapping)} / Data saved in {time.time() - start2:.2f} seconds\"\n",
    "    print(sentence3)   \n",
    "\n",
    "\n",
    "start8 = time.time()\n",
    "if saveexcel: \n",
    "    # Save the big summary table Spindles_GlobalResults\n",
    "    writer = pd.ExcelWriter(folder_to_save / f'Spdl_Global.xlsx')\n",
    "    Spindles_GlobalResults.to_excel(writer)\n",
    "    writer.close()\n",
    "\n",
    "    # Save the big summary table SWR_GlobalResults\n",
    "    writer = pd.ExcelWriter(folder_to_save / f'SWR_Global.xlsx')\n",
    "    SWR_GlobalResults.to_excel(writer)\n",
    "    writer.close()\n",
    "\n",
    "with open(folder_to_save / f'Spdl_Global.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(Spindles_GlobalResults, pickle_file)   \n",
    "\n",
    "with open(folder_to_save / f'SWR_Global.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(SWR_GlobalResults, pickle_file)\n",
    "\n",
    "print(f\"Global matrix saved in {time.time() - start8:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
